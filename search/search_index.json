{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Documentation Quick Start User Guide API Reference Manual For Developers","title":"Documentation"},{"location":"#documentation","text":"","title":"Documentation"},{"location":"#quick-start","text":"","title":"Quick Start"},{"location":"#user-guide","text":"","title":"User Guide"},{"location":"#api-reference-manual","text":"","title":"API Reference Manual"},{"location":"#for-developers","text":"","title":"For Developers"},{"location":"get_started/","text":"Get Started An executable configuration graph. Note: We describe the concept of this core module in following few lines and show some pesudo-codes. This is very close to but not the same as the real code. An acyclic directed hypergraph G consists of a set of vertices V and a set of hyperarcs H , where a hyperarc is a pair <X, Y> , X and Y non empty subset of V . We have a tag system that split the vertices V into maybe overlapping subsets V_i , that each of which is a degenerated hypergraph G_i that only consists of vertices V_i and a set of hyperarcs H_i so that each hyperarc is a pair <x, Y> , where x \\in V_i and Y \\subset V_i . We call tails x as producers and heads Y as consumers in each hyperarc, this states the dependencies. User defines a vertice ( Node in the code) by specify a computation process f ( forward in the code) and the resources R ( Dataset s, nn.Module s, imperatively programmed function definitions such as losses and metrics, etc.) needed by it. vertice_1 = Node ( name = \"consumer_node_name\" , resources = ... , forward = lambda n , x : do_something_with ( n . resources , x [ \"producer_node_name\" ]), tags = [ \"group1\" , \"group2\" ], ) A longer version of forward parameter that corresponds to the previous notation would be forward = lambda self, V_i: do_something_with(self.resources, V_i[\"x\"]) , but we will stick to the shorter version in the code. So at the time of configuration, we are able to define every material as a node, and the name of nodes can be duplicated, i.e. multiple x\\in V can have the same identifier, as long as they does not have the same tag i that selects V_i . The tags mechanism is flexible. Every node can have multiple of them, and multiple tags can be specified so that a union of subsets will be retrieved. If no tag is specified for a node, a default tag * will be used and a retrival will always include the * group. ```python hyper_graph = HyperGraph([ vertice_1, vertice_2, ..., vertice_n, ]) activated_graph = hyper_graph[\"group1\", \"group3\", \"group5\"] freeze_and_execute(activated_graph)","title":"Get Started"},{"location":"get_started/#get-started","text":"An executable configuration graph. Note: We describe the concept of this core module in following few lines and show some pesudo-codes. This is very close to but not the same as the real code. An acyclic directed hypergraph G consists of a set of vertices V and a set of hyperarcs H , where a hyperarc is a pair <X, Y> , X and Y non empty subset of V . We have a tag system that split the vertices V into maybe overlapping subsets V_i , that each of which is a degenerated hypergraph G_i that only consists of vertices V_i and a set of hyperarcs H_i so that each hyperarc is a pair <x, Y> , where x \\in V_i and Y \\subset V_i . We call tails x as producers and heads Y as consumers in each hyperarc, this states the dependencies. User defines a vertice ( Node in the code) by specify a computation process f ( forward in the code) and the resources R ( Dataset s, nn.Module s, imperatively programmed function definitions such as losses and metrics, etc.) needed by it. vertice_1 = Node ( name = \"consumer_node_name\" , resources = ... , forward = lambda n , x : do_something_with ( n . resources , x [ \"producer_node_name\" ]), tags = [ \"group1\" , \"group2\" ], ) A longer version of forward parameter that corresponds to the previous notation would be forward = lambda self, V_i: do_something_with(self.resources, V_i[\"x\"]) , but we will stick to the shorter version in the code. So at the time of configuration, we are able to define every material as a node, and the name of nodes can be duplicated, i.e. multiple x\\in V can have the same identifier, as long as they does not have the same tag i that selects V_i . The tags mechanism is flexible. Every node can have multiple of them, and multiple tags can be specified so that a union of subsets will be retrieved. If no tag is specified for a node, a default tag * will be used and a retrival will always include the * group. ```python hyper_graph = HyperGraph([ vertice_1, vertice_2, ..., vertice_n, ]) activated_graph = hyper_graph[\"group1\", \"group3\", \"group5\"] freeze_and_execute(activated_graph)","title":"Get Started"},{"location":"documents/","text":"API Overview Modules api api.hypergraph api.scripts.wait_process : wait for a process to finish. api.transforms api.transforms.image api.transforms.image.io api.transforms.image.photometric api.transforms.image.spatial api.transforms.random api.transforms.semseg api.utils core.dataset core.graph : contains Node and ExecutableGraph . core.hypergraph core.loss core.metric core.module core.optim llutil llutil.argparser : parse arguments for functions and command line. llutil.board llutil.collections llutil.config llutil.debug llutil.dictprocess llutil.file_client llutil.ignore_me llutil.launcher llutil.launcher.elastic_multiprocessing llutil.launcher.events llutil.launcher.launch_agent llutil.launcher.launcher llutil.launcher.local_elastic_agent llutil.logger : logging utilities. llutil.multiprocessing : a drop-in replacement for torch.multiprocessing . llutil.print llutil.pycuda : Integrates PyCUDA to PyTorch and ice. llutil.shadow_tb llutil.test : helps developers of ice to test. Classes dataset.DatasetNode : Automating DataLoader and DataSampler creation and maintainance. dataset.ResumableDistributedSampler graph.ExecutableGraph graph.GraphOutputCache graph.InvalidURIError : An Exception raised when valid node URI is expected. graph.Node : This class defines the executable node. graph.StopAllTasks : An Exception raised to exit current running. graph.StopTask : An Exception raised to exit current task. hypergraph.Counter hypergraph.GlobalCounters : GlobalCounters(steps: core.hypergraph.Counter = , epochs: core.hypergraph.Counter = ) hypergraph.HyperGraph : HyperGraph is the container for all nodes. hypergraph.Repeat hypergraph.ResumeTaskFailed : raised when task structure does not match during resuming. hypergraph.Task loss.LossMode : An enumeration. loss.LossNode metric.AverageMeter metric.DictMetric metric.Meter : value reducer that works recursively. metric.MetricNode metric.MovingAverageMeter metric.SummationMeter metric.ValueMeter module.ModuleNode : a node that extends torch.nn.Module optim.Optimizer : Optimizer configuration API for ice-learn. argparser.ArgumentMissingError : Raised when a required argument is missing from command line. argparser.ArgumentTypeError : Raised when converting an argument failed. argparser.FlexibleArgParser : A flexible and lightweight argument parser that saves loads of code. board.BoardWriter collections.ConfigDict : stores multi-level configurations easily. collections.Counter : count values by group. collections.Dict : access dict values as attributes. config.Configurable debug.SubProcessPdb : Pdb that works from a multiprocessing child file_client.BaseStorageBackend : Abstract class of storage backends. file_client.CephBackend : Ceph storage backend (for internal use). file_client.FileClient : A general file client to access files in different backends. file_client.HTTPBackend : HTTP and HTTPS storage bachend. file_client.HardDiskBackend : Raw hard disks storage backend. file_client.LmdbBackend : Lmdb storage backend. file_client.MemcachedBackend : Memcached storage backend. file_client.PetrelBackend : Petrel storage backend (for internal use). ignore_me.IgnoreMe elastic_multiprocessing.MultiprocessContext : PContext holding worker processes invoked as a function. elastic_multiprocessing.PContext : The base class that standardizes operations over a set of processes elastic_multiprocessing.TailLog : Tails the given log files. The log files do not have to exist when the events.Events : Communicate among main process (agent) and subprocesses (workers). launch_agent.LaunchConfig : Creates a rendezvous config. launcher.ElasticLauncher : A helper Configurable class for torchrun and torch.distributed.launch . local_elastic_agent.LocalElasticAgent : An implementation of :py:class: torchelastic.agent.server.ElasticAgent pycuda.CUDAModule : Just-In-Time compilation of a set of CUDA kernel functions and device functions from source. Functions hypergraph.add hypergraph.backup_source_files hypergraph.init_autocast hypergraph.init_grad_scaler hypergraph.print_forward_output hypergraph.run hypergraph.set_gradient_accumulate io.Load : Args : io.imfrombytes : Read an image from bytes. io.imread : Read an image. io.imwrite : Write image to file. io.use_backend : Select a backend for image decoding. photometric.Normalize : Normalize the image and convert BGR2RGB. photometric.PhotoMetricDistortion : Apply photometric distortion to image sequentially, every dictprocessation photometric.ToTensor : Args: spatial.Crop : crop a region of interest from the src array. spatial.Flip : flip the src image. spatial.Pad : Padding a image to target size. spatial.Resize : Args: spatial.SizeDivisorMultiple : Returns a smallest but larger shape to ensure each edge to be multiple to some number. random.RandomChoice random.RandomDo random.RandomFloats random.RandomImage : generate a random image for testing purpose random.RandomIntegers random.RandomProbabilities random.RandomROI : generate random region of interest. semseg.LabelToTensor : Convert to tensor (as int64). semseg.LoadAnnotation : Load annotations for semantic segmentation. semseg.RandomCrop : Crop a pair of images and segmentation labels such that the class is relatively balanced for training. utils.parse_devices dataset.failsafe_collate : Puts each data field into a tensor with outer dimension batch size hypergraph.GlobalCounters.__init__ hypergraph.LoadCheckpointTask hypergraph.SaveCheckpointTask argparser.as_dict : helps to regularize input into a dict. argparser.as_list : helps to regularize input into list of element. argparser.get_hostname argparser.is_list_of : Check whether it is a list of some type. argparser.is_seq_of : Check whether it is a sequence of some type. argparser.is_tuple_of : Check whether it is a tuple of some type. argparser.isa : an alias for python built-in isinstance . argparser.parse_scalar config.clone : clone configurables, containers, and ordinary objects recursively. config.configurable : This decorator delays the initialization of cls until freeze() . config.freeze : freeze configurables recursively. config.frozen config.has_builder config.is_configurable : check if a class or an object is configurable. config.make_configurable : This function converts multiple existing classes to configurables. config.objattr debug.set_trace dictprocess.Collect : a predefined DictProcessor that keep only selected entries. dictprocess.Compose : a predefined DictProcessor that composes a list of other DictProcessors together. dictprocess.dictprocess : a decorator that convert function into a DictProcessor ( Callable[[Dict], Dict] ). file_client.has_method : Check whether the object has a method. file_client.mmcv_mkdir_or_exist elastic_multiprocessing.start_processes : Starts n copies of entrypoint processes with the provided options. elastic_multiprocessing.tail_logfile launch_agent.LaunchConfig.__init__ launch_agent.launch_agent launcher.get_current_launcher logger.get_logger : set up a simple logger that writes into stderr. multiprocessing.auto_freeze_enabled multiprocessing.enable_auto_freeze multiprocessing.in_main_process : Whether current process is worker process or main process. print.format_size : Format a byte count as a human readable file size. shadow_tb.shadow test.requires_n_gpus","title":"Index"},{"location":"documents/#api-overview","text":"","title":"API Overview"},{"location":"documents/#modules","text":"api api.hypergraph api.scripts.wait_process : wait for a process to finish. api.transforms api.transforms.image api.transforms.image.io api.transforms.image.photometric api.transforms.image.spatial api.transforms.random api.transforms.semseg api.utils core.dataset core.graph : contains Node and ExecutableGraph . core.hypergraph core.loss core.metric core.module core.optim llutil llutil.argparser : parse arguments for functions and command line. llutil.board llutil.collections llutil.config llutil.debug llutil.dictprocess llutil.file_client llutil.ignore_me llutil.launcher llutil.launcher.elastic_multiprocessing llutil.launcher.events llutil.launcher.launch_agent llutil.launcher.launcher llutil.launcher.local_elastic_agent llutil.logger : logging utilities. llutil.multiprocessing : a drop-in replacement for torch.multiprocessing . llutil.print llutil.pycuda : Integrates PyCUDA to PyTorch and ice. llutil.shadow_tb llutil.test : helps developers of ice to test.","title":"Modules"},{"location":"documents/#classes","text":"dataset.DatasetNode : Automating DataLoader and DataSampler creation and maintainance. dataset.ResumableDistributedSampler graph.ExecutableGraph graph.GraphOutputCache graph.InvalidURIError : An Exception raised when valid node URI is expected. graph.Node : This class defines the executable node. graph.StopAllTasks : An Exception raised to exit current running. graph.StopTask : An Exception raised to exit current task. hypergraph.Counter hypergraph.GlobalCounters : GlobalCounters(steps: core.hypergraph.Counter = , epochs: core.hypergraph.Counter = ) hypergraph.HyperGraph : HyperGraph is the container for all nodes. hypergraph.Repeat hypergraph.ResumeTaskFailed : raised when task structure does not match during resuming. hypergraph.Task loss.LossMode : An enumeration. loss.LossNode metric.AverageMeter metric.DictMetric metric.Meter : value reducer that works recursively. metric.MetricNode metric.MovingAverageMeter metric.SummationMeter metric.ValueMeter module.ModuleNode : a node that extends torch.nn.Module optim.Optimizer : Optimizer configuration API for ice-learn. argparser.ArgumentMissingError : Raised when a required argument is missing from command line. argparser.ArgumentTypeError : Raised when converting an argument failed. argparser.FlexibleArgParser : A flexible and lightweight argument parser that saves loads of code. board.BoardWriter collections.ConfigDict : stores multi-level configurations easily. collections.Counter : count values by group. collections.Dict : access dict values as attributes. config.Configurable debug.SubProcessPdb : Pdb that works from a multiprocessing child file_client.BaseStorageBackend : Abstract class of storage backends. file_client.CephBackend : Ceph storage backend (for internal use). file_client.FileClient : A general file client to access files in different backends. file_client.HTTPBackend : HTTP and HTTPS storage bachend. file_client.HardDiskBackend : Raw hard disks storage backend. file_client.LmdbBackend : Lmdb storage backend. file_client.MemcachedBackend : Memcached storage backend. file_client.PetrelBackend : Petrel storage backend (for internal use). ignore_me.IgnoreMe elastic_multiprocessing.MultiprocessContext : PContext holding worker processes invoked as a function. elastic_multiprocessing.PContext : The base class that standardizes operations over a set of processes elastic_multiprocessing.TailLog : Tails the given log files. The log files do not have to exist when the events.Events : Communicate among main process (agent) and subprocesses (workers). launch_agent.LaunchConfig : Creates a rendezvous config. launcher.ElasticLauncher : A helper Configurable class for torchrun and torch.distributed.launch . local_elastic_agent.LocalElasticAgent : An implementation of :py:class: torchelastic.agent.server.ElasticAgent pycuda.CUDAModule : Just-In-Time compilation of a set of CUDA kernel functions and device functions from source.","title":"Classes"},{"location":"documents/#functions","text":"hypergraph.add hypergraph.backup_source_files hypergraph.init_autocast hypergraph.init_grad_scaler hypergraph.print_forward_output hypergraph.run hypergraph.set_gradient_accumulate io.Load : Args : io.imfrombytes : Read an image from bytes. io.imread : Read an image. io.imwrite : Write image to file. io.use_backend : Select a backend for image decoding. photometric.Normalize : Normalize the image and convert BGR2RGB. photometric.PhotoMetricDistortion : Apply photometric distortion to image sequentially, every dictprocessation photometric.ToTensor : Args: spatial.Crop : crop a region of interest from the src array. spatial.Flip : flip the src image. spatial.Pad : Padding a image to target size. spatial.Resize : Args: spatial.SizeDivisorMultiple : Returns a smallest but larger shape to ensure each edge to be multiple to some number. random.RandomChoice random.RandomDo random.RandomFloats random.RandomImage : generate a random image for testing purpose random.RandomIntegers random.RandomProbabilities random.RandomROI : generate random region of interest. semseg.LabelToTensor : Convert to tensor (as int64). semseg.LoadAnnotation : Load annotations for semantic segmentation. semseg.RandomCrop : Crop a pair of images and segmentation labels such that the class is relatively balanced for training. utils.parse_devices dataset.failsafe_collate : Puts each data field into a tensor with outer dimension batch size hypergraph.GlobalCounters.__init__ hypergraph.LoadCheckpointTask hypergraph.SaveCheckpointTask argparser.as_dict : helps to regularize input into a dict. argparser.as_list : helps to regularize input into list of element. argparser.get_hostname argparser.is_list_of : Check whether it is a list of some type. argparser.is_seq_of : Check whether it is a sequence of some type. argparser.is_tuple_of : Check whether it is a tuple of some type. argparser.isa : an alias for python built-in isinstance . argparser.parse_scalar config.clone : clone configurables, containers, and ordinary objects recursively. config.configurable : This decorator delays the initialization of cls until freeze() . config.freeze : freeze configurables recursively. config.frozen config.has_builder config.is_configurable : check if a class or an object is configurable. config.make_configurable : This function converts multiple existing classes to configurables. config.objattr debug.set_trace dictprocess.Collect : a predefined DictProcessor that keep only selected entries. dictprocess.Compose : a predefined DictProcessor that composes a list of other DictProcessors together. dictprocess.dictprocess : a decorator that convert function into a DictProcessor ( Callable[[Dict], Dict] ). file_client.has_method : Check whether the object has a method. file_client.mmcv_mkdir_or_exist elastic_multiprocessing.start_processes : Starts n copies of entrypoint processes with the provided options. elastic_multiprocessing.tail_logfile launch_agent.LaunchConfig.__init__ launch_agent.launch_agent launcher.get_current_launcher logger.get_logger : set up a simple logger that writes into stderr. multiprocessing.auto_freeze_enabled multiprocessing.enable_auto_freeze multiprocessing.in_main_process : Whether current process is worker process or main process. print.format_size : Format a byte count as a human readable file size. shadow_tb.shadow test.requires_n_gpus","title":"Functions"},{"location":"documents/api.hypergraph/","text":"module api.hypergraph function run run ( * args , ** kwds ) function add add ( name , node : Node , tags = '*' ) function print_forward_output print_forward_output ( * args , ** kwds ) function init_grad_scaler init_grad_scaler ( * args , ** kwds ) function init_autocast init_autocast ( * args , ** kwds ) function set_gradient_accumulate set_gradient_accumulate ( every ) function backup_source_files backup_source_files ( entrypoint : str )","title":"Api.hypergraph"},{"location":"documents/api.hypergraph/#module-apihypergraph","text":"","title":"module api.hypergraph"},{"location":"documents/api.hypergraph/#function-run","text":"run ( * args , ** kwds )","title":"function run"},{"location":"documents/api.hypergraph/#function-add","text":"add ( name , node : Node , tags = '*' )","title":"function add"},{"location":"documents/api.hypergraph/#function-print_forward_output","text":"print_forward_output ( * args , ** kwds )","title":"function print_forward_output"},{"location":"documents/api.hypergraph/#function-init_grad_scaler","text":"init_grad_scaler ( * args , ** kwds )","title":"function init_grad_scaler"},{"location":"documents/api.hypergraph/#function-init_autocast","text":"init_autocast ( * args , ** kwds )","title":"function init_autocast"},{"location":"documents/api.hypergraph/#function-set_gradient_accumulate","text":"set_gradient_accumulate ( every )","title":"function set_gradient_accumulate"},{"location":"documents/api.hypergraph/#function-backup_source_files","text":"backup_source_files ( entrypoint : str )","title":"function backup_source_files"},{"location":"documents/api/","text":"module api Global Variables hypergraph utils","title":"Api"},{"location":"documents/api/#module-api","text":"","title":"module api"},{"location":"documents/api/#global-variables","text":"hypergraph utils","title":"Global Variables"},{"location":"documents/api.scripts.wait_process/","text":"module api.scripts.wait_process wait for a process to finish. usage: wait_process [-h] PIDS [PIDS ...] This command just blocks until all processes specified in PIDS exits. positional arguments: PIDS optional arguments: -h, --help show this help message and exit","title":"Api.scripts.wait process"},{"location":"documents/api.scripts.wait_process/#module-apiscriptswait_process","text":"wait for a process to finish. usage: wait_process [-h] PIDS [PIDS ...] This command just blocks until all processes specified in PIDS exits. positional arguments: PIDS optional arguments: -h, --help show this help message and exit","title":"module api.scripts.wait_process"},{"location":"documents/api.scripts.waitfinish/","text":"module api.scripts.waitfinish usage: waitfinish [-h] PIDS [PIDS ...] This command just blocks until all processes specified in PIDS exits. positional arguments: PIDS optional arguments: -h, --help show this help message and exit","title":"Api.scripts.waitfinish"},{"location":"documents/api.scripts.waitfinish/#module-apiscriptswaitfinish","text":"usage: waitfinish [-h] PIDS [PIDS ...] This command just blocks until all processes specified in PIDS exits. positional arguments: PIDS optional arguments: -h, --help show this help message and exit","title":"module api.scripts.waitfinish"},{"location":"documents/api.transforms.image.io/","text":"module api.transforms.image.io Global Variables IMREAD_COLOR IMREAD_GRAYSCALE IMREAD_IGNORE_ORIENTATION IMREAD_UNCHANGED TJCS_RGB TJPF_GRAY TJPF_BGR TurboJPEG tifffile jpeg supported_backends imread_flags imread_backend function use_backend use_backend ( backend ) Select a backend for image decoding. Args: backend (str): The image decoding backend type. Options are cv2 , `pillow , turbojpeg (see https </b>: //github.com/lilohuang/PyTurboJPEG) and tifffile . turbojpeg is faster but it only supports .jpeg` file format. function imread imread ( img_or_path , flag = 'color' , channel_order = 'bgr' , backend = None , file_client_args = None ) Read an image. Note: In v1.4.1 and later, add file_client_args parameters. Args: img_or_path (ndarray or str or Path): Either a numpy array or str or pathlib.Path. If it is a numpy array (loaded image), then it will be returned as is. flag (str): Flags specifying the color type of a loaded image, candidates are color , grayscale , unchanged , color_ignore_orientation and grayscale_ignore_orientation . By default, cv2 and pillow backend would rotate the image according to its EXIF info unless called with unchanged or *_ignore_orientation flags. turbojpeg and tifffile backend always ignore image's EXIF info regardless of the flag. The turbojpeg backend only supports color and grayscale . channel_order (str): Order of channel, candidates are bgr and rgb . backend (str | None): The image decoding backend type. Options are cv2 , pillow , turbojpeg , tifffile , None . If backend is None, the global imread_backend specified by `mmcv.use_backend() will be used. Default` : None. file_client_args (dict | None): Arguments to instantiate a FileClient. See : class: mmcv.fileio.FileClient for details. Default : None. Returns: ndarray : Loaded image array. Examples: import mmcv img_path = '/path/to/img.jpg' img = mmcv . imread ( img_path ) img = mmcv . imread ( img_path , flag = 'color' , channel_order = 'rgb' , # ... backend='cv2') img = mmcv . imread ( img_path , flag = 'color' , channel_order = 'bgr' , # ... backend='pillow') s3_img_path = 's3://bucket/img.jpg' # infer the file backend by the prefix s3 img = mmcv . imread ( s3_img_path ) # manually set the file backend petrel img = mmcv . imread ( s3_img_path , file_client_args = { # ... 'backend': 'petrel'}) http_img_path = 'http://path/to/img.jpg' img = mmcv . imread ( http_img_path ) img = mmcv . imread ( http_img_path , file_client_args = { # ... 'backend': 'http'}) function imfrombytes imfrombytes ( content , flag = 'color' , channel_order = 'bgr' , backend = None ) Read an image from bytes. Args: content (bytes): Image bytes got from files or other streams. flag (str): Same as :func: imread . backend (str | None): The image decoding backend type. Options are cv2 , pillow , turbojpeg , tifffile , None . If backend is None, the global imread_backend specified by mmcv.use_backend() will be used. Default : None. Returns: ndarray : Loaded image array. Examples: img_path = '/path/to/img.jpg' with open ( img_path , 'rb' ) as f : img_buff = f . read () img = mmcv . imfrombytes ( img_buff ) img = mmcv . imfrombytes ( img_buff , flag = 'color' , channel_order = 'rgb' ) img = mmcv . imfrombytes ( img_buff , backend = 'pillow' ) img = mmcv . imfrombytes ( img_buff , backend = 'cv2' ) function imwrite imwrite ( img , file_path , params = None , auto_mkdir = None , file_client_args = None ) Write image to file. Note: In v1.4.1 and later, add file_client_args parameters. Warning: The parameter auto_mkdir will be deprecated in the future and every file clients will make directory automatically. Args: img (ndarray): Image array to be written. file_path (str): Image file path. params (None or list): Same as opencv :func: imwrite interface. auto_mkdir (bool): If the parent folder of file_path does not exist, whether to create it automatically. It will be deprecated. file_client_args (dict | None): Arguments to instantiate a FileClient. See : class: mmcv.fileio.FileClient for details. Default : None. Returns: bool : Successful or not. Examples: # write to hard disk client ret = mmcv . imwrite ( img , '/path/to/img.jpg' ) # infer the file backend by the prefix s3 ret = mmcv . imwrite ( img , 's3://bucket/img.jpg' ) # manually set the file backend petrel ret = mmcv . imwrite ( img , 's3://bucket/img.jpg' , file_client_args = { # ... 'backend': 'petrel'}) function Load Load ( img_path , prefix = None , to_float32 = False , flag = 'color' , channel_order = 'bgr' , backend = 'cv2' , file_client : FileClient = < ice . llutil . file_client . FileClient object at 0x7fa8a00b3ee0 > ) Args : * flag (str): Flags specifying the color type of a loaded image, candidates are color , grayscale , unchanged , color_ignore_orientation and grayscale_ignore_orientation . By default, cv2 and pillow backend would rotate the image according to its EXIF info unless called with unchanged or *_ignore_orientation flags. turbojpeg and tifffile backend always ignore image's EXIF info regardless of the flag. The turbojpeg backend only supports color and grayscale . * channel_order (str): Order of channel, candidates are bgr and rgb . * backend (str | None): The image decoding backend type. Options are cv2 , pillow , turbojpeg , tifffile , None . If backend is None, the global imread_backend specified by mmcv.use_backend() will be used. Default: None. * file_client : See mmcv.fileio.FileClient for details. References : - [mmseg.datasets.pipelines.LoadImageFromFile](https://mmsegmentation.readthedocs.io/en/latest/api.html#mmseg.datasets.pipelines.LoadImageFromFile) - [mmcv.image.imfrombytes()](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.image.imfrombytes) - [mmcv.image.imread()](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.image.imread)","title":"Api.transforms.image.io"},{"location":"documents/api.transforms.image.io/#module-apitransformsimageio","text":"","title":"module api.transforms.image.io"},{"location":"documents/api.transforms.image.io/#global-variables","text":"IMREAD_COLOR IMREAD_GRAYSCALE IMREAD_IGNORE_ORIENTATION IMREAD_UNCHANGED TJCS_RGB TJPF_GRAY TJPF_BGR TurboJPEG tifffile jpeg supported_backends imread_flags imread_backend","title":"Global Variables"},{"location":"documents/api.transforms.image.io/#function-use_backend","text":"use_backend ( backend ) Select a backend for image decoding. Args: backend (str): The image decoding backend type. Options are cv2 , `pillow , turbojpeg (see https </b>: //github.com/lilohuang/PyTurboJPEG) and tifffile . turbojpeg is faster but it only supports .jpeg` file format.","title":"function use_backend"},{"location":"documents/api.transforms.image.io/#function-imread","text":"imread ( img_or_path , flag = 'color' , channel_order = 'bgr' , backend = None , file_client_args = None ) Read an image. Note: In v1.4.1 and later, add file_client_args parameters. Args: img_or_path (ndarray or str or Path): Either a numpy array or str or pathlib.Path. If it is a numpy array (loaded image), then it will be returned as is. flag (str): Flags specifying the color type of a loaded image, candidates are color , grayscale , unchanged , color_ignore_orientation and grayscale_ignore_orientation . By default, cv2 and pillow backend would rotate the image according to its EXIF info unless called with unchanged or *_ignore_orientation flags. turbojpeg and tifffile backend always ignore image's EXIF info regardless of the flag. The turbojpeg backend only supports color and grayscale . channel_order (str): Order of channel, candidates are bgr and rgb . backend (str | None): The image decoding backend type. Options are cv2 , pillow , turbojpeg , tifffile , None . If backend is None, the global imread_backend specified by `mmcv.use_backend() will be used. Default` : None. file_client_args (dict | None): Arguments to instantiate a FileClient. See : class: mmcv.fileio.FileClient for details. Default : None. Returns: ndarray : Loaded image array. Examples: import mmcv img_path = '/path/to/img.jpg' img = mmcv . imread ( img_path ) img = mmcv . imread ( img_path , flag = 'color' , channel_order = 'rgb' , # ... backend='cv2') img = mmcv . imread ( img_path , flag = 'color' , channel_order = 'bgr' , # ... backend='pillow') s3_img_path = 's3://bucket/img.jpg' # infer the file backend by the prefix s3 img = mmcv . imread ( s3_img_path ) # manually set the file backend petrel img = mmcv . imread ( s3_img_path , file_client_args = { # ... 'backend': 'petrel'}) http_img_path = 'http://path/to/img.jpg' img = mmcv . imread ( http_img_path ) img = mmcv . imread ( http_img_path , file_client_args = { # ... 'backend': 'http'})","title":"function imread"},{"location":"documents/api.transforms.image.io/#function-imfrombytes","text":"imfrombytes ( content , flag = 'color' , channel_order = 'bgr' , backend = None ) Read an image from bytes. Args: content (bytes): Image bytes got from files or other streams. flag (str): Same as :func: imread . backend (str | None): The image decoding backend type. Options are cv2 , pillow , turbojpeg , tifffile , None . If backend is None, the global imread_backend specified by mmcv.use_backend() will be used. Default : None. Returns: ndarray : Loaded image array. Examples: img_path = '/path/to/img.jpg' with open ( img_path , 'rb' ) as f : img_buff = f . read () img = mmcv . imfrombytes ( img_buff ) img = mmcv . imfrombytes ( img_buff , flag = 'color' , channel_order = 'rgb' ) img = mmcv . imfrombytes ( img_buff , backend = 'pillow' ) img = mmcv . imfrombytes ( img_buff , backend = 'cv2' )","title":"function imfrombytes"},{"location":"documents/api.transforms.image.io/#function-imwrite","text":"imwrite ( img , file_path , params = None , auto_mkdir = None , file_client_args = None ) Write image to file. Note: In v1.4.1 and later, add file_client_args parameters. Warning: The parameter auto_mkdir will be deprecated in the future and every file clients will make directory automatically. Args: img (ndarray): Image array to be written. file_path (str): Image file path. params (None or list): Same as opencv :func: imwrite interface. auto_mkdir (bool): If the parent folder of file_path does not exist, whether to create it automatically. It will be deprecated. file_client_args (dict | None): Arguments to instantiate a FileClient. See : class: mmcv.fileio.FileClient for details. Default : None. Returns: bool : Successful or not. Examples: # write to hard disk client ret = mmcv . imwrite ( img , '/path/to/img.jpg' ) # infer the file backend by the prefix s3 ret = mmcv . imwrite ( img , 's3://bucket/img.jpg' ) # manually set the file backend petrel ret = mmcv . imwrite ( img , 's3://bucket/img.jpg' , file_client_args = { # ... 'backend': 'petrel'})","title":"function imwrite"},{"location":"documents/api.transforms.image.io/#function-load","text":"Load ( img_path , prefix = None , to_float32 = False , flag = 'color' , channel_order = 'bgr' , backend = 'cv2' , file_client : FileClient = < ice . llutil . file_client . FileClient object at 0x7fa8a00b3ee0 > ) Args : * flag (str): Flags specifying the color type of a loaded image, candidates are color , grayscale , unchanged , color_ignore_orientation and grayscale_ignore_orientation . By default, cv2 and pillow backend would rotate the image according to its EXIF info unless called with unchanged or *_ignore_orientation flags. turbojpeg and tifffile backend always ignore image's EXIF info regardless of the flag. The turbojpeg backend only supports color and grayscale . * channel_order (str): Order of channel, candidates are bgr and rgb . * backend (str | None): The image decoding backend type. Options are cv2 , pillow , turbojpeg , tifffile , None . If backend is None, the global imread_backend specified by mmcv.use_backend() will be used. Default: None. * file_client : See mmcv.fileio.FileClient for details. References : - [mmseg.datasets.pipelines.LoadImageFromFile](https://mmsegmentation.readthedocs.io/en/latest/api.html#mmseg.datasets.pipelines.LoadImageFromFile) - [mmcv.image.imfrombytes()](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.image.imfrombytes) - [mmcv.image.imread()](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.image.imread)","title":"function Load"},{"location":"documents/api.transforms.image/","text":"module api.transforms.image Global Variables photometric IMREAD_COLOR IMREAD_GRAYSCALE IMREAD_IGNORE_ORIENTATION IMREAD_UNCHANGED TJCS_RGB TJPF_GRAY TJPF_BGR TurboJPEG tifffile jpeg supported_backends imread_flags imread_backend spatial interp_codes","title":"Api.transforms.image"},{"location":"documents/api.transforms.image/#module-apitransformsimage","text":"","title":"module api.transforms.image"},{"location":"documents/api.transforms.image/#global-variables","text":"photometric IMREAD_COLOR IMREAD_GRAYSCALE IMREAD_IGNORE_ORIENTATION IMREAD_UNCHANGED TJCS_RGB TJPF_GRAY TJPF_BGR TurboJPEG tifffile jpeg supported_backends imread_flags imread_backend spatial interp_codes","title":"Global Variables"},{"location":"documents/api.transforms.image.photometric/","text":"module api.transforms.image.photometric function Normalize Normalize ( img , mean , std , to_rgb = True ) Normalize the image and convert BGR2RGB. Args: img (np.ndarray): original image. mean (sequence): Mean values of 3 channels. std (sequence): Std values of 3 channels. to_rgb (bool): Whether to convert the image from BGR to RGB, default is true. Returns: dict : {'img': Normalized results, 'img_norm_cfg': {'mean': ..., 'std': ..., 'to_rgb':...}} function ToTensor ToTensor ( img : ndarray ) Args: img (np.ndarray): (1) transpose (HWC->CHW), (2)to tensor Returns: a torch.Tensor function PhotoMetricDistortion PhotoMetricDistortion ( img , brightness_delta = 32 , contrast_range = ( 0.5 , 1.5 ), saturation_range = ( 0.5 , 1.5 ), hue_delta = 18 ) Apply photometric distortion to image sequentially, every dictprocessation is applied with a probability of 0.5. The position of random contrast is in second or second to last. random brightness random contrast (mode 0) convert color from BGR to HSV random saturation random hue convert color from HSV to BGR random contrast (mode 1) Args: img (np.ndarray): imput image. brightness_delta (int): delta of brightness. contrast_range (tuple): range of contrast. saturation_range (tuple): range of saturation. hue_delta (int): delta of hue. Returns: dict : distorted_image","title":"Api.transforms.image.photometric"},{"location":"documents/api.transforms.image.photometric/#module-apitransformsimagephotometric","text":"","title":"module api.transforms.image.photometric"},{"location":"documents/api.transforms.image.photometric/#function-normalize","text":"Normalize ( img , mean , std , to_rgb = True ) Normalize the image and convert BGR2RGB. Args: img (np.ndarray): original image. mean (sequence): Mean values of 3 channels. std (sequence): Std values of 3 channels. to_rgb (bool): Whether to convert the image from BGR to RGB, default is true. Returns: dict : {'img': Normalized results, 'img_norm_cfg': {'mean': ..., 'std': ..., 'to_rgb':...}}","title":"function Normalize"},{"location":"documents/api.transforms.image.photometric/#function-totensor","text":"ToTensor ( img : ndarray ) Args: img (np.ndarray): (1) transpose (HWC->CHW), (2)to tensor Returns: a torch.Tensor","title":"function ToTensor"},{"location":"documents/api.transforms.image.photometric/#function-photometricdistortion","text":"PhotoMetricDistortion ( img , brightness_delta = 32 , contrast_range = ( 0.5 , 1.5 ), saturation_range = ( 0.5 , 1.5 ), hue_delta = 18 ) Apply photometric distortion to image sequentially, every dictprocessation is applied with a probability of 0.5. The position of random contrast is in second or second to last. random brightness random contrast (mode 0) convert color from BGR to HSV random saturation random hue convert color from HSV to BGR random contrast (mode 1) Args: img (np.ndarray): imput image. brightness_delta (int): delta of brightness. contrast_range (tuple): range of contrast. saturation_range (tuple): range of saturation. hue_delta (int): delta of hue. Returns: dict : distorted_image","title":"function PhotoMetricDistortion"},{"location":"documents/api.transforms.image.spatial/","text":"module api.transforms.image.spatial Global Variables interp_codes function Resize Resize ( src , dsize_w : int = None , dsize_h : int = None , scale : float = None , interpolation : str = 'nearest' , keep_ratio : bool = False , return_scale : bool = False ) Args: src (np.ndarray): The input image to be resized. dsize_w (int, optional): Target width. Higher priority than scale . Defaults to None. dsize_h (int, optional): Target height. Should be assigned if dsize_w is specified. Defaults to None. scale (float, optional): Calculate target size using this scale. Defaults to None. interpolation (str, optional): Interpolation method, accepted values are \"nearest\", \"bilinear\", \"bicubic\", \"area\", \"lanczos\".. Defaults to \"nearest\". keep_ratio (bool, optional): If dsize is specified, the image will be rescaled as large as possible and keep its aspect ratio, and padding redundant areas with zeros. Defaults to False. return_scale (bool, optional): Whether to return actual w_scale and h_scale . Defaults to False. Raises: TypeError : when only one of dsize_w and dsize_h is specified. TypeError : when scale is negative. Returns: tuple | ndarray : ( resized_img , w_scale , h_scale ) or resized_img function Crop Crop ( src : ndarray , roi : Tuple ) crop a region of interest from the src array. Args: src (np.ndarray): source array (H, W) or (H, W, C) roi (Tuple): region of interst (top, bottom, left, right) Returns: np.ndarray : src[top:bottom, left:right, ...] function Flip Flip ( src : ndarray , direction : str = 'horizontal' ) flip the src image. Args: src (np.ndarray): image (H, W) or (H, W, C) direction (str, optional): choose in \"horizontal\" and \"vertical\". Defaults to \"horizontal\". Raises: ValueError : bad direction value Returns: np.ndarray : flipped image. function Pad Pad ( img , dst_w , dst_h , pad_val = 0 , padding_mode = 'constant' ) Padding a image to target size. Args: src (np.ndarray): Source image. dst_w (int): target width. dst_h (int): target height. pad_val (int, optional): padding value to be filled in. Defaults to 0. User should set the value to some value meant to be ignored. padding_mode (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default : constant. - constant: pads with a constant value, this value is specified with pad_val. - edge: pads with the last value at the edge of the image. - reflect: pads with reflection of image without repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode will result in [3, 2, 1, 2, 3, 4, 3, 2]. - symmetric: pads with reflection of image repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode will result in [2, 1, 1, 2, 3, 4, 4, 3] Returns: np.ndarray : padded image. function SizeDivisorMultiple SizeDivisorMultiple ( img = None , w = None , h = None , divisor ) Returns a smallest but larger shape to ensure each edge to be multiple to some number. Args: img (np.ndarray, optional): (H, W) or (H, W, 3), will extract image size if w or h not specified. w (int, optional): original width h (int, optional): original height divisor (int, optional): the returned edge is a multiple of this value. Returns: dict : {\"h\": new_h, \"w\": new_w}","title":"Api.transforms.image.spatial"},{"location":"documents/api.transforms.image.spatial/#module-apitransformsimagespatial","text":"","title":"module api.transforms.image.spatial"},{"location":"documents/api.transforms.image.spatial/#global-variables","text":"interp_codes","title":"Global Variables"},{"location":"documents/api.transforms.image.spatial/#function-resize","text":"Resize ( src , dsize_w : int = None , dsize_h : int = None , scale : float = None , interpolation : str = 'nearest' , keep_ratio : bool = False , return_scale : bool = False ) Args: src (np.ndarray): The input image to be resized. dsize_w (int, optional): Target width. Higher priority than scale . Defaults to None. dsize_h (int, optional): Target height. Should be assigned if dsize_w is specified. Defaults to None. scale (float, optional): Calculate target size using this scale. Defaults to None. interpolation (str, optional): Interpolation method, accepted values are \"nearest\", \"bilinear\", \"bicubic\", \"area\", \"lanczos\".. Defaults to \"nearest\". keep_ratio (bool, optional): If dsize is specified, the image will be rescaled as large as possible and keep its aspect ratio, and padding redundant areas with zeros. Defaults to False. return_scale (bool, optional): Whether to return actual w_scale and h_scale . Defaults to False. Raises: TypeError : when only one of dsize_w and dsize_h is specified. TypeError : when scale is negative. Returns: tuple | ndarray : ( resized_img , w_scale , h_scale ) or resized_img","title":"function Resize"},{"location":"documents/api.transforms.image.spatial/#function-crop","text":"Crop ( src : ndarray , roi : Tuple ) crop a region of interest from the src array. Args: src (np.ndarray): source array (H, W) or (H, W, C) roi (Tuple): region of interst (top, bottom, left, right) Returns: np.ndarray : src[top:bottom, left:right, ...]","title":"function Crop"},{"location":"documents/api.transforms.image.spatial/#function-flip","text":"Flip ( src : ndarray , direction : str = 'horizontal' ) flip the src image. Args: src (np.ndarray): image (H, W) or (H, W, C) direction (str, optional): choose in \"horizontal\" and \"vertical\". Defaults to \"horizontal\". Raises: ValueError : bad direction value Returns: np.ndarray : flipped image.","title":"function Flip"},{"location":"documents/api.transforms.image.spatial/#function-pad","text":"Pad ( img , dst_w , dst_h , pad_val = 0 , padding_mode = 'constant' ) Padding a image to target size. Args: src (np.ndarray): Source image. dst_w (int): target width. dst_h (int): target height. pad_val (int, optional): padding value to be filled in. Defaults to 0. User should set the value to some value meant to be ignored. padding_mode (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default : constant. - constant: pads with a constant value, this value is specified with pad_val. - edge: pads with the last value at the edge of the image. - reflect: pads with reflection of image without repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode will result in [3, 2, 1, 2, 3, 4, 3, 2]. - symmetric: pads with reflection of image repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode will result in [2, 1, 1, 2, 3, 4, 4, 3] Returns: np.ndarray : padded image.","title":"function Pad"},{"location":"documents/api.transforms.image.spatial/#function-sizedivisormultiple","text":"SizeDivisorMultiple ( img = None , w = None , h = None , divisor ) Returns a smallest but larger shape to ensure each edge to be multiple to some number. Args: img (np.ndarray, optional): (H, W) or (H, W, 3), will extract image size if w or h not specified. w (int, optional): original width h (int, optional): original height divisor (int, optional): the returned edge is a multiple of this value. Returns: dict : {\"h\": new_h, \"w\": new_w}","title":"function SizeDivisorMultiple"},{"location":"documents/api.transforms/","text":"module api.transforms Global Variables image semseg random","title":"Api.transforms"},{"location":"documents/api.transforms/#module-apitransforms","text":"","title":"module api.transforms"},{"location":"documents/api.transforms/#global-variables","text":"image semseg random","title":"Global Variables"},{"location":"documents/api.transforms.random/","text":"module api.transforms.random function RandomIntegers RandomIntegers ( low = 0 , high = None , size = None , dtype =< class ' numpy . int64 '>, endpoint = False , tolist = False , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) function RandomFloats RandomFloats ( low = 0.0 , high = 1.0 , size = None , dtype =< class ' numpy . float64 '>, tolist = False , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) function RandomProbabilities RandomProbabilities ( size = None , dtype =< class ' numpy . float64 '>, rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) function RandomChoice RandomChoice ( candidates : List = None , return_index = False , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) function RandomROI RandomROI ( img = None , img_w : int = None , img_h : int = None , roi_h : int , roi_w : int , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) generate random region of interest. Args: roi_h (int): roi height. roi_w (int): roi width. img (np.ndarray, optional): if img_w or img_h is not specified, infer from img . Defaults to None. img_w (int, optional): source image width. Defaults to None. img_h (int, optional): source image height. Defaults to None. rng (np.random.Generator, optional). Returns: Tuple[int] : (top, bottom, left, right) function RandomDo RandomDo ( translist : List [ Callable ], prob : float = 0.5 , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) function RandomImage RandomImage ( img_w = 640 , img_h = 480 , color = True , low = 0 , high = 255 , dtype =< class ' numpy . uint8 '>, rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) generate a random image for testing purpose Args: img_w (int, optional): generated image width. Defaults to 640. img_h (int, optional): generated image height. Defaults to 480. color (bool, optional): if True, return (H, W, 3) else (H, W)-sized iamge. Defaults to True. low (int, optional): minimum pixel value. Defaults to 0. high (int, optional): maximum pixel value. Defaults to 255. dtype (optional): Defaults to np.uint8. rng (optional): np.random.Generator. Defaults to _rng. Returns: np.ndarray : image array (H, W) or (H, W, 3)","title":"Api.transforms.random"},{"location":"documents/api.transforms.random/#module-apitransformsrandom","text":"","title":"module api.transforms.random"},{"location":"documents/api.transforms.random/#function-randomintegers","text":"RandomIntegers ( low = 0 , high = None , size = None , dtype =< class ' numpy . int64 '>, endpoint = False , tolist = False , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 )","title":"function RandomIntegers"},{"location":"documents/api.transforms.random/#function-randomfloats","text":"RandomFloats ( low = 0.0 , high = 1.0 , size = None , dtype =< class ' numpy . float64 '>, tolist = False , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 )","title":"function RandomFloats"},{"location":"documents/api.transforms.random/#function-randomprobabilities","text":"RandomProbabilities ( size = None , dtype =< class ' numpy . float64 '>, rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 )","title":"function RandomProbabilities"},{"location":"documents/api.transforms.random/#function-randomchoice","text":"RandomChoice ( candidates : List = None , return_index = False , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 )","title":"function RandomChoice"},{"location":"documents/api.transforms.random/#function-randomroi","text":"RandomROI ( img = None , img_w : int = None , img_h : int = None , roi_h : int , roi_w : int , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) generate random region of interest. Args: roi_h (int): roi height. roi_w (int): roi width. img (np.ndarray, optional): if img_w or img_h is not specified, infer from img . Defaults to None. img_w (int, optional): source image width. Defaults to None. img_h (int, optional): source image height. Defaults to None. rng (np.random.Generator, optional). Returns: Tuple[int] : (top, bottom, left, right)","title":"function RandomROI"},{"location":"documents/api.transforms.random/#function-randomdo","text":"RandomDo ( translist : List [ Callable ], prob : float = 0.5 , rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 )","title":"function RandomDo"},{"location":"documents/api.transforms.random/#function-randomimage","text":"RandomImage ( img_w = 640 , img_h = 480 , color = True , low = 0 , high = 255 , dtype =< class ' numpy . uint8 '>, rng = Generator ( PCG64 ) at 0x7FA88C0C63C0 ) generate a random image for testing purpose Args: img_w (int, optional): generated image width. Defaults to 640. img_h (int, optional): generated image height. Defaults to 480. color (bool, optional): if True, return (H, W, 3) else (H, W)-sized iamge. Defaults to True. low (int, optional): minimum pixel value. Defaults to 0. high (int, optional): maximum pixel value. Defaults to 255. dtype (optional): Defaults to np.uint8. rng (optional): np.random.Generator. Defaults to _rng. Returns: np.ndarray : image array (H, W) or (H, W, 3)","title":"function RandomImage"},{"location":"documents/api.transforms.semseg/","text":"module api.transforms.semseg function LoadAnnotation LoadAnnotation ( seg_path , prefix = None , label_map = None , reduce_zero_label = False , imdecode_backend = 'pillow' , file_client : FileClient = < ice . llutil . file_client . FileClient object at 0x7fa8a00b3ee0 > ) Load annotations for semantic segmentation. Args : - reduce_zero_label (bool): Whether reduce all label value by 1. Usually used for datasets where 0 is background label. Default: False. - imdecode_backend (str): Backend for `mmcv.imdecode`. Default: 'pillow' - file_client : See [mmcv.fileio.FileClient](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient) for details. References : - [mmseg.datasets.pipelines.LoadAnnotations](https://mmsegmentation.readthedocs.io/en/latest/api.html#mmseg.datasets.pipelines.LoadAnnotations) function RandomCrop RandomCrop ( img = None , seg = None , dst_h : int , dst_w : int , cat_max_ratio = 1.0 , ignore_index = 255 , rng = Generator ( PCG64 ) at 0x7FA88C0C6900 ) Crop a pair of images and segmentation labels such that the class is relatively balanced for training. function LabelToTensor LabelToTensor ( src : ndarray ) Convert to tensor (as int64). Args: src (np.ndarray): (H, W)-shaped integer map. Returns: a torch.Tensor","title":"Api.transforms.semseg"},{"location":"documents/api.transforms.semseg/#module-apitransformssemseg","text":"","title":"module api.transforms.semseg"},{"location":"documents/api.transforms.semseg/#function-loadannotation","text":"LoadAnnotation ( seg_path , prefix = None , label_map = None , reduce_zero_label = False , imdecode_backend = 'pillow' , file_client : FileClient = < ice . llutil . file_client . FileClient object at 0x7fa8a00b3ee0 > ) Load annotations for semantic segmentation. Args : - reduce_zero_label (bool): Whether reduce all label value by 1. Usually used for datasets where 0 is background label. Default: False. - imdecode_backend (str): Backend for `mmcv.imdecode`. Default: 'pillow' - file_client : See [mmcv.fileio.FileClient](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.fileio.FileClient) for details. References : - [mmseg.datasets.pipelines.LoadAnnotations](https://mmsegmentation.readthedocs.io/en/latest/api.html#mmseg.datasets.pipelines.LoadAnnotations)","title":"function LoadAnnotation"},{"location":"documents/api.transforms.semseg/#function-randomcrop","text":"RandomCrop ( img = None , seg = None , dst_h : int , dst_w : int , cat_max_ratio = 1.0 , ignore_index = 255 , rng = Generator ( PCG64 ) at 0x7FA88C0C6900 ) Crop a pair of images and segmentation labels such that the class is relatively balanced for training.","title":"function RandomCrop"},{"location":"documents/api.transforms.semseg/#function-labeltotensor","text":"LabelToTensor ( src : ndarray ) Convert to tensor (as int64). Args: src (np.ndarray): (H, W)-shaped integer map. Returns: a torch.Tensor","title":"function LabelToTensor"},{"location":"documents/api.utils/","text":"module api.utils function parse_devices parse_devices ( devices : str )","title":"Api.utils"},{"location":"documents/api.utils/#module-apiutils","text":"","title":"module api.utils"},{"location":"documents/api.utils/#function-parse_devices","text":"parse_devices ( devices : str )","title":"function parse_devices"},{"location":"documents/core.dataset/","text":"module core.dataset Global Variables string_classes function failsafe_collate failsafe_collate ( batch ) Puts each data field into a tensor with outer dimension batch size class ResumableDistributedSampler method __init__ __init__ ( dataset : Dataset , num_replicas : Optional [ int ] = None , rank : Optional [ int ] = None , shuffle : bool = True , seed : int = 0 , drop_last : bool = False , num_iters : int = None ) \u2192 None property indices method set_start_batch_idx set_start_batch_idx ( i ) class DatasetNode Automating DataLoader and DataSampler creation and maintainance. method __init__ __init__ ( * args , ** kwds ) \u2192 None property board property device the assigned device by current launcher. property epoch_size property epoch_steps property global_auto_steps property global_train_epochs property global_train_steps property grad_acc_steps property grad_scaler property launcher property name the node name in the current activated ExecutableGraph . property out_dir property run_id property step_mode whether current task is running by step (True) or by epoch (False). property task property training whether current task is training. method forward_impl forward_impl ( _ ) method load_state_dict load_state_dict ( _state_dict : Dict , strict : bool = None ) method state_dict state_dict () \u2192 Dict","title":"Core.dataset"},{"location":"documents/core.dataset/#module-coredataset","text":"","title":"module core.dataset"},{"location":"documents/core.dataset/#global-variables","text":"string_classes","title":"Global Variables"},{"location":"documents/core.dataset/#function-failsafe_collate","text":"failsafe_collate ( batch ) Puts each data field into a tensor with outer dimension batch size","title":"function failsafe_collate"},{"location":"documents/core.dataset/#class-resumabledistributedsampler","text":"","title":"class ResumableDistributedSampler"},{"location":"documents/core.dataset/#method-__init__","text":"__init__ ( dataset : Dataset , num_replicas : Optional [ int ] = None , rank : Optional [ int ] = None , shuffle : bool = True , seed : int = 0 , drop_last : bool = False , num_iters : int = None ) \u2192 None","title":"method __init__"},{"location":"documents/core.dataset/#property-indices","text":"","title":"property indices"},{"location":"documents/core.dataset/#method-set_start_batch_idx","text":"set_start_batch_idx ( i )","title":"method set_start_batch_idx"},{"location":"documents/core.dataset/#class-datasetnode","text":"Automating DataLoader and DataSampler creation and maintainance.","title":"class DatasetNode"},{"location":"documents/core.dataset/#method-__init___1","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/core.dataset/#property-board","text":"","title":"property board"},{"location":"documents/core.dataset/#property-device","text":"the assigned device by current launcher.","title":"property device"},{"location":"documents/core.dataset/#property-epoch_size","text":"","title":"property epoch_size"},{"location":"documents/core.dataset/#property-epoch_steps","text":"","title":"property epoch_steps"},{"location":"documents/core.dataset/#property-global_auto_steps","text":"","title":"property global_auto_steps"},{"location":"documents/core.dataset/#property-global_train_epochs","text":"","title":"property global_train_epochs"},{"location":"documents/core.dataset/#property-global_train_steps","text":"","title":"property global_train_steps"},{"location":"documents/core.dataset/#property-grad_acc_steps","text":"","title":"property grad_acc_steps"},{"location":"documents/core.dataset/#property-grad_scaler","text":"","title":"property grad_scaler"},{"location":"documents/core.dataset/#property-launcher","text":"","title":"property launcher"},{"location":"documents/core.dataset/#property-name","text":"the node name in the current activated ExecutableGraph .","title":"property name"},{"location":"documents/core.dataset/#property-out_dir","text":"","title":"property out_dir"},{"location":"documents/core.dataset/#property-run_id","text":"","title":"property run_id"},{"location":"documents/core.dataset/#property-step_mode","text":"whether current task is running by step (True) or by epoch (False).","title":"property step_mode"},{"location":"documents/core.dataset/#property-task","text":"","title":"property task"},{"location":"documents/core.dataset/#property-training","text":"whether current task is training.","title":"property training"},{"location":"documents/core.dataset/#method-forward_impl","text":"forward_impl ( _ )","title":"method forward_impl"},{"location":"documents/core.dataset/#method-load_state_dict","text":"load_state_dict ( _state_dict : Dict , strict : bool = None )","title":"method load_state_dict"},{"location":"documents/core.dataset/#method-state_dict","text":"state_dict () \u2192 Dict","title":"method state_dict"},{"location":"documents/core.graph/","text":"module core.graph contains Node and ExecutableGraph . class InvalidURIError An Exception raised when valid node URI is expected. class StopTask An Exception raised to exit current task. class StopAllTasks An Exception raised to exit current running. class Node This class defines the executable node. A executable graph is defined by a collection of executable nodes and their dependency relationships. A node is executable if it has at least following phases of execution: forward , backward , update . Different subclass of nodes may implement them differently. This class is designed to be executed easily in batch mode (see ExecutableGraph.apply() for details), so that a bunch of nodes can execute together, respecting several synchronization points between phases. The dependency relationship is determined at runtime by how user access the graph argument of Node.forward() function. The graph argument is actually a cache (a GraphOutputCache instance) of the graph nodes outputs. The results of precedent nodes will be saved in the cache, so dependents can retrieve them easily. method __init__ __init__ ( * args , ** kwds ) \u2192 None property board property device the assigned device by current launcher. property epoch_size property epoch_steps property global_auto_steps property global_train_epochs property global_train_steps property grad_acc_steps property grad_scaler property launcher property name the node name in the current activated ExecutableGraph . property out_dir property run_id property step_mode whether current task is running by step (True) or by epoch (False). property task property training whether current task is training. method backward backward () calculates gradients. method clean_up clean_up () an event hook for clean up all resources at switching executable graphs. method dry_run dry_run () only update states about progress. method epoch_end epoch_end () an event hook for epoch end. (only for epoch mode) method epoch_start epoch_start () an event hook for epoch start. (only for epoch mode) method forward forward () retrieves forward output in cache or calculates it using forward_impl and save the output to the cache. Subclasses should not override this method. method forward_impl forward_impl ( cache : 'GraphOutputCache' ) forward pass of the node, inputs of current executable graph can be directly retrieved from graph argument. method load_state_dict load_state_dict ( _state_dict : Dict , strict : bool ) resumes node state from state_dict. method move move ( data , device = None ) method prepare prepare () an event hook for prepare all resources at switching executable graphs. method state_dict state_dict () \u2192 Dict returns serialization of current node. method update update () update parameters or buffers, e.g. using SGD based optimizer to update parameters. class GraphOutputCache method __init__ __init__ ( egraph : 'ExecutableGraph' ) \u2192 None method __getitem__ __getitem__ ( name ) Execute node with name name if not executed, return the last executed cache else. method clear clear () Clear the cache, next calls to __getitem__ will recalculate. class ExecutableGraph method __init__ __init__ ( hypergraph ) \u2192 None property grad_scaler method add_node add_node ( node_name , node , tags ) method apply apply ( method : str , * args , filter : Callable [[ Node ], bool ] = lambda _ : True ,, ** kwds ) method clean_up_nodes clean_up_nodes () method items items () method iterate iterate () method prepare_nodes prepare_nodes ()","title":"Core.graph"},{"location":"documents/core.graph/#module-coregraph","text":"contains Node and ExecutableGraph .","title":"module core.graph"},{"location":"documents/core.graph/#class-invalidurierror","text":"An Exception raised when valid node URI is expected.","title":"class InvalidURIError"},{"location":"documents/core.graph/#class-stoptask","text":"An Exception raised to exit current task.","title":"class StopTask"},{"location":"documents/core.graph/#class-stopalltasks","text":"An Exception raised to exit current running.","title":"class StopAllTasks"},{"location":"documents/core.graph/#class-node","text":"This class defines the executable node. A executable graph is defined by a collection of executable nodes and their dependency relationships. A node is executable if it has at least following phases of execution: forward , backward , update . Different subclass of nodes may implement them differently. This class is designed to be executed easily in batch mode (see ExecutableGraph.apply() for details), so that a bunch of nodes can execute together, respecting several synchronization points between phases. The dependency relationship is determined at runtime by how user access the graph argument of Node.forward() function. The graph argument is actually a cache (a GraphOutputCache instance) of the graph nodes outputs. The results of precedent nodes will be saved in the cache, so dependents can retrieve them easily.","title":"class Node"},{"location":"documents/core.graph/#method-__init__","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/core.graph/#property-board","text":"","title":"property board"},{"location":"documents/core.graph/#property-device","text":"the assigned device by current launcher.","title":"property device"},{"location":"documents/core.graph/#property-epoch_size","text":"","title":"property epoch_size"},{"location":"documents/core.graph/#property-epoch_steps","text":"","title":"property epoch_steps"},{"location":"documents/core.graph/#property-global_auto_steps","text":"","title":"property global_auto_steps"},{"location":"documents/core.graph/#property-global_train_epochs","text":"","title":"property global_train_epochs"},{"location":"documents/core.graph/#property-global_train_steps","text":"","title":"property global_train_steps"},{"location":"documents/core.graph/#property-grad_acc_steps","text":"","title":"property grad_acc_steps"},{"location":"documents/core.graph/#property-grad_scaler","text":"","title":"property grad_scaler"},{"location":"documents/core.graph/#property-launcher","text":"","title":"property launcher"},{"location":"documents/core.graph/#property-name","text":"the node name in the current activated ExecutableGraph .","title":"property name"},{"location":"documents/core.graph/#property-out_dir","text":"","title":"property out_dir"},{"location":"documents/core.graph/#property-run_id","text":"","title":"property run_id"},{"location":"documents/core.graph/#property-step_mode","text":"whether current task is running by step (True) or by epoch (False).","title":"property step_mode"},{"location":"documents/core.graph/#property-task","text":"","title":"property task"},{"location":"documents/core.graph/#property-training","text":"whether current task is training.","title":"property training"},{"location":"documents/core.graph/#method-backward","text":"backward () calculates gradients.","title":"method backward"},{"location":"documents/core.graph/#method-clean_up","text":"clean_up () an event hook for clean up all resources at switching executable graphs.","title":"method clean_up"},{"location":"documents/core.graph/#method-dry_run","text":"dry_run () only update states about progress.","title":"method dry_run"},{"location":"documents/core.graph/#method-epoch_end","text":"epoch_end () an event hook for epoch end. (only for epoch mode)","title":"method epoch_end"},{"location":"documents/core.graph/#method-epoch_start","text":"epoch_start () an event hook for epoch start. (only for epoch mode)","title":"method epoch_start"},{"location":"documents/core.graph/#method-forward","text":"forward () retrieves forward output in cache or calculates it using forward_impl and save the output to the cache. Subclasses should not override this method.","title":"method forward"},{"location":"documents/core.graph/#method-forward_impl","text":"forward_impl ( cache : 'GraphOutputCache' ) forward pass of the node, inputs of current executable graph can be directly retrieved from graph argument.","title":"method forward_impl"},{"location":"documents/core.graph/#method-load_state_dict","text":"load_state_dict ( _state_dict : Dict , strict : bool ) resumes node state from state_dict.","title":"method load_state_dict"},{"location":"documents/core.graph/#method-move","text":"move ( data , device = None )","title":"method move"},{"location":"documents/core.graph/#method-prepare","text":"prepare () an event hook for prepare all resources at switching executable graphs.","title":"method prepare"},{"location":"documents/core.graph/#method-state_dict","text":"state_dict () \u2192 Dict returns serialization of current node.","title":"method state_dict"},{"location":"documents/core.graph/#method-update","text":"update () update parameters or buffers, e.g. using SGD based optimizer to update parameters.","title":"method update"},{"location":"documents/core.graph/#class-graphoutputcache","text":"","title":"class GraphOutputCache"},{"location":"documents/core.graph/#method-__init___1","text":"__init__ ( egraph : 'ExecutableGraph' ) \u2192 None","title":"method __init__"},{"location":"documents/core.graph/#method-__getitem__","text":"__getitem__ ( name ) Execute node with name name if not executed, return the last executed cache else.","title":"method __getitem__"},{"location":"documents/core.graph/#method-clear","text":"clear () Clear the cache, next calls to __getitem__ will recalculate.","title":"method clear"},{"location":"documents/core.graph/#class-executablegraph","text":"","title":"class ExecutableGraph"},{"location":"documents/core.graph/#method-__init___2","text":"__init__ ( hypergraph ) \u2192 None","title":"method __init__"},{"location":"documents/core.graph/#property-grad_scaler_1","text":"","title":"property grad_scaler"},{"location":"documents/core.graph/#method-add_node","text":"add_node ( node_name , node , tags )","title":"method add_node"},{"location":"documents/core.graph/#method-apply","text":"apply ( method : str , * args , filter : Callable [[ Node ], bool ] = lambda _ : True ,, ** kwds )","title":"method apply"},{"location":"documents/core.graph/#method-clean_up_nodes","text":"clean_up_nodes ()","title":"method clean_up_nodes"},{"location":"documents/core.graph/#method-items","text":"items ()","title":"method items"},{"location":"documents/core.graph/#method-iterate","text":"iterate ()","title":"method iterate"},{"location":"documents/core.graph/#method-prepare_nodes","text":"prepare_nodes ()","title":"method prepare_nodes"},{"location":"documents/core.hypergraph/","text":"module core.hypergraph Global Variables global_shared_events function LoadCheckpointTask LoadCheckpointTask ( resume_from , strict = False , tags = '*' ) function SaveCheckpointTask SaveCheckpointTask ( save_to = None , tags = '*' ) class ResumeTaskFailed raised when task structure does not match during resuming. class Task method __init__ __init__ ( * args , ** kwds ) \u2192 None property global_auto_epochs property global_auto_steps method load_state_dict load_state_dict ( _state_dict , dry_run = False ) method state_dict state_dict () class Repeat method __init__ __init__ ( * args , ** kwds ) \u2192 None method load_state_dict load_state_dict ( _state_dict , dry_run = False ) method state_dict state_dict () class Counter method __init__ __init__ () \u2192 None property total class GlobalCounters GlobalCounters(steps: core.hypergraph.Counter = , epochs: core.hypergraph.Counter = ) function __init__ __init__ ( steps : Counter = < core . hypergraph . Counter object at 0x7fa8819b32e0 > , epochs : Counter = < core . hypergraph . Counter object at 0x7fa8819b3c40 > ) \u2192 None class HyperGraph HyperGraph is the container for all nodes. method __init__ __init__ ( autocast_enabled = False , autocast_dtype = torch . float16 , grad_scaler : Union [ bool , GradScaler ] = None ) \u2192 None property launcher method add add ( name , node : Node , tags = '*' ) method backup_source_files backup_source_files ( entrypoint : str ) method exec_tasks exec_tasks ( tasks , launcher : ElasticLauncher ) method init_autocast init_autocast ( autocast_enabled = True , autocast_dtype = torch . float16 , grad_scaler : Union [ bool , GradScaler ] = None ) method init_grad_scaler init_grad_scaler ( self , grad_scaler : Union [ bool , GradScaler ] = False , * , init_scale = 2.0 ** 16 , growth_factor = 2.0 , backoff_factor = 0.5 , growth_interval = 2000 , enabled = True ) Ellipsis method is_autocast_enabled is_autocast_enabled () \u2192 bool method is_grad_scaler_enabled is_grad_scaler_enabled () \u2192 bool method load_checkpoint load_checkpoint ( resume_from , strict = False , tags = '*' ) method print_forward_output print_forward_output ( * nodenames , every = 1 , total = None , tags : List [ str ] = '*' , train_only = True , localrank0_only = True ) method remove remove ( query ) method run run ( self , tasks , devices = 'auto' , run_id : str = 'none' , out_dir : str = None , resume_from : str = None , seed = 0 ) Ellipsis method run run ( self , tasks , launcher : ElasticLauncher = None , run_id : str = 'none' , out_dir : str = None , resume_from : str = None , seed = 0 ) Ellipsis method run run ( self , tasks , devices = 'auto' , run_id = 'none' , nnodes = '1:1' , dist_backend = 'auto' , monitor_interval = 5 , node_rank = 0 , master_addr = '127.0.0.1' , master_port = None , redirects = '2' , tee = '1' , out_dir = None , resume_from = None , seed = 0 , role = 'default' , max_restarts = 0 , omp_num_threads = 1 , start_method = 'spawn' ) Ellipsis method run run ( self , tasks , devices = 'auto' , run_id = 'none' , nnodes = '1:1' , dist_backend = 'auto' , monitor_interval = 5 , rdzv_endpoint = '' , rdzv_backend = 'static' , rdzv_configs = '' , standalone = False , redirects = '2' , tee = '1' , out_dir = None , resume_from = None , seed = 0 , role = 'default' , max_restarts = 0 , omp_num_threads = 1 , start_method = 'spawn' ) Ellipsis method save_checkpoint save_checkpoint ( save_to = None , tags = '*' ) method select_egraph select_egraph ( query ) \u2192 ExecutableGraph method select_nodes select_nodes ( * query ) method set_gradient_accumulate set_gradient_accumulate ( every = 1 )","title":"Core.hypergraph"},{"location":"documents/core.hypergraph/#module-corehypergraph","text":"","title":"module core.hypergraph"},{"location":"documents/core.hypergraph/#global-variables","text":"global_shared_events","title":"Global Variables"},{"location":"documents/core.hypergraph/#function-loadcheckpointtask","text":"LoadCheckpointTask ( resume_from , strict = False , tags = '*' )","title":"function LoadCheckpointTask"},{"location":"documents/core.hypergraph/#function-savecheckpointtask","text":"SaveCheckpointTask ( save_to = None , tags = '*' )","title":"function SaveCheckpointTask"},{"location":"documents/core.hypergraph/#class-resumetaskfailed","text":"raised when task structure does not match during resuming.","title":"class ResumeTaskFailed"},{"location":"documents/core.hypergraph/#class-task","text":"","title":"class Task"},{"location":"documents/core.hypergraph/#method-__init__","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/core.hypergraph/#property-global_auto_epochs","text":"","title":"property global_auto_epochs"},{"location":"documents/core.hypergraph/#property-global_auto_steps","text":"","title":"property global_auto_steps"},{"location":"documents/core.hypergraph/#method-load_state_dict","text":"load_state_dict ( _state_dict , dry_run = False )","title":"method load_state_dict"},{"location":"documents/core.hypergraph/#method-state_dict","text":"state_dict ()","title":"method state_dict"},{"location":"documents/core.hypergraph/#class-repeat","text":"","title":"class Repeat"},{"location":"documents/core.hypergraph/#method-__init___1","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/core.hypergraph/#method-load_state_dict_1","text":"load_state_dict ( _state_dict , dry_run = False )","title":"method load_state_dict"},{"location":"documents/core.hypergraph/#method-state_dict_1","text":"state_dict ()","title":"method state_dict"},{"location":"documents/core.hypergraph/#class-counter","text":"","title":"class Counter"},{"location":"documents/core.hypergraph/#method-__init___2","text":"__init__ () \u2192 None","title":"method __init__"},{"location":"documents/core.hypergraph/#property-total","text":"","title":"property total"},{"location":"documents/core.hypergraph/#class-globalcounters","text":"GlobalCounters(steps: core.hypergraph.Counter = , epochs: core.hypergraph.Counter = )","title":"class GlobalCounters"},{"location":"documents/core.hypergraph/#function-__init__","text":"__init__ ( steps : Counter = < core . hypergraph . Counter object at 0x7fa8819b32e0 > , epochs : Counter = < core . hypergraph . Counter object at 0x7fa8819b3c40 > ) \u2192 None","title":"function __init__"},{"location":"documents/core.hypergraph/#class-hypergraph","text":"HyperGraph is the container for all nodes.","title":"class HyperGraph"},{"location":"documents/core.hypergraph/#method-__init___3","text":"__init__ ( autocast_enabled = False , autocast_dtype = torch . float16 , grad_scaler : Union [ bool , GradScaler ] = None ) \u2192 None","title":"method __init__"},{"location":"documents/core.hypergraph/#property-launcher","text":"","title":"property launcher"},{"location":"documents/core.hypergraph/#method-add","text":"add ( name , node : Node , tags = '*' )","title":"method add"},{"location":"documents/core.hypergraph/#method-backup_source_files","text":"backup_source_files ( entrypoint : str )","title":"method backup_source_files"},{"location":"documents/core.hypergraph/#method-exec_tasks","text":"exec_tasks ( tasks , launcher : ElasticLauncher )","title":"method exec_tasks"},{"location":"documents/core.hypergraph/#method-init_autocast","text":"init_autocast ( autocast_enabled = True , autocast_dtype = torch . float16 , grad_scaler : Union [ bool , GradScaler ] = None )","title":"method init_autocast"},{"location":"documents/core.hypergraph/#method-init_grad_scaler","text":"init_grad_scaler ( self , grad_scaler : Union [ bool , GradScaler ] = False , * , init_scale = 2.0 ** 16 , growth_factor = 2.0 , backoff_factor = 0.5 , growth_interval = 2000 , enabled = True ) Ellipsis","title":"method init_grad_scaler"},{"location":"documents/core.hypergraph/#method-is_autocast_enabled","text":"is_autocast_enabled () \u2192 bool","title":"method is_autocast_enabled"},{"location":"documents/core.hypergraph/#method-is_grad_scaler_enabled","text":"is_grad_scaler_enabled () \u2192 bool","title":"method is_grad_scaler_enabled"},{"location":"documents/core.hypergraph/#method-load_checkpoint","text":"load_checkpoint ( resume_from , strict = False , tags = '*' )","title":"method load_checkpoint"},{"location":"documents/core.hypergraph/#method-print_forward_output","text":"print_forward_output ( * nodenames , every = 1 , total = None , tags : List [ str ] = '*' , train_only = True , localrank0_only = True )","title":"method print_forward_output"},{"location":"documents/core.hypergraph/#method-remove","text":"remove ( query )","title":"method remove"},{"location":"documents/core.hypergraph/#method-run","text":"run ( self , tasks , devices = 'auto' , run_id : str = 'none' , out_dir : str = None , resume_from : str = None , seed = 0 ) Ellipsis","title":"method run"},{"location":"documents/core.hypergraph/#method-run_1","text":"run ( self , tasks , launcher : ElasticLauncher = None , run_id : str = 'none' , out_dir : str = None , resume_from : str = None , seed = 0 ) Ellipsis","title":"method run"},{"location":"documents/core.hypergraph/#method-run_2","text":"run ( self , tasks , devices = 'auto' , run_id = 'none' , nnodes = '1:1' , dist_backend = 'auto' , monitor_interval = 5 , node_rank = 0 , master_addr = '127.0.0.1' , master_port = None , redirects = '2' , tee = '1' , out_dir = None , resume_from = None , seed = 0 , role = 'default' , max_restarts = 0 , omp_num_threads = 1 , start_method = 'spawn' ) Ellipsis","title":"method run"},{"location":"documents/core.hypergraph/#method-run_3","text":"run ( self , tasks , devices = 'auto' , run_id = 'none' , nnodes = '1:1' , dist_backend = 'auto' , monitor_interval = 5 , rdzv_endpoint = '' , rdzv_backend = 'static' , rdzv_configs = '' , standalone = False , redirects = '2' , tee = '1' , out_dir = None , resume_from = None , seed = 0 , role = 'default' , max_restarts = 0 , omp_num_threads = 1 , start_method = 'spawn' ) Ellipsis","title":"method run"},{"location":"documents/core.hypergraph/#method-save_checkpoint","text":"save_checkpoint ( save_to = None , tags = '*' )","title":"method save_checkpoint"},{"location":"documents/core.hypergraph/#method-select_egraph","text":"select_egraph ( query ) \u2192 ExecutableGraph","title":"method select_egraph"},{"location":"documents/core.hypergraph/#method-select_nodes","text":"select_nodes ( * query )","title":"method select_nodes"},{"location":"documents/core.hypergraph/#method-set_gradient_accumulate","text":"set_gradient_accumulate ( every = 1 )","title":"method set_gradient_accumulate"},{"location":"documents/core.loss/","text":"module core.loss class LossMode An enumeration. class LossNode method __init__ __init__ ( * args , ** kwds ) property board property device the assigned device by current launcher. property epoch_size property epoch_steps property global_auto_steps property global_train_epochs property global_train_steps property grad_acc_steps property grad_scaler property launcher property name the node name in the current activated ExecutableGraph . property out_dir property run_id property step_mode whether current task is running by step (True) or by epoch (False). property task property training whether current task is training. method backward backward () method forward_impl forward_impl ( cache : 'GraphOutputCache' )","title":"Core.loss"},{"location":"documents/core.loss/#module-coreloss","text":"","title":"module core.loss"},{"location":"documents/core.loss/#class-lossmode","text":"An enumeration.","title":"class LossMode"},{"location":"documents/core.loss/#class-lossnode","text":"","title":"class LossNode"},{"location":"documents/core.loss/#method-__init__","text":"__init__ ( * args , ** kwds )","title":"method __init__"},{"location":"documents/core.loss/#property-board","text":"","title":"property board"},{"location":"documents/core.loss/#property-device","text":"the assigned device by current launcher.","title":"property device"},{"location":"documents/core.loss/#property-epoch_size","text":"","title":"property epoch_size"},{"location":"documents/core.loss/#property-epoch_steps","text":"","title":"property epoch_steps"},{"location":"documents/core.loss/#property-global_auto_steps","text":"","title":"property global_auto_steps"},{"location":"documents/core.loss/#property-global_train_epochs","text":"","title":"property global_train_epochs"},{"location":"documents/core.loss/#property-global_train_steps","text":"","title":"property global_train_steps"},{"location":"documents/core.loss/#property-grad_acc_steps","text":"","title":"property grad_acc_steps"},{"location":"documents/core.loss/#property-grad_scaler","text":"","title":"property grad_scaler"},{"location":"documents/core.loss/#property-launcher","text":"","title":"property launcher"},{"location":"documents/core.loss/#property-name","text":"the node name in the current activated ExecutableGraph .","title":"property name"},{"location":"documents/core.loss/#property-out_dir","text":"","title":"property out_dir"},{"location":"documents/core.loss/#property-run_id","text":"","title":"property run_id"},{"location":"documents/core.loss/#property-step_mode","text":"whether current task is running by step (True) or by epoch (False).","title":"property step_mode"},{"location":"documents/core.loss/#property-task","text":"","title":"property task"},{"location":"documents/core.loss/#property-training","text":"whether current task is training.","title":"property training"},{"location":"documents/core.loss/#method-backward","text":"backward ()","title":"method backward"},{"location":"documents/core.loss/#method-forward_impl","text":"forward_impl ( cache : 'GraphOutputCache' )","title":"method forward_impl"},{"location":"documents/core.metric/","text":"module core.metric class Meter value reducer that works recursively. method evaluate evaluate ( * args , ** kwds ) method reset reset () method sync sync () method update update ( value , * args ) class DictMetric method __init__ __init__ ( meters = None , meter_prototype = None ) method evaluate evaluate ( * args , ** kwds ) method reset reset () method sync sync () method update update ( explicit = {}, * shared_args , ** kwds ) class MetricNode method __init__ __init__ ( * args , ** kwds ) property board property device the assigned device by current launcher. property epoch_size property epoch_steps property global_auto_steps property global_train_epochs property global_train_steps property grad_acc_steps property grad_scaler property launcher property name the node name in the current activated ExecutableGraph . property out_dir property run_id property step_mode whether current task is running by step (True) or by epoch (False). property task property training whether current task is training. method better better ( new_value ) \u2192 bool method epoch_end epoch_end () method epoch_start epoch_start () method tensorboard_log_metric tensorboard_log_metric ( postfix = '' ) method update update () class ValueMeter method evaluate evaluate () method reset reset () method sync sync () method update update ( value : Tensor ) class SummationMeter method evaluate evaluate () method reset reset () method sync sync () method update update ( batch_sum : Tensor ) class AverageMeter method evaluate evaluate () method reset reset () method sync sync () method update update ( batch_avg : Tensor , count : int = 1 ) class MovingAverageMeter method __init__ __init__ ( window_size : int ) \u2192 None method evaluate evaluate () method reset reset () method sync sync () method update update ( * values )","title":"Core.metric"},{"location":"documents/core.metric/#module-coremetric","text":"","title":"module core.metric"},{"location":"documents/core.metric/#class-meter","text":"value reducer that works recursively.","title":"class Meter"},{"location":"documents/core.metric/#method-evaluate","text":"evaluate ( * args , ** kwds )","title":"method evaluate"},{"location":"documents/core.metric/#method-reset","text":"reset ()","title":"method reset"},{"location":"documents/core.metric/#method-sync","text":"sync ()","title":"method sync"},{"location":"documents/core.metric/#method-update","text":"update ( value , * args )","title":"method update"},{"location":"documents/core.metric/#class-dictmetric","text":"","title":"class DictMetric"},{"location":"documents/core.metric/#method-__init__","text":"__init__ ( meters = None , meter_prototype = None )","title":"method __init__"},{"location":"documents/core.metric/#method-evaluate_1","text":"evaluate ( * args , ** kwds )","title":"method evaluate"},{"location":"documents/core.metric/#method-reset_1","text":"reset ()","title":"method reset"},{"location":"documents/core.metric/#method-sync_1","text":"sync ()","title":"method sync"},{"location":"documents/core.metric/#method-update_1","text":"update ( explicit = {}, * shared_args , ** kwds )","title":"method update"},{"location":"documents/core.metric/#class-metricnode","text":"","title":"class MetricNode"},{"location":"documents/core.metric/#method-__init___1","text":"__init__ ( * args , ** kwds )","title":"method __init__"},{"location":"documents/core.metric/#property-board","text":"","title":"property board"},{"location":"documents/core.metric/#property-device","text":"the assigned device by current launcher.","title":"property device"},{"location":"documents/core.metric/#property-epoch_size","text":"","title":"property epoch_size"},{"location":"documents/core.metric/#property-epoch_steps","text":"","title":"property epoch_steps"},{"location":"documents/core.metric/#property-global_auto_steps","text":"","title":"property global_auto_steps"},{"location":"documents/core.metric/#property-global_train_epochs","text":"","title":"property global_train_epochs"},{"location":"documents/core.metric/#property-global_train_steps","text":"","title":"property global_train_steps"},{"location":"documents/core.metric/#property-grad_acc_steps","text":"","title":"property grad_acc_steps"},{"location":"documents/core.metric/#property-grad_scaler","text":"","title":"property grad_scaler"},{"location":"documents/core.metric/#property-launcher","text":"","title":"property launcher"},{"location":"documents/core.metric/#property-name","text":"the node name in the current activated ExecutableGraph .","title":"property name"},{"location":"documents/core.metric/#property-out_dir","text":"","title":"property out_dir"},{"location":"documents/core.metric/#property-run_id","text":"","title":"property run_id"},{"location":"documents/core.metric/#property-step_mode","text":"whether current task is running by step (True) or by epoch (False).","title":"property step_mode"},{"location":"documents/core.metric/#property-task","text":"","title":"property task"},{"location":"documents/core.metric/#property-training","text":"whether current task is training.","title":"property training"},{"location":"documents/core.metric/#method-better","text":"better ( new_value ) \u2192 bool","title":"method better"},{"location":"documents/core.metric/#method-epoch_end","text":"epoch_end ()","title":"method epoch_end"},{"location":"documents/core.metric/#method-epoch_start","text":"epoch_start ()","title":"method epoch_start"},{"location":"documents/core.metric/#method-tensorboard_log_metric","text":"tensorboard_log_metric ( postfix = '' )","title":"method tensorboard_log_metric"},{"location":"documents/core.metric/#method-update_2","text":"update ()","title":"method update"},{"location":"documents/core.metric/#class-valuemeter","text":"","title":"class ValueMeter"},{"location":"documents/core.metric/#method-evaluate_2","text":"evaluate ()","title":"method evaluate"},{"location":"documents/core.metric/#method-reset_2","text":"reset ()","title":"method reset"},{"location":"documents/core.metric/#method-sync_2","text":"sync ()","title":"method sync"},{"location":"documents/core.metric/#method-update_3","text":"update ( value : Tensor )","title":"method update"},{"location":"documents/core.metric/#class-summationmeter","text":"","title":"class SummationMeter"},{"location":"documents/core.metric/#method-evaluate_3","text":"evaluate ()","title":"method evaluate"},{"location":"documents/core.metric/#method-reset_3","text":"reset ()","title":"method reset"},{"location":"documents/core.metric/#method-sync_3","text":"sync ()","title":"method sync"},{"location":"documents/core.metric/#method-update_4","text":"update ( batch_sum : Tensor )","title":"method update"},{"location":"documents/core.metric/#class-averagemeter","text":"","title":"class AverageMeter"},{"location":"documents/core.metric/#method-evaluate_4","text":"evaluate ()","title":"method evaluate"},{"location":"documents/core.metric/#method-reset_4","text":"reset ()","title":"method reset"},{"location":"documents/core.metric/#method-sync_4","text":"sync ()","title":"method sync"},{"location":"documents/core.metric/#method-update_5","text":"update ( batch_avg : Tensor , count : int = 1 )","title":"method update"},{"location":"documents/core.metric/#class-movingaveragemeter","text":"","title":"class MovingAverageMeter"},{"location":"documents/core.metric/#method-__init___2","text":"__init__ ( window_size : int ) \u2192 None","title":"method __init__"},{"location":"documents/core.metric/#method-evaluate_5","text":"evaluate ()","title":"method evaluate"},{"location":"documents/core.metric/#method-reset_5","text":"reset ()","title":"method reset"},{"location":"documents/core.metric/#method-sync_5","text":"sync ()","title":"method sync"},{"location":"documents/core.metric/#method-update_6","text":"update ( * values )","title":"method update"},{"location":"documents/core.module/","text":"module core.module class ModuleNode a node that extends torch.nn.Module ModuleNode manages neural network modules ( torch.nn.Module ) and the optimizers responsible to train them. For each ModuleNode , multiple optimizers can be specified, each of which can be responsible for different group of parameters by filtering parameters names. Multiple ModelNode with different training configuration under differnt tags can share a same torch.nn.Module . method __init__ __init__ ( * args , ** kwds ) \u2192 None property board property device the assigned device by current launcher. property epoch_size property epoch_steps property global_auto_steps property global_train_epochs property global_train_steps property grad_acc_steps property grad_scaler property launcher property name the node name in the current activated ExecutableGraph . property out_dir property run_id property step_mode whether current task is running by step (True) or by epoch (False). property task property training whether current task is training. method epoch_end epoch_end () method epoch_start epoch_start () method forward_impl forward_impl ( cache : 'GraphOutputCache' ) method load_state_dict load_state_dict ( _state_dict : Dict , strict : bool ) method prepare prepare () method state_dict state_dict () method update update ()","title":"Core.module"},{"location":"documents/core.module/#module-coremodule","text":"","title":"module core.module"},{"location":"documents/core.module/#class-modulenode","text":"a node that extends torch.nn.Module ModuleNode manages neural network modules ( torch.nn.Module ) and the optimizers responsible to train them. For each ModuleNode , multiple optimizers can be specified, each of which can be responsible for different group of parameters by filtering parameters names. Multiple ModelNode with different training configuration under differnt tags can share a same torch.nn.Module .","title":"class ModuleNode"},{"location":"documents/core.module/#method-__init__","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/core.module/#property-board","text":"","title":"property board"},{"location":"documents/core.module/#property-device","text":"the assigned device by current launcher.","title":"property device"},{"location":"documents/core.module/#property-epoch_size","text":"","title":"property epoch_size"},{"location":"documents/core.module/#property-epoch_steps","text":"","title":"property epoch_steps"},{"location":"documents/core.module/#property-global_auto_steps","text":"","title":"property global_auto_steps"},{"location":"documents/core.module/#property-global_train_epochs","text":"","title":"property global_train_epochs"},{"location":"documents/core.module/#property-global_train_steps","text":"","title":"property global_train_steps"},{"location":"documents/core.module/#property-grad_acc_steps","text":"","title":"property grad_acc_steps"},{"location":"documents/core.module/#property-grad_scaler","text":"","title":"property grad_scaler"},{"location":"documents/core.module/#property-launcher","text":"","title":"property launcher"},{"location":"documents/core.module/#property-name","text":"the node name in the current activated ExecutableGraph .","title":"property name"},{"location":"documents/core.module/#property-out_dir","text":"","title":"property out_dir"},{"location":"documents/core.module/#property-run_id","text":"","title":"property run_id"},{"location":"documents/core.module/#property-step_mode","text":"whether current task is running by step (True) or by epoch (False).","title":"property step_mode"},{"location":"documents/core.module/#property-task","text":"","title":"property task"},{"location":"documents/core.module/#property-training","text":"whether current task is training.","title":"property training"},{"location":"documents/core.module/#method-epoch_end","text":"epoch_end ()","title":"method epoch_end"},{"location":"documents/core.module/#method-epoch_start","text":"epoch_start ()","title":"method epoch_start"},{"location":"documents/core.module/#method-forward_impl","text":"forward_impl ( cache : 'GraphOutputCache' )","title":"method forward_impl"},{"location":"documents/core.module/#method-load_state_dict","text":"load_state_dict ( _state_dict : Dict , strict : bool )","title":"method load_state_dict"},{"location":"documents/core.module/#method-prepare","text":"prepare ()","title":"method prepare"},{"location":"documents/core.module/#method-state_dict","text":"state_dict ()","title":"method state_dict"},{"location":"documents/core.module/#method-update","text":"update ()","title":"method update"},{"location":"documents/core.optim/","text":"module core.optim class Optimizer Optimizer configuration API for ice-learn. This is an extension of torch.optim.Optimizer that: allows the user to update the optimizer states using ice.DictProcessor , leverages torch.ZeroRedundancyOptimizer inside for memory efficient distributed training, is able to accumulate gradients for simulating large batch size, etc. Inspired by: https://pytorch.org/docs/stable/_modules/torch/optim/optimizer.html#Optimizer https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py method __init__ __init__ ( * args , ** kwds ) \u2192 None method load_state_dict load_state_dict ( _state_dict ) method state_dict state_dict ( rank ) method update update ( self , grad_scaler : GradScaler , grad_acc_steps : int , * , current_epoch , epoch_steps , global_steps , epoch_size ) Ellipsis","title":"Core.optim"},{"location":"documents/core.optim/#module-coreoptim","text":"","title":"module core.optim"},{"location":"documents/core.optim/#class-optimizer","text":"Optimizer configuration API for ice-learn. This is an extension of torch.optim.Optimizer that: allows the user to update the optimizer states using ice.DictProcessor , leverages torch.ZeroRedundancyOptimizer inside for memory efficient distributed training, is able to accumulate gradients for simulating large batch size, etc. Inspired by: https://pytorch.org/docs/stable/_modules/torch/optim/optimizer.html#Optimizer https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py","title":"class Optimizer"},{"location":"documents/core.optim/#method-__init__","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/core.optim/#method-load_state_dict","text":"load_state_dict ( _state_dict )","title":"method load_state_dict"},{"location":"documents/core.optim/#method-state_dict","text":"state_dict ( rank )","title":"method state_dict"},{"location":"documents/core.optim/#method-update","text":"update ( self , grad_scaler : GradScaler , grad_acc_steps : int , * , current_epoch , epoch_steps , global_steps , epoch_size ) Ellipsis","title":"method update"},{"location":"documents/llutil.argparser/","text":"module llutil.argparser parse arguments for functions and command line. This module provides helper functions for commonly used argument processing for functions, and a FlexibleArgParser for command line argument parsing. The default singleton of this argument parser is accessable via ice.args . Global Variables REQUIRED function isa isa ( obj , types ) an alias for python built-in isinstance . function parse_scalar parse_scalar ( obj ) function as_list as_list ( maybe_element ) helps to regularize input into list of element. No matter what is input, will output a list for your iteration. Basic Examples: assert as_list ( \"string\" ) == [ \"string\" ] assert as_list ([ \"string\" , \"string\" ]) == [ \"string\" , \"string\" ] assert as_list (( \"string\" , \"string\" )) == [ \"string\" , \"string\" ] assert as_list ([[ \"string\" , \"string\" ]]) == [ \"string\" , \"string\" ] An Application Example: def func ( * args ): return as_list ( args ) assert func ( \"a\" , \"b\" ) == [ \"a\" , \"b\" ] assert func ([ \"a\" , \"b\" ]) == [ \"a\" , \"b\" ] function as_dict as_dict ( maybe_element , key ) helps to regularize input into a dict. if maybe_element is not a dict, will return a dict with single key as {key:maybe_element} , else will return maybe_element . Args: maybe_element : a dict or any object. key : the sole key. Returns: dict : ensures to be a dict. Example: assert as_dict ({ \"k\" : \"v\" }, \"k\" ) == { \"k\" : \"v\" } assert as_dict ( \"v\" , \"k\" ) == { \"k\" : \"v\" } function is_seq_of is_seq_of ( seq , expected_type , seq_type = None ) Check whether it is a sequence of some type. Args: seq (Sequence): The sequence to be checked. expected_type (type): Expected type of sequence items. seq_type (type, optional): Expected sequence type. Returns: bool : Whether the sequence is valid. function is_list_of is_list_of ( seq , expected_type ) Check whether it is a list of some type. A partial method of :func: is_seq_of . function is_tuple_of is_tuple_of ( seq , expected_type ) Check whether it is a tuple of some type. A partial method of :func: is_seq_of . function get_hostname get_hostname () class ArgumentMissingError Raised when a required argument is missing from command line. class ArgumentTypeError Raised when converting an argument failed. class FlexibleArgParser A flexible and lightweight argument parser that saves loads of code. This module works differently compared to python built-in argparse module. It accepts two types of command line arguments, i.e. positional and keyword based (options). The keyword based arguments (options) should be specified as key=value or key=\"value\" . The positional arguments is indexed directly using an integer, but this feature is not recommended. Example: import ice # same as `python <script>.py 2 k1=4` in shell. ice . args . parse_args ([ \"2\" , \"k1=4\" ]) # setdefault() generally is optional. ice . args . setdefault ( \"k1\" , 8 , int ) ice . args . setdefault ( \"k2\" , 8 ) assert len ( ice . args ) == 3 assert 2 == int ( ice . args [ 0 ]) # default type is str. assert 4 == ice . args [ \"k1\" ] # as setdefault specified a type, here a conversion is not needed. assert 4 == ice . args . k1 # attribute also works. assert 8 == ice . args . k2 # use default value. ice . args [ \"k1\" ] = 1 ice . args . k3 = 1 ice . args . update ( k2 = 0 ) ice . args . update ({ 0 : - 1 }) assert - 1 == ice . args [ 0 ] assert 1 == ice . args [ \"k3\" ] assert 0 == ice . args . k2 Note: If you manually call parse_args() , call it before setdefault() . method __init__ __init__ () \u2192 None method hparam_dict hparam_dict () \u2192 Dict method parse_args parse_args ( argv ) Manually parse args. Args: argv (List[str]): simillar to sys.argv[1:] . method setdefault setdefault ( key , default , _type =< class ' str '>, hparam=False, help='') Set argument value under key as value , only if original entry does not exists. Args: key (int|str): the keyword. value : default_value to be set when orginal entry does not exists. Returns: original or updated value. method update update ( _FlexibleArgParser__dict = {}, ** kwds ) simillar to dict.update().","title":"Llutil.argparser"},{"location":"documents/llutil.argparser/#module-llutilargparser","text":"parse arguments for functions and command line. This module provides helper functions for commonly used argument processing for functions, and a FlexibleArgParser for command line argument parsing. The default singleton of this argument parser is accessable via ice.args .","title":"module llutil.argparser"},{"location":"documents/llutil.argparser/#global-variables","text":"REQUIRED","title":"Global Variables"},{"location":"documents/llutil.argparser/#function-isa","text":"isa ( obj , types ) an alias for python built-in isinstance .","title":"function isa"},{"location":"documents/llutil.argparser/#function-parse_scalar","text":"parse_scalar ( obj )","title":"function parse_scalar"},{"location":"documents/llutil.argparser/#function-as_list","text":"as_list ( maybe_element ) helps to regularize input into list of element. No matter what is input, will output a list for your iteration. Basic Examples: assert as_list ( \"string\" ) == [ \"string\" ] assert as_list ([ \"string\" , \"string\" ]) == [ \"string\" , \"string\" ] assert as_list (( \"string\" , \"string\" )) == [ \"string\" , \"string\" ] assert as_list ([[ \"string\" , \"string\" ]]) == [ \"string\" , \"string\" ] An Application Example: def func ( * args ): return as_list ( args ) assert func ( \"a\" , \"b\" ) == [ \"a\" , \"b\" ] assert func ([ \"a\" , \"b\" ]) == [ \"a\" , \"b\" ]","title":"function as_list"},{"location":"documents/llutil.argparser/#function-as_dict","text":"as_dict ( maybe_element , key ) helps to regularize input into a dict. if maybe_element is not a dict, will return a dict with single key as {key:maybe_element} , else will return maybe_element . Args: maybe_element : a dict or any object. key : the sole key. Returns: dict : ensures to be a dict. Example: assert as_dict ({ \"k\" : \"v\" }, \"k\" ) == { \"k\" : \"v\" } assert as_dict ( \"v\" , \"k\" ) == { \"k\" : \"v\" }","title":"function as_dict"},{"location":"documents/llutil.argparser/#function-is_seq_of","text":"is_seq_of ( seq , expected_type , seq_type = None ) Check whether it is a sequence of some type. Args: seq (Sequence): The sequence to be checked. expected_type (type): Expected type of sequence items. seq_type (type, optional): Expected sequence type. Returns: bool : Whether the sequence is valid.","title":"function is_seq_of"},{"location":"documents/llutil.argparser/#function-is_list_of","text":"is_list_of ( seq , expected_type ) Check whether it is a list of some type. A partial method of :func: is_seq_of .","title":"function is_list_of"},{"location":"documents/llutil.argparser/#function-is_tuple_of","text":"is_tuple_of ( seq , expected_type ) Check whether it is a tuple of some type. A partial method of :func: is_seq_of .","title":"function is_tuple_of"},{"location":"documents/llutil.argparser/#function-get_hostname","text":"get_hostname ()","title":"function get_hostname"},{"location":"documents/llutil.argparser/#class-argumentmissingerror","text":"Raised when a required argument is missing from command line.","title":"class ArgumentMissingError"},{"location":"documents/llutil.argparser/#class-argumenttypeerror","text":"Raised when converting an argument failed.","title":"class ArgumentTypeError"},{"location":"documents/llutil.argparser/#class-flexibleargparser","text":"A flexible and lightweight argument parser that saves loads of code. This module works differently compared to python built-in argparse module. It accepts two types of command line arguments, i.e. positional and keyword based (options). The keyword based arguments (options) should be specified as key=value or key=\"value\" . The positional arguments is indexed directly using an integer, but this feature is not recommended. Example: import ice # same as `python <script>.py 2 k1=4` in shell. ice . args . parse_args ([ \"2\" , \"k1=4\" ]) # setdefault() generally is optional. ice . args . setdefault ( \"k1\" , 8 , int ) ice . args . setdefault ( \"k2\" , 8 ) assert len ( ice . args ) == 3 assert 2 == int ( ice . args [ 0 ]) # default type is str. assert 4 == ice . args [ \"k1\" ] # as setdefault specified a type, here a conversion is not needed. assert 4 == ice . args . k1 # attribute also works. assert 8 == ice . args . k2 # use default value. ice . args [ \"k1\" ] = 1 ice . args . k3 = 1 ice . args . update ( k2 = 0 ) ice . args . update ({ 0 : - 1 }) assert - 1 == ice . args [ 0 ] assert 1 == ice . args [ \"k3\" ] assert 0 == ice . args . k2 Note: If you manually call parse_args() , call it before setdefault() .","title":"class FlexibleArgParser"},{"location":"documents/llutil.argparser/#method-__init__","text":"__init__ () \u2192 None","title":"method __init__"},{"location":"documents/llutil.argparser/#method-hparam_dict","text":"hparam_dict () \u2192 Dict","title":"method hparam_dict"},{"location":"documents/llutil.argparser/#method-parse_args","text":"parse_args ( argv ) Manually parse args. Args: argv (List[str]): simillar to sys.argv[1:] .","title":"method parse_args"},{"location":"documents/llutil.argparser/#method-setdefault","text":"setdefault ( key , default , _type =< class ' str '>, hparam=False, help='') Set argument value under key as value , only if original entry does not exists. Args: key (int|str): the keyword. value : default_value to be set when orginal entry does not exists. Returns: original or updated value.","title":"method setdefault"},{"location":"documents/llutil.argparser/#method-update","text":"update ( _FlexibleArgParser__dict = {}, ** kwds ) simillar to dict.update().","title":"method update"},{"location":"documents/llutil.board/","text":"module llutil.board class BoardWriter method __init__ __init__ ( log_dir = None , comment = '' , purge_step = None , max_queue = 10 , flush_secs = 120 , filename_suffix = '' ) method add_hparams add_hparams ( hparam_domain_discrete = None ) Add a set of hyperparameters to be compared in TensorBoard. Args: hparam_domain_discrete : (Optional[Dict[str, List[Any]]]) A dictionary that contains names of the hyperparameters and all discrete values they can hold method add_scalar add_scalar ( tag , scalar_value , global_step = None , walltime = None , new_style = False , double_precision = False )","title":"Llutil.board"},{"location":"documents/llutil.board/#module-llutilboard","text":"","title":"module llutil.board"},{"location":"documents/llutil.board/#class-boardwriter","text":"","title":"class BoardWriter"},{"location":"documents/llutil.board/#method-__init__","text":"__init__ ( log_dir = None , comment = '' , purge_step = None , max_queue = 10 , flush_secs = 120 , filename_suffix = '' )","title":"method __init__"},{"location":"documents/llutil.board/#method-add_hparams","text":"add_hparams ( hparam_domain_discrete = None ) Add a set of hyperparameters to be compared in TensorBoard. Args: hparam_domain_discrete : (Optional[Dict[str, List[Any]]]) A dictionary that contains names of the hyperparameters and all discrete values they can hold","title":"method add_hparams"},{"location":"documents/llutil.board/#method-add_scalar","text":"add_scalar ( tag , scalar_value , global_step = None , walltime = None , new_style = False , double_precision = False )","title":"method add_scalar"},{"location":"documents/llutil.collections/","text":"module llutil.collections class Dict access dict values as attributes. class Counter count values by group. Features: Get or set values using dictionary or attribute interface. Returns a zero count for missing items instead of raising a KeyError. a total() function that sums all values. Example: import ice cnt = ice . Counter () assert 0 == cnt [ 'x' ] assert 0 == cnt . x cnt . x += 1 assert 1 == cnt [ 'x' ] assert 1 == cnt . x cnt [ 'y' ] += 1 assert 2 == cnt . total () method total total () class ConfigDict stores multi-level configurations easily. Features: Get or set values using dictionary or attribute interface. Create empty dict for intermediate items instead of raising a KeyError. Example: import ice _C = ice . ConfigDict () _C . PROPERTY1 = 1 _C . GROUP1 . PROPERTY1 = 2","title":"Llutil.collections"},{"location":"documents/llutil.collections/#module-llutilcollections","text":"","title":"module llutil.collections"},{"location":"documents/llutil.collections/#class-dict","text":"access dict values as attributes.","title":"class Dict"},{"location":"documents/llutil.collections/#class-counter","text":"count values by group. Features: Get or set values using dictionary or attribute interface. Returns a zero count for missing items instead of raising a KeyError. a total() function that sums all values. Example: import ice cnt = ice . Counter () assert 0 == cnt [ 'x' ] assert 0 == cnt . x cnt . x += 1 assert 1 == cnt [ 'x' ] assert 1 == cnt . x cnt [ 'y' ] += 1 assert 2 == cnt . total ()","title":"class Counter"},{"location":"documents/llutil.collections/#method-total","text":"total ()","title":"method total"},{"location":"documents/llutil.collections/#class-configdict","text":"stores multi-level configurations easily. Features: Get or set values using dictionary or attribute interface. Create empty dict for intermediate items instead of raising a KeyError. Example: import ice _C = ice . ConfigDict () _C . PROPERTY1 = 1 _C . GROUP1 . PROPERTY1 = 2","title":"class ConfigDict"},{"location":"documents/llutil.config/","text":"module llutil.config function configurable configurable ( cls ) This decorator delays the initialization of cls until freeze() . Returns: decorated class which is now configurable. Example: import ice @ice . configurable class AClass : def __init__ ( self , a , b , c , d ): self . a = a self . b = b self . c = c self . d = d # partial initialization. i = AClass ( b = 0 ) # alter positional and keyword arguments afterwards. i [ 0 ] = 2 i [ 'b' ] = 1 i . update ({ 'c' : 3 , 'd' : 4 }) i . update ( d = 5 ) # unfrozen configurable can be printed as a legal construction python statement. assert repr ( i ) == \"AClass(a=2, b=1, c=3, d=5)\" # real initialization of original object. i . freeze () assert i . a == 2 and i . b == 1 function is_configurable is_configurable ( cls ) \u2192 bool check if a class or an object is configurable. Returns: bool Example: import ice import torch.nn as nn ice . make_configurable ( nn . Conv2d , nn . Linear ) assert ice . is_configurable ( nn . Conv2d ) function has_builder has_builder ( obj ) \u2192 bool function frozen frozen ( obj ) function make_configurable make_configurable ( * classes ) This function converts multiple existing classes to configurables. Note: This have exactly the same effects of decorate each class with @configurable when defining the class. Each class only need to be decorated once, extra calling of conversion is ignored and has no side effects. Example: import ice import torch.nn as nn ice . make_configurable ( nn . Conv2d , nn . Linear ) assert ice . is_configurable ( nn . Conv2d ) function clone clone ( obj , deepcopy = True ) clone configurables, containers, and ordinary objects recursively. Args: obj (configurable or list/dict of configurables): the configurable object to be cloned. deepcopy (bool, optional): copy resources by value. Defaults to True. Returns: Unfrozen copy of the original configurable. import ice import torch.nn as nn ice . make_configurable ( nn . Conv2d , nn . Linear ) convcfg = nn . Conv2d ( 16 , 8 ) conv1x1 = convcfg . clone () # or ice.clone(convcfg) conv1x1 [ 'kernel_size' ] = 1 conv1x1 . freeze () # or ice.freeze(conv1x1) assert conv1x1 . kernel_size == ( 1 , 1 ) conv3x3 = convcfg . clone () conv3x3 [ 'kernel_size' ] = 3 conv3x3 . freeze () assert conv3x3 . kernel_size == ( 3 , 3 ) function freeze freeze ( obj ) freeze configurables recursively. Freezing is the process of building the configuration into real objects. Original __init__() functions of configurable classes declared by configurable or make_configurable now will be called recursively to initialize the real instance, also known as the frozen version of a configurable. Args: obj (configurable or list/dict of configurables): the configurable object to be freeze. Returns: Frozen version of the original configurable. Note: Freezing happens in-place, ignoring the returned value is safe. If a user wants to reuse the configuration feature, he can clone() the object before or after frozen with the same effect. Example: See examples for configurable and clone . function objattr objattr ( obj , attrname ) class Configurable method __init__ __init__ ( * args , ** kwds ) \u2192 None method auto_freeze auto_freeze () method clone clone ( deepcopy = True ) method extra_repr extra_repr () method freeze freeze () method update_params update_params ( * args , ** kwds )","title":"Llutil.config"},{"location":"documents/llutil.config/#module-llutilconfig","text":"","title":"module llutil.config"},{"location":"documents/llutil.config/#function-configurable","text":"configurable ( cls ) This decorator delays the initialization of cls until freeze() . Returns: decorated class which is now configurable. Example: import ice @ice . configurable class AClass : def __init__ ( self , a , b , c , d ): self . a = a self . b = b self . c = c self . d = d # partial initialization. i = AClass ( b = 0 ) # alter positional and keyword arguments afterwards. i [ 0 ] = 2 i [ 'b' ] = 1 i . update ({ 'c' : 3 , 'd' : 4 }) i . update ( d = 5 ) # unfrozen configurable can be printed as a legal construction python statement. assert repr ( i ) == \"AClass(a=2, b=1, c=3, d=5)\" # real initialization of original object. i . freeze () assert i . a == 2 and i . b == 1","title":"function configurable"},{"location":"documents/llutil.config/#function-is_configurable","text":"is_configurable ( cls ) \u2192 bool check if a class or an object is configurable. Returns: bool Example: import ice import torch.nn as nn ice . make_configurable ( nn . Conv2d , nn . Linear ) assert ice . is_configurable ( nn . Conv2d )","title":"function is_configurable"},{"location":"documents/llutil.config/#function-has_builder","text":"has_builder ( obj ) \u2192 bool","title":"function has_builder"},{"location":"documents/llutil.config/#function-frozen","text":"frozen ( obj )","title":"function frozen"},{"location":"documents/llutil.config/#function-make_configurable","text":"make_configurable ( * classes ) This function converts multiple existing classes to configurables. Note: This have exactly the same effects of decorate each class with @configurable when defining the class. Each class only need to be decorated once, extra calling of conversion is ignored and has no side effects. Example: import ice import torch.nn as nn ice . make_configurable ( nn . Conv2d , nn . Linear ) assert ice . is_configurable ( nn . Conv2d )","title":"function make_configurable"},{"location":"documents/llutil.config/#function-clone","text":"clone ( obj , deepcopy = True ) clone configurables, containers, and ordinary objects recursively. Args: obj (configurable or list/dict of configurables): the configurable object to be cloned. deepcopy (bool, optional): copy resources by value. Defaults to True. Returns: Unfrozen copy of the original configurable. import ice import torch.nn as nn ice . make_configurable ( nn . Conv2d , nn . Linear ) convcfg = nn . Conv2d ( 16 , 8 ) conv1x1 = convcfg . clone () # or ice.clone(convcfg) conv1x1 [ 'kernel_size' ] = 1 conv1x1 . freeze () # or ice.freeze(conv1x1) assert conv1x1 . kernel_size == ( 1 , 1 ) conv3x3 = convcfg . clone () conv3x3 [ 'kernel_size' ] = 3 conv3x3 . freeze () assert conv3x3 . kernel_size == ( 3 , 3 )","title":"function clone"},{"location":"documents/llutil.config/#function-freeze","text":"freeze ( obj ) freeze configurables recursively. Freezing is the process of building the configuration into real objects. Original __init__() functions of configurable classes declared by configurable or make_configurable now will be called recursively to initialize the real instance, also known as the frozen version of a configurable. Args: obj (configurable or list/dict of configurables): the configurable object to be freeze. Returns: Frozen version of the original configurable. Note: Freezing happens in-place, ignoring the returned value is safe. If a user wants to reuse the configuration feature, he can clone() the object before or after frozen with the same effect. Example: See examples for configurable and clone .","title":"function freeze"},{"location":"documents/llutil.config/#function-objattr","text":"objattr ( obj , attrname )","title":"function objattr"},{"location":"documents/llutil.config/#class-configurable","text":"","title":"class Configurable"},{"location":"documents/llutil.config/#method-__init__","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/llutil.config/#method-auto_freeze","text":"auto_freeze ()","title":"method auto_freeze"},{"location":"documents/llutil.config/#method-clone","text":"clone ( deepcopy = True )","title":"method clone"},{"location":"documents/llutil.config/#method-extra_repr","text":"extra_repr ()","title":"method extra_repr"},{"location":"documents/llutil.config/#method-freeze","text":"freeze ()","title":"method freeze"},{"location":"documents/llutil.config/#method-update_params","text":"update_params ( * args , ** kwds )","title":"method update_params"},{"location":"documents/llutil.debug/","text":"module llutil.debug Global Variables global_shared_events function set_trace set_trace ( debug_local_rank = 0 ) class SubProcessPdb Pdb that works from a multiprocessing child method __init__ __init__ ()","title":"Llutil.debug"},{"location":"documents/llutil.debug/#module-llutildebug","text":"","title":"module llutil.debug"},{"location":"documents/llutil.debug/#global-variables","text":"global_shared_events","title":"Global Variables"},{"location":"documents/llutil.debug/#function-set_trace","text":"set_trace ( debug_local_rank = 0 )","title":"function set_trace"},{"location":"documents/llutil.debug/#class-subprocesspdb","text":"Pdb that works from a multiprocessing child","title":"class SubProcessPdb"},{"location":"documents/llutil.debug/#method-__init__","text":"__init__ ()","title":"method __init__"},{"location":"documents/llutil.dictprocess/","text":"module llutil.dictprocess function dictprocess dictprocess ( f ) a decorator that convert function into a DictProcessor ( Callable[[Dict], Dict] ). ice.dictprocess is a function decorator that convert any function into a callable DictProcessor class that would take a dict as input and update its content. The input arguments and return values of the function are automatically mapped to source and destination the keywords of the state dict being modified. The input arguments mapping rule is simpler. A decorated DictProcessor class can specify fixed parameters at instantiation time, and dynamic parameters as state dict content at runtime. The output arguments mapping is controlled by an extra argument at instantiation time called dst and the return value of the original function, may vary in different scenarios as shown in the following table: dst \\ ret value dict list / tuple None None Do not update, return value directly. Update state dict with returned dict. Do not update, return list / tuple directly. Do nothing. str Update with dict(dst=ret) If len(ret) == 1 , update with dict(dst=ret.values()[0]) ; If dst in ret , update with dict(dst=ret[dst]) ; else update with dict(dst=ret) Update with dict(dst=ret) Update with dict(dst=None) list / tuple Update with {dst[0]:ret} Update with {k:ret[k] for k in dst} Update with {k:v for k, v in zip(dst, ret)} Update with {dst[0]:None} dict(update_key=return_key) Raise TypeError Update with {k:ret[rk] for k, rk in dst.items()} Raise TypeError Raise TypeError Example: import ice @ice . dictprocess def Add ( x , y ): return x + y @ice . dictprocess def Power ( x , n ): return pow ( x , n ) pipeline = [ Add ( x = \"a\" , y = \"b\" , dst = \"c\" ), Power ( x = \"c\" , n = 2 , dst = \"c\" ), ] state_dict = { \"a\" : 1 , \"b\" : 2 } for f in pipeline : state_dict == f ( state_dict ) assert state_dict == { \"a\" : 1 , \"b\" : 2 , \"c\" : 9 } The definition of operations minimizes the boilerplate, and the configuration phase is simple and concise. All these features enables best reusability for complex data processing pipelines. function Compose Compose ( translist : List [ Callable [[ Dict ], Dict ]]) a predefined DictProcessor that composes a list of other DictProcessors together. function Collect Collect ( * keys ) a predefined DictProcessor that keep only selected entries.","title":"Llutil.dictprocess"},{"location":"documents/llutil.dictprocess/#module-llutildictprocess","text":"","title":"module llutil.dictprocess"},{"location":"documents/llutil.dictprocess/#function-dictprocess","text":"dictprocess ( f ) a decorator that convert function into a DictProcessor ( Callable[[Dict], Dict] ). ice.dictprocess is a function decorator that convert any function into a callable DictProcessor class that would take a dict as input and update its content. The input arguments and return values of the function are automatically mapped to source and destination the keywords of the state dict being modified. The input arguments mapping rule is simpler. A decorated DictProcessor class can specify fixed parameters at instantiation time, and dynamic parameters as state dict content at runtime. The output arguments mapping is controlled by an extra argument at instantiation time called dst and the return value of the original function, may vary in different scenarios as shown in the following table: dst \\ ret value dict list / tuple None None Do not update, return value directly. Update state dict with returned dict. Do not update, return list / tuple directly. Do nothing. str Update with dict(dst=ret) If len(ret) == 1 , update with dict(dst=ret.values()[0]) ; If dst in ret , update with dict(dst=ret[dst]) ; else update with dict(dst=ret) Update with dict(dst=ret) Update with dict(dst=None) list / tuple Update with {dst[0]:ret} Update with {k:ret[k] for k in dst} Update with {k:v for k, v in zip(dst, ret)} Update with {dst[0]:None} dict(update_key=return_key) Raise TypeError Update with {k:ret[rk] for k, rk in dst.items()} Raise TypeError Raise TypeError Example: import ice @ice . dictprocess def Add ( x , y ): return x + y @ice . dictprocess def Power ( x , n ): return pow ( x , n ) pipeline = [ Add ( x = \"a\" , y = \"b\" , dst = \"c\" ), Power ( x = \"c\" , n = 2 , dst = \"c\" ), ] state_dict = { \"a\" : 1 , \"b\" : 2 } for f in pipeline : state_dict == f ( state_dict ) assert state_dict == { \"a\" : 1 , \"b\" : 2 , \"c\" : 9 } The definition of operations minimizes the boilerplate, and the configuration phase is simple and concise. All these features enables best reusability for complex data processing pipelines.","title":"function dictprocess"},{"location":"documents/llutil.dictprocess/#function-compose","text":"Compose ( translist : List [ Callable [[ Dict ], Dict ]]) a predefined DictProcessor that composes a list of other DictProcessors together.","title":"function Compose"},{"location":"documents/llutil.dictprocess/#function-collect","text":"Collect ( * keys ) a predefined DictProcessor that keep only selected entries.","title":"function Collect"},{"location":"documents/llutil.file_client/","text":"module llutil.file_client function mmcv_mkdir_or_exist mmcv_mkdir_or_exist ( dir_name , mode = 511 ) function has_method has_method ( obj : object , method : str ) \u2192 bool Check whether the object has a method. Args: method (str): The method name to check. obj (object): The object to check. Returns: bool : True if the object has the method else False. class BaseStorageBackend Abstract class of storage backends. All backends need to implement two apis: get() and get_text() . get() reads the file as a byte stream and get_text() reads the file as texts. property allow_symlink property name method get get ( filepath ) method get_text get_text ( filepath ) class CephBackend Ceph storage backend (for internal use). Args: path_mapping (dict|None): path mapping dict from local path to Petrel path. When ``path_mapping={'src' : 'dst'} `, src in filepath` will be replaced by dst . Default : None. .. warning: :class:`mmcv.fileio.file_client.CephBackend` will be deprecated, please use :class:`mmcv.fileio.file_client.PetrelBackend` instead. <a href=\"https://github.com/tjyuyao/ice-learn/blob/main/ice/llutil/file_client.py#L75\"><img align=\"right\" style=\"float:right;\" src=\"https://img.shields.io/badge/-source-cccccc?style=flat-square\"></a> ### <kbd>method</kbd> `__init__` ```python __init__(path_mapping=None) property allow_symlink property name method get get ( filepath ) method get_text get_text ( filepath , encoding = None ) class PetrelBackend Petrel storage backend (for internal use). PetrelBackend supports reading and writing data to multiple clusters. If the file path contains the cluster name, PetrelBackend will read data from specified cluster or write data to it. Otherwise, PetrelBackend will access the default cluster. Args: path_mapping (dict, optional): Path mapping dict from local path to Petrel path. When ``path_mapping={'src' : 'dst'} `, src` in `filepath will be replaced by dst . Default` : None. enable_mc (bool, optional): Whether to enable memcached support. Default : True. Examples: filepath1 = 's3://path/of/file' filepath2 = 'cluster-name:s3://path/of/file' client = PetrelBackend () client . get ( filepath1 ) # get data from default cluster client . get ( filepath2 ) # get data from 'cluster-name' cluster method __init__ __init__ ( path_mapping : Optional [ dict ] = None , enable_mc : bool = True ) property allow_symlink property name method exists exists ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path exists. Args: filepath (str or Path): Path to be checked whether exists. Returns: bool : Return True if filepath exists, False otherwise. method get get ( filepath : Union [ str , Path ]) \u2192 memoryview Read data from a given filepath with 'rb' mode. Args: filepath (str or Path): Path to read data. Returns: memoryview : A memory view of expected bytes object to avoid copying. The memoryview object can be converted to bytes by value_buf.tobytes() . method get_local_path get_local_path ( filepath : Union [ str , Path ]) \u2192 Iterable [ str ] Download a file from filepath and return a temporary path. get_local_path is decorated by :meth: contxtlib.contextmanager . It can be called with with statement, and when exists from the with statement, the temporary path will be released. Args: filepath (str | Path): Download a file from filepath . Examples: client = PetrelBackend () # After existing from the `with` clause, # the path will be removed with client . get_local_path ( 's3://path/of/your/file' ) as path : # ... # do something here Yields: Iterable[str] : Only yield one temporary path. method get_text get_text ( filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 str Read data from a given filepath with 'r' mode. Args: filepath (str or Path): Path to read data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'. Returns: str : Expected text reading from filepath . method isdir isdir ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a directory. Args: filepath (str or Path): Path to be checked whether it is a directory. Returns: bool : Return True if filepath points to a directory, False otherwise. method isfile isfile ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a file. Args: filepath (str or Path): Path to be checked whether it is a file. Returns: bool : Return True if filepath points to a file, False otherwise. method join_path join_path ( filepath : Union [ str , Path ], * filepaths : Union [ str , Path ]) \u2192 str Concatenate all file paths. Args: filepath (str or Path): Path to be concatenated. Returns: str : The result after concatenation. method list_dir_or_file list_dir_or_file ( dir_path : Union [ str , Path ], list_dir : bool = True , list_file : bool = True , suffix : Optional [ str , Tuple [ str ]] = None , recursive : bool = False ) \u2192 Iterator [ str ] Scan a directory to find the interested directories or files in arbitrary order. Note: Petrel has no concept of directories but it simulates the directory hierarchy in the filesystem through public prefixes. In addition, if the returned path ends with '/', it means the path is a public prefix which is a logical directory. Note: :meth: list_dir_or_file returns the path relative to dir_path . In addition, the returned path of directory will not contains the suffix '/' which is consistent with other backends. Args: dir_path (str | Path): Path of the directory. list_dir (bool): List the directories. Default: True. list_file (bool): List the path of files. Default: True. suffix (str or tuple[str], optional): File suffix that we are interested in. Default : None. recursive (bool): If set to True, recursively scan the directory. Default : False. Yields: Iterable[str] : A relative path to dir_path . method put put ( obj : bytes , filepath : Union [ str , Path ]) \u2192 None Save data to a given filepath . Args: obj (bytes): Data to be saved. filepath (str or Path): Path to write data. method put_text put_text ( obj : str , filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 None Save data to a given filepath . Args: obj (str): Data to be written. filepath (str or Path): Path to write data. encoding (str): The encoding format used to encode the obj . Default : 'utf-8'. method remove remove ( filepath : Union [ str , Path ]) \u2192 None Remove a file. Args: filepath (str or Path): Path to be removed. class MemcachedBackend Memcached storage backend. Attributes: server_list_cfg (str): Config file for memcached server list. client_cfg (str): Config file for memcached client. sys_path (str | None): Additional path to be appended to sys.path . Default : None. method __init__ __init__ ( server_list_cfg , client_cfg , sys_path = None ) property allow_symlink property name method get get ( filepath ) method get_text get_text ( filepath , encoding = None ) class LmdbBackend Lmdb storage backend. Args: db_path (str): Lmdb database path. readonly (bool, optional): Lmdb environment parameter. If True, disallow any write operations. Default : True. lock (bool, optional): Lmdb environment parameter. If False, when concurrent access occurs, do not lock the database. Default : False. readahead (bool, optional): Lmdb environment parameter. If False, disable the OS filesystem readahead mechanism, which may improve random read performance when a database is larger than RAM. Default : False. Attributes: db_path (str): Lmdb database path. method __init__ __init__ ( db_path , readonly = True , lock = False , readahead = False , ** kwargs ) property allow_symlink property name method get get ( filepath ) Get values according to the filepath. Args: filepath (str | obj: Path ): Here, filepath is the lmdb key. method get_text get_text ( filepath , encoding = None ) class HardDiskBackend Raw hard disks storage backend. property allow_symlink property name method exists exists ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path exists. Args: filepath (str or Path): Path to be checked whether exists. Returns: bool : Return True if filepath exists, False otherwise. method get get ( filepath : Union [ str , Path ]) \u2192 bytes Read data from a given filepath with 'rb' mode. Args: filepath (str or Path): Path to read data. Returns: bytes : Expected bytes object. method get_local_path get_local_path ( filepath : Union [ str , Path ]) \u2192 Iterable [ Union [ str , Path ]] Only for unified API and do nothing. method get_text get_text ( filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 str Read data from a given filepath with 'r' mode. Args: filepath (str or Path): Path to read data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'. Returns: str : Expected text reading from filepath . method isdir isdir ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a directory. Args: filepath (str or Path): Path to be checked whether it is a directory. Returns: bool : Return True if filepath points to a directory, False otherwise. method isfile isfile ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a file. Args: filepath (str or Path): Path to be checked whether it is a file. Returns: bool : Return True if filepath points to a file, False otherwise. method join_path join_path ( filepath : Union [ str , Path ], * filepaths : Union [ str , Path ]) \u2192 str Concatenate all file paths. Join one or more filepath components intelligently. The return value is the concatenation of filepath and any members of *filepaths. Args: filepath (str or Path): Path to be concatenated. Returns: str : The result of concatenation. method list_dir_or_file list_dir_or_file ( dir_path : Union [ str , Path ], list_dir : bool = True , list_file : bool = True , suffix : Optional [ str , Tuple [ str ]] = None , recursive : bool = False ) \u2192 Iterator [ str ] Scan a directory to find the interested directories or files in arbitrary order. Note: :meth: list_dir_or_file returns the path relative to dir_path . Args: dir_path (str | Path): Path of the directory. list_dir (bool): List the directories. Default: True. list_file (bool): List the path of files. Default: True. suffix (str or tuple[str], optional): File suffix that we are interested in. Default : None. recursive (bool): If set to True, recursively scan the directory. Default : False. Yields: Iterable[str] : A relative path to dir_path . method put put ( obj : bytes , filepath : Union [ str , Path ]) \u2192 None Write data to a given filepath with 'wb' mode. Note: put will create a directory if the directory of filepath does not exist. Args: obj (bytes): Data to be written. filepath (str or Path): Path to write data. method put_text put_text ( obj : str , filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 None Write data to a given filepath with 'w' mode. Note: put_text will create a directory if the directory of filepath does not exist. Args: obj (str): Data to be written. filepath (str or Path): Path to write data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'. method remove remove ( filepath : Union [ str , Path ]) \u2192 None Remove a file. Args: filepath (str or Path): Path to be removed. class HTTPBackend HTTP and HTTPS storage bachend. property allow_symlink property name method get get ( filepath ) method get_local_path get_local_path ( filepath : str ) \u2192 Iterable [ str ] Download a file from filepath . get_local_path is decorated by :meth: contxtlib.contextmanager . It can be called with with statement, and when exists from the with statement, the temporary path will be released. Args: filepath (str): Download a file from filepath . Examples: client = HTTPBackend () # After existing from the `with` clause, # the path will be removed with client . get_local_path ( 'http://path/of/your/file' ) as path : # ... # do something here method get_text get_text ( filepath , encoding = 'utf-8' ) class FileClient A general file client to access files in different backends. The client loads a file or text in a specified backend from its path and returns it as a binary or text file. There are two ways to choose a backend, the name of backend and the prefix of path. Although both of them can be used to choose a storage backend, backend has a higher priority that is if they are all set, the storage backend will be chosen by the backend argument. If they are all None , the disk backend will be chosen. Note that It can also register other backend accessor with a given name, prefixes, and backend class. In addition, We use the singleton pattern to avoid repeated object creation. If the arguments are the same, the same object will be returned. Args: backend (str, optional): The storage backend type. Options are \"disk\", \"ceph\", \"memcached\", \"lmdb\", \"http\" and \"petrel\". Default : None. prefix (str, optional): The prefix of the registered storage backend. Options are \"s3\", \"http\", \"https\". Default : None. Examples: # only set backend file_client = FileClient ( backend = 'petrel' ) # only set prefix file_client = FileClient ( prefix = 's3' ) # set both backend and prefix but use backend to choose client file_client = FileClient ( backend = 'petrel' , prefix = 's3' ) # if the arguments are the same, the same object is returned file_client1 = FileClient ( backend = 'petrel' ) file_client1 is file_client # True Attributes: client (:obj: BaseStorageBackend ): The backend object. property allow_symlink property name method exists exists ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path exists. Args: filepath (str or Path): Path to be checked whether exists. Returns: bool : Return True if filepath exists, False otherwise. method get get ( filepath : Union [ str , Path ]) \u2192 Union [ bytes , memoryview ] Read data from a given filepath with 'rb' mode. Note: There are two types of return values for get , one is bytes and the other is memoryview . The advantage of using memoryview is that you can avoid copying, and if you want to convert it to bytes , you can use .tobytes() . Args: filepath (str or Path): Path to read data. Returns: bytes | memoryview : Expected bytes object or a memory view of the bytes object. method get_local_path get_local_path ( filepath : Union [ str , Path ]) \u2192 Iterable [ str ] Download data from filepath and write the data to local path. get_local_path is decorated by :meth: contxtlib.contextmanager . It can be called with with statement, and when exists from the with statement, the temporary path will be released. Note: If the filepath is a local path, just return itself. .. warning: `get_local_path` is an experimental interface that may change in the future. Args: filepath (str or Path): Path to be read data. Examples: file_client = FileClient ( prefix = 's3' ) with file_client . get_local_path ( 's3://bucket/abc.jpg' ) as path : # ... # do something here Yields: Iterable[str] : Only yield one path. method get_text get_text ( filepath : Union [ str , Path ], encoding = 'utf-8' ) \u2192 str Read data from a given filepath with 'r' mode. Args: filepath (str or Path): Path to read data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'. Returns: str : Expected text reading from filepath . classmethod infer_client infer_client ( file_client_args : Optional [ dict ] = None , uri : Optional [ str , Path ] = None ) \u2192 FileClient Infer a suitable file client based on the URI and arguments. Args: file_client_args (dict, optional): Arguments to instantiate a FileClient. Default : None. uri (str | Path, optional): Uri to be parsed that contains the file prefix. Default : None. Examples: uri = 's3://path/of/your/file' file_client = FileClient . infer_client ( uri = uri ) file_client_args = { 'backend' : 'petrel' } file_client = FileClient . infer_client ( file_client_args ) Returns: FileClient : Instantiated FileClient object. method isdir isdir ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a directory. Args: filepath (str or Path): Path to be checked whether it is a directory. Returns: bool : Return True if filepath points to a directory, False otherwise. method isfile isfile ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a file. Args: filepath (str or Path): Path to be checked whether it is a file. Returns: bool : Return True if filepath points to a file, False otherwise. method join_path join_path ( filepath : Union [ str , Path ], * filepaths : Union [ str , Path ]) \u2192 str Concatenate all file paths. Join one or more filepath components intelligently. The return value is the concatenation of filepath and any members of *filepaths. Args: filepath (str or Path): Path to be concatenated. Returns: str : The result of concatenation. method list_dir_or_file list_dir_or_file ( dir_path : Union [ str , Path ], list_dir : bool = True , list_file : bool = True , suffix : Optional [ str , Tuple [ str ]] = None , recursive : bool = False ) \u2192 Iterator [ str ] Scan a directory to find the interested directories or files in arbitrary order. Note: :meth: list_dir_or_file returns the path relative to dir_path . Args: dir_path (str | Path): Path of the directory. list_dir (bool): List the directories. Default: True. list_file (bool): List the path of files. Default: True. suffix (str or tuple[str], optional): File suffix that we are interested in. Default : None. recursive (bool): If set to True, recursively scan the directory. Default : False. Yields: Iterable[str] : A relative path to dir_path . method parse_uri_prefix parse_uri_prefix ( uri : Union [ str , Path ]) \u2192 Optional [ str ] Parse the prefix of a uri. Args: uri (str | Path): Uri to be parsed that contains the file prefix. Examples: FileClient . parse_uri_prefix ( 's3://path/of/your/file' ) # 's3' Returns: str | None : Return the prefix of uri if the uri contains '://' else None . method put put ( obj : bytes , filepath : Union [ str , Path ]) \u2192 None Write data to a given filepath with 'wb' mode. Note: put should create a directory if the directory of filepath does not exist. Args: obj (bytes): Data to be written. filepath (str or Path): Path to write data. method put_text put_text ( obj : str , filepath : Union [ str , Path ]) \u2192 None Write data to a given filepath with 'w' mode. Note: put_text should create a directory if the directory of filepath does not exist. Args: obj (str): Data to be written. filepath (str or Path): Path to write data. encoding (str, optional): The encoding format used to open the `filepath . Default` : 'utf-8'. classmethod register_backend register_backend ( name , backend = None , force = False , prefixes = None ) Register a backend to FileClient. This method can be used as a normal class method or a decorator. .. code-block:: python class NewBackend(BaseStorageBackend): def get(self, filepath): return filepath def get_text(self, filepath): return filepath FileClient.register_backend('new', NewBackend) or .. code-block:: python @FileClient.register_backend('new') class NewBackend(BaseStorageBackend): def get(self, filepath): return filepath def get_text(self, filepath): return filepath Args: name (str): The name of the registered backend. backend (class, optional): The backend class to be registered, which must be a subclass of : class: BaseStorageBackend . When this method is used as a decorator, backend is None. Defaults to None. force (bool, optional): Whether to override the backend if the name has already been registered. Defaults to False. prefixes (str or list[str] or tuple[str], optional): The prefixes of the registered storage backend. Default : None. New in version 1.3.15. method remove remove ( filepath : Union [ str , Path ]) \u2192 None Remove a file. Args: filepath (str, Path): Path to be removed.","title":"Llutil.file client"},{"location":"documents/llutil.file_client/#module-llutilfile_client","text":"","title":"module llutil.file_client"},{"location":"documents/llutil.file_client/#function-mmcv_mkdir_or_exist","text":"mmcv_mkdir_or_exist ( dir_name , mode = 511 )","title":"function mmcv_mkdir_or_exist"},{"location":"documents/llutil.file_client/#function-has_method","text":"has_method ( obj : object , method : str ) \u2192 bool Check whether the object has a method. Args: method (str): The method name to check. obj (object): The object to check. Returns: bool : True if the object has the method else False.","title":"function has_method"},{"location":"documents/llutil.file_client/#class-basestoragebackend","text":"Abstract class of storage backends. All backends need to implement two apis: get() and get_text() . get() reads the file as a byte stream and get_text() reads the file as texts.","title":"class BaseStorageBackend"},{"location":"documents/llutil.file_client/#property-allow_symlink","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-get","text":"get ( filepath )","title":"method get"},{"location":"documents/llutil.file_client/#method-get_text","text":"get_text ( filepath )","title":"method get_text"},{"location":"documents/llutil.file_client/#class-cephbackend","text":"Ceph storage backend (for internal use). Args: path_mapping (dict|None): path mapping dict from local path to Petrel path. When ``path_mapping={'src' : 'dst'} `, src in filepath` will be replaced by dst . Default : None. .. warning: :class:`mmcv.fileio.file_client.CephBackend` will be deprecated, please use :class:`mmcv.fileio.file_client.PetrelBackend` instead. <a href=\"https://github.com/tjyuyao/ice-learn/blob/main/ice/llutil/file_client.py#L75\"><img align=\"right\" style=\"float:right;\" src=\"https://img.shields.io/badge/-source-cccccc?style=flat-square\"></a> ### <kbd>method</kbd> `__init__` ```python __init__(path_mapping=None)","title":"class CephBackend"},{"location":"documents/llutil.file_client/#property-allow_symlink_1","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name_1","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-get_1","text":"get ( filepath )","title":"method get"},{"location":"documents/llutil.file_client/#method-get_text_1","text":"get_text ( filepath , encoding = None )","title":"method get_text"},{"location":"documents/llutil.file_client/#class-petrelbackend","text":"Petrel storage backend (for internal use). PetrelBackend supports reading and writing data to multiple clusters. If the file path contains the cluster name, PetrelBackend will read data from specified cluster or write data to it. Otherwise, PetrelBackend will access the default cluster. Args: path_mapping (dict, optional): Path mapping dict from local path to Petrel path. When ``path_mapping={'src' : 'dst'} `, src` in `filepath will be replaced by dst . Default` : None. enable_mc (bool, optional): Whether to enable memcached support. Default : True. Examples: filepath1 = 's3://path/of/file' filepath2 = 'cluster-name:s3://path/of/file' client = PetrelBackend () client . get ( filepath1 ) # get data from default cluster client . get ( filepath2 ) # get data from 'cluster-name' cluster","title":"class PetrelBackend"},{"location":"documents/llutil.file_client/#method-__init__","text":"__init__ ( path_mapping : Optional [ dict ] = None , enable_mc : bool = True )","title":"method __init__"},{"location":"documents/llutil.file_client/#property-allow_symlink_2","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name_2","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-exists","text":"exists ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path exists. Args: filepath (str or Path): Path to be checked whether exists. Returns: bool : Return True if filepath exists, False otherwise.","title":"method exists"},{"location":"documents/llutil.file_client/#method-get_2","text":"get ( filepath : Union [ str , Path ]) \u2192 memoryview Read data from a given filepath with 'rb' mode. Args: filepath (str or Path): Path to read data. Returns: memoryview : A memory view of expected bytes object to avoid copying. The memoryview object can be converted to bytes by value_buf.tobytes() .","title":"method get"},{"location":"documents/llutil.file_client/#method-get_local_path","text":"get_local_path ( filepath : Union [ str , Path ]) \u2192 Iterable [ str ] Download a file from filepath and return a temporary path. get_local_path is decorated by :meth: contxtlib.contextmanager . It can be called with with statement, and when exists from the with statement, the temporary path will be released. Args: filepath (str | Path): Download a file from filepath . Examples: client = PetrelBackend () # After existing from the `with` clause, # the path will be removed with client . get_local_path ( 's3://path/of/your/file' ) as path : # ... # do something here Yields: Iterable[str] : Only yield one temporary path.","title":"method get_local_path"},{"location":"documents/llutil.file_client/#method-get_text_2","text":"get_text ( filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 str Read data from a given filepath with 'r' mode. Args: filepath (str or Path): Path to read data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'. Returns: str : Expected text reading from filepath .","title":"method get_text"},{"location":"documents/llutil.file_client/#method-isdir","text":"isdir ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a directory. Args: filepath (str or Path): Path to be checked whether it is a directory. Returns: bool : Return True if filepath points to a directory, False otherwise.","title":"method isdir"},{"location":"documents/llutil.file_client/#method-isfile","text":"isfile ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a file. Args: filepath (str or Path): Path to be checked whether it is a file. Returns: bool : Return True if filepath points to a file, False otherwise.","title":"method isfile"},{"location":"documents/llutil.file_client/#method-join_path","text":"join_path ( filepath : Union [ str , Path ], * filepaths : Union [ str , Path ]) \u2192 str Concatenate all file paths. Args: filepath (str or Path): Path to be concatenated. Returns: str : The result after concatenation.","title":"method join_path"},{"location":"documents/llutil.file_client/#method-list_dir_or_file","text":"list_dir_or_file ( dir_path : Union [ str , Path ], list_dir : bool = True , list_file : bool = True , suffix : Optional [ str , Tuple [ str ]] = None , recursive : bool = False ) \u2192 Iterator [ str ] Scan a directory to find the interested directories or files in arbitrary order. Note: Petrel has no concept of directories but it simulates the directory hierarchy in the filesystem through public prefixes. In addition, if the returned path ends with '/', it means the path is a public prefix which is a logical directory. Note: :meth: list_dir_or_file returns the path relative to dir_path . In addition, the returned path of directory will not contains the suffix '/' which is consistent with other backends. Args: dir_path (str | Path): Path of the directory. list_dir (bool): List the directories. Default: True. list_file (bool): List the path of files. Default: True. suffix (str or tuple[str], optional): File suffix that we are interested in. Default : None. recursive (bool): If set to True, recursively scan the directory. Default : False. Yields: Iterable[str] : A relative path to dir_path .","title":"method list_dir_or_file"},{"location":"documents/llutil.file_client/#method-put","text":"put ( obj : bytes , filepath : Union [ str , Path ]) \u2192 None Save data to a given filepath . Args: obj (bytes): Data to be saved. filepath (str or Path): Path to write data.","title":"method put"},{"location":"documents/llutil.file_client/#method-put_text","text":"put_text ( obj : str , filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 None Save data to a given filepath . Args: obj (str): Data to be written. filepath (str or Path): Path to write data. encoding (str): The encoding format used to encode the obj . Default : 'utf-8'.","title":"method put_text"},{"location":"documents/llutil.file_client/#method-remove","text":"remove ( filepath : Union [ str , Path ]) \u2192 None Remove a file. Args: filepath (str or Path): Path to be removed.","title":"method remove"},{"location":"documents/llutil.file_client/#class-memcachedbackend","text":"Memcached storage backend. Attributes: server_list_cfg (str): Config file for memcached server list. client_cfg (str): Config file for memcached client. sys_path (str | None): Additional path to be appended to sys.path . Default : None.","title":"class MemcachedBackend"},{"location":"documents/llutil.file_client/#method-__init___1","text":"__init__ ( server_list_cfg , client_cfg , sys_path = None )","title":"method __init__"},{"location":"documents/llutil.file_client/#property-allow_symlink_3","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name_3","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-get_3","text":"get ( filepath )","title":"method get"},{"location":"documents/llutil.file_client/#method-get_text_3","text":"get_text ( filepath , encoding = None )","title":"method get_text"},{"location":"documents/llutil.file_client/#class-lmdbbackend","text":"Lmdb storage backend. Args: db_path (str): Lmdb database path. readonly (bool, optional): Lmdb environment parameter. If True, disallow any write operations. Default : True. lock (bool, optional): Lmdb environment parameter. If False, when concurrent access occurs, do not lock the database. Default : False. readahead (bool, optional): Lmdb environment parameter. If False, disable the OS filesystem readahead mechanism, which may improve random read performance when a database is larger than RAM. Default : False. Attributes: db_path (str): Lmdb database path.","title":"class LmdbBackend"},{"location":"documents/llutil.file_client/#method-__init___2","text":"__init__ ( db_path , readonly = True , lock = False , readahead = False , ** kwargs )","title":"method __init__"},{"location":"documents/llutil.file_client/#property-allow_symlink_4","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name_4","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-get_4","text":"get ( filepath ) Get values according to the filepath. Args: filepath (str | obj: Path ): Here, filepath is the lmdb key.","title":"method get"},{"location":"documents/llutil.file_client/#method-get_text_4","text":"get_text ( filepath , encoding = None )","title":"method get_text"},{"location":"documents/llutil.file_client/#class-harddiskbackend","text":"Raw hard disks storage backend.","title":"class HardDiskBackend"},{"location":"documents/llutil.file_client/#property-allow_symlink_5","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name_5","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-exists_1","text":"exists ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path exists. Args: filepath (str or Path): Path to be checked whether exists. Returns: bool : Return True if filepath exists, False otherwise.","title":"method exists"},{"location":"documents/llutil.file_client/#method-get_5","text":"get ( filepath : Union [ str , Path ]) \u2192 bytes Read data from a given filepath with 'rb' mode. Args: filepath (str or Path): Path to read data. Returns: bytes : Expected bytes object.","title":"method get"},{"location":"documents/llutil.file_client/#method-get_local_path_1","text":"get_local_path ( filepath : Union [ str , Path ]) \u2192 Iterable [ Union [ str , Path ]] Only for unified API and do nothing.","title":"method get_local_path"},{"location":"documents/llutil.file_client/#method-get_text_5","text":"get_text ( filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 str Read data from a given filepath with 'r' mode. Args: filepath (str or Path): Path to read data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'. Returns: str : Expected text reading from filepath .","title":"method get_text"},{"location":"documents/llutil.file_client/#method-isdir_1","text":"isdir ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a directory. Args: filepath (str or Path): Path to be checked whether it is a directory. Returns: bool : Return True if filepath points to a directory, False otherwise.","title":"method isdir"},{"location":"documents/llutil.file_client/#method-isfile_1","text":"isfile ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a file. Args: filepath (str or Path): Path to be checked whether it is a file. Returns: bool : Return True if filepath points to a file, False otherwise.","title":"method isfile"},{"location":"documents/llutil.file_client/#method-join_path_1","text":"join_path ( filepath : Union [ str , Path ], * filepaths : Union [ str , Path ]) \u2192 str Concatenate all file paths. Join one or more filepath components intelligently. The return value is the concatenation of filepath and any members of *filepaths. Args: filepath (str or Path): Path to be concatenated. Returns: str : The result of concatenation.","title":"method join_path"},{"location":"documents/llutil.file_client/#method-list_dir_or_file_1","text":"list_dir_or_file ( dir_path : Union [ str , Path ], list_dir : bool = True , list_file : bool = True , suffix : Optional [ str , Tuple [ str ]] = None , recursive : bool = False ) \u2192 Iterator [ str ] Scan a directory to find the interested directories or files in arbitrary order. Note: :meth: list_dir_or_file returns the path relative to dir_path . Args: dir_path (str | Path): Path of the directory. list_dir (bool): List the directories. Default: True. list_file (bool): List the path of files. Default: True. suffix (str or tuple[str], optional): File suffix that we are interested in. Default : None. recursive (bool): If set to True, recursively scan the directory. Default : False. Yields: Iterable[str] : A relative path to dir_path .","title":"method list_dir_or_file"},{"location":"documents/llutil.file_client/#method-put_1","text":"put ( obj : bytes , filepath : Union [ str , Path ]) \u2192 None Write data to a given filepath with 'wb' mode. Note: put will create a directory if the directory of filepath does not exist. Args: obj (bytes): Data to be written. filepath (str or Path): Path to write data.","title":"method put"},{"location":"documents/llutil.file_client/#method-put_text_1","text":"put_text ( obj : str , filepath : Union [ str , Path ], encoding : str = 'utf-8' ) \u2192 None Write data to a given filepath with 'w' mode. Note: put_text will create a directory if the directory of filepath does not exist. Args: obj (str): Data to be written. filepath (str or Path): Path to write data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'.","title":"method put_text"},{"location":"documents/llutil.file_client/#method-remove_1","text":"remove ( filepath : Union [ str , Path ]) \u2192 None Remove a file. Args: filepath (str or Path): Path to be removed.","title":"method remove"},{"location":"documents/llutil.file_client/#class-httpbackend","text":"HTTP and HTTPS storage bachend.","title":"class HTTPBackend"},{"location":"documents/llutil.file_client/#property-allow_symlink_6","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name_6","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-get_6","text":"get ( filepath )","title":"method get"},{"location":"documents/llutil.file_client/#method-get_local_path_2","text":"get_local_path ( filepath : str ) \u2192 Iterable [ str ] Download a file from filepath . get_local_path is decorated by :meth: contxtlib.contextmanager . It can be called with with statement, and when exists from the with statement, the temporary path will be released. Args: filepath (str): Download a file from filepath . Examples: client = HTTPBackend () # After existing from the `with` clause, # the path will be removed with client . get_local_path ( 'http://path/of/your/file' ) as path : # ... # do something here","title":"method get_local_path"},{"location":"documents/llutil.file_client/#method-get_text_6","text":"get_text ( filepath , encoding = 'utf-8' )","title":"method get_text"},{"location":"documents/llutil.file_client/#class-fileclient","text":"A general file client to access files in different backends. The client loads a file or text in a specified backend from its path and returns it as a binary or text file. There are two ways to choose a backend, the name of backend and the prefix of path. Although both of them can be used to choose a storage backend, backend has a higher priority that is if they are all set, the storage backend will be chosen by the backend argument. If they are all None , the disk backend will be chosen. Note that It can also register other backend accessor with a given name, prefixes, and backend class. In addition, We use the singleton pattern to avoid repeated object creation. If the arguments are the same, the same object will be returned. Args: backend (str, optional): The storage backend type. Options are \"disk\", \"ceph\", \"memcached\", \"lmdb\", \"http\" and \"petrel\". Default : None. prefix (str, optional): The prefix of the registered storage backend. Options are \"s3\", \"http\", \"https\". Default : None. Examples: # only set backend file_client = FileClient ( backend = 'petrel' ) # only set prefix file_client = FileClient ( prefix = 's3' ) # set both backend and prefix but use backend to choose client file_client = FileClient ( backend = 'petrel' , prefix = 's3' ) # if the arguments are the same, the same object is returned file_client1 = FileClient ( backend = 'petrel' ) file_client1 is file_client # True Attributes: client (:obj: BaseStorageBackend ): The backend object.","title":"class FileClient"},{"location":"documents/llutil.file_client/#property-allow_symlink_7","text":"","title":"property allow_symlink"},{"location":"documents/llutil.file_client/#property-name_7","text":"","title":"property name"},{"location":"documents/llutil.file_client/#method-exists_2","text":"exists ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path exists. Args: filepath (str or Path): Path to be checked whether exists. Returns: bool : Return True if filepath exists, False otherwise.","title":"method exists"},{"location":"documents/llutil.file_client/#method-get_7","text":"get ( filepath : Union [ str , Path ]) \u2192 Union [ bytes , memoryview ] Read data from a given filepath with 'rb' mode. Note: There are two types of return values for get , one is bytes and the other is memoryview . The advantage of using memoryview is that you can avoid copying, and if you want to convert it to bytes , you can use .tobytes() . Args: filepath (str or Path): Path to read data. Returns: bytes | memoryview : Expected bytes object or a memory view of the bytes object.","title":"method get"},{"location":"documents/llutil.file_client/#method-get_local_path_3","text":"get_local_path ( filepath : Union [ str , Path ]) \u2192 Iterable [ str ] Download data from filepath and write the data to local path. get_local_path is decorated by :meth: contxtlib.contextmanager . It can be called with with statement, and when exists from the with statement, the temporary path will be released. Note: If the filepath is a local path, just return itself. .. warning: `get_local_path` is an experimental interface that may change in the future. Args: filepath (str or Path): Path to be read data. Examples: file_client = FileClient ( prefix = 's3' ) with file_client . get_local_path ( 's3://bucket/abc.jpg' ) as path : # ... # do something here Yields: Iterable[str] : Only yield one path.","title":"method get_local_path"},{"location":"documents/llutil.file_client/#method-get_text_7","text":"get_text ( filepath : Union [ str , Path ], encoding = 'utf-8' ) \u2192 str Read data from a given filepath with 'r' mode. Args: filepath (str or Path): Path to read data. encoding (str): The encoding format used to open the filepath . Default : 'utf-8'. Returns: str : Expected text reading from filepath .","title":"method get_text"},{"location":"documents/llutil.file_client/#classmethod-infer_client","text":"infer_client ( file_client_args : Optional [ dict ] = None , uri : Optional [ str , Path ] = None ) \u2192 FileClient Infer a suitable file client based on the URI and arguments. Args: file_client_args (dict, optional): Arguments to instantiate a FileClient. Default : None. uri (str | Path, optional): Uri to be parsed that contains the file prefix. Default : None. Examples: uri = 's3://path/of/your/file' file_client = FileClient . infer_client ( uri = uri ) file_client_args = { 'backend' : 'petrel' } file_client = FileClient . infer_client ( file_client_args ) Returns: FileClient : Instantiated FileClient object.","title":"classmethod infer_client"},{"location":"documents/llutil.file_client/#method-isdir_2","text":"isdir ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a directory. Args: filepath (str or Path): Path to be checked whether it is a directory. Returns: bool : Return True if filepath points to a directory, False otherwise.","title":"method isdir"},{"location":"documents/llutil.file_client/#method-isfile_2","text":"isfile ( filepath : Union [ str , Path ]) \u2192 bool Check whether a file path is a file. Args: filepath (str or Path): Path to be checked whether it is a file. Returns: bool : Return True if filepath points to a file, False otherwise.","title":"method isfile"},{"location":"documents/llutil.file_client/#method-join_path_2","text":"join_path ( filepath : Union [ str , Path ], * filepaths : Union [ str , Path ]) \u2192 str Concatenate all file paths. Join one or more filepath components intelligently. The return value is the concatenation of filepath and any members of *filepaths. Args: filepath (str or Path): Path to be concatenated. Returns: str : The result of concatenation.","title":"method join_path"},{"location":"documents/llutil.file_client/#method-list_dir_or_file_2","text":"list_dir_or_file ( dir_path : Union [ str , Path ], list_dir : bool = True , list_file : bool = True , suffix : Optional [ str , Tuple [ str ]] = None , recursive : bool = False ) \u2192 Iterator [ str ] Scan a directory to find the interested directories or files in arbitrary order. Note: :meth: list_dir_or_file returns the path relative to dir_path . Args: dir_path (str | Path): Path of the directory. list_dir (bool): List the directories. Default: True. list_file (bool): List the path of files. Default: True. suffix (str or tuple[str], optional): File suffix that we are interested in. Default : None. recursive (bool): If set to True, recursively scan the directory. Default : False. Yields: Iterable[str] : A relative path to dir_path .","title":"method list_dir_or_file"},{"location":"documents/llutil.file_client/#method-parse_uri_prefix","text":"parse_uri_prefix ( uri : Union [ str , Path ]) \u2192 Optional [ str ] Parse the prefix of a uri. Args: uri (str | Path): Uri to be parsed that contains the file prefix. Examples: FileClient . parse_uri_prefix ( 's3://path/of/your/file' ) # 's3' Returns: str | None : Return the prefix of uri if the uri contains '://' else None .","title":"method parse_uri_prefix"},{"location":"documents/llutil.file_client/#method-put_2","text":"put ( obj : bytes , filepath : Union [ str , Path ]) \u2192 None Write data to a given filepath with 'wb' mode. Note: put should create a directory if the directory of filepath does not exist. Args: obj (bytes): Data to be written. filepath (str or Path): Path to write data.","title":"method put"},{"location":"documents/llutil.file_client/#method-put_text_2","text":"put_text ( obj : str , filepath : Union [ str , Path ]) \u2192 None Write data to a given filepath with 'w' mode. Note: put_text should create a directory if the directory of filepath does not exist. Args: obj (str): Data to be written. filepath (str or Path): Path to write data. encoding (str, optional): The encoding format used to open the `filepath . Default` : 'utf-8'.","title":"method put_text"},{"location":"documents/llutil.file_client/#classmethod-register_backend","text":"register_backend ( name , backend = None , force = False , prefixes = None ) Register a backend to FileClient. This method can be used as a normal class method or a decorator. .. code-block:: python class NewBackend(BaseStorageBackend): def get(self, filepath): return filepath def get_text(self, filepath): return filepath FileClient.register_backend('new', NewBackend) or .. code-block:: python @FileClient.register_backend('new') class NewBackend(BaseStorageBackend): def get(self, filepath): return filepath def get_text(self, filepath): return filepath Args: name (str): The name of the registered backend. backend (class, optional): The backend class to be registered, which must be a subclass of : class: BaseStorageBackend . When this method is used as a decorator, backend is None. Defaults to None. force (bool, optional): Whether to override the backend if the name has already been registered. Defaults to False. prefixes (str or list[str] or tuple[str], optional): The prefixes of the registered storage backend. Default : None. New in version 1.3.15.","title":"classmethod register_backend"},{"location":"documents/llutil.file_client/#method-remove_2","text":"remove ( filepath : Union [ str , Path ]) \u2192 None Remove a file. Args: filepath (str, Path): Path to be removed.","title":"method remove"},{"location":"documents/llutil.ignore_me/","text":"module llutil.ignore_me class IgnoreMe method __init__ __init__ ( * args , ** kwds )","title":"Llutil.ignore me"},{"location":"documents/llutil.ignore_me/#module-llutilignore_me","text":"","title":"module llutil.ignore_me"},{"location":"documents/llutil.ignore_me/#class-ignoreme","text":"","title":"class IgnoreMe"},{"location":"documents/llutil.ignore_me/#method-__init__","text":"__init__ ( * args , ** kwds )","title":"method __init__"},{"location":"documents/llutil.launcher.elastic_multiprocessing/","text":"module llutil.launcher.elastic_multiprocessing Global Variables IS_WINDOWS function tail_logfile tail_logfile ( header : str , file : str , dst : < class ' TextIO '>, finished : Event , interval_sec : float , lock : < built - in function allocate_lock > , progbar_events : Dict [ str , Event ] ) function start_processes start_processes ( name : str , entrypoint : Union [ Callable , str ], args : Dict [ int , Tuple ], envs : Dict [ int , Dict [ str , str ]], log_dir : str , start_method : str = 'spawn' , redirects : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , tee : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , progbar_events : Dict [ str , Event ] = None ) \u2192 PContext Starts n copies of entrypoint processes with the provided options. entrypoint is either a Callable (function) or a str (binary). The number of copies is determined by the number of entries for args and envs arguments, which need to have the same key set. args and env parameters are the arguments and environment variables to pass down to the entrypoint mapped by the replica index (local rank). All local ranks must be accounted for. That is, the keyset should be {0,1,...,(nprocs-1)} . .. note:: When the entrypoint is a binary ( str ), args can only be strings. If any other type is given, then it is casted to a string representation (e.g. str(arg1) ). Furthermore, a binary failure will only write an error.json error file if the main function is annotated with torch.distributed.elastic.multiprocessing.errors.record . For function launches, this is done by default and there is no need to manually annotate with the @record annotation. redirects and tees are bitmasks specifying which std stream(s) to redirect to a log file in the log_dir . Valid mask values are defined in Std . To redirect/tee only certain local ranks, pass redirects as a map with the key as the local rank to specify the redirect behavior for. Any missing local ranks will default to Std.NONE . tee acts like the unix \"tee\" command in that it redirects + prints to console. To avoid worker stdout/stderr from printing to console, use the redirects parameter. For each process, the log_dir will contain: . {local_rank}/error.json : if the process failed, a file with the error info . {local_rank}/stdout.json : if redirect & STDOUT == STDOUT . {local_rank}/stderr.json : if redirect & STDERR == STDERR .. note:: It is expected that the log_dir exists, is empty, and is a directory. Example: : log_dir = \"/tmp/test\" # ok; two copies of foo: foo(\"bar0\"), foo(\"bar1\") start_processes( name=\"trainer\", entrypoint=foo, args:{0:(\"bar0\",), 1:(\"bar1\",), envs:{0:{}, 1:{}}, log_dir=log_dir ) # invalid; envs missing for local rank 1 start_processes( name=\"trainer\", entrypoint=foo, args:{0:(\"bar0\",), 1:(\"bar1\",), envs:{0:{}}, log_dir=log_dir ) # ok; two copies of /usr/bin/touch: touch file1, touch file2 start_processes( name=\"trainer\", entrypoint=\"/usr/bin/touch\", args:{0:(\"file1\",), 1:(\"file2\",), envs:{0:{}, 1:{}}, log_dir=log_dir ) # caution; arguments casted to string, runs: # echo \"1\" \"2\" \"3\" and echo \"[1, 2, 3]\" start_processes( name=\"trainer\", entrypoint=\"/usr/bin/echo\", args:{0:(1,2,3), 1:([1,2,3],), envs:{0:{}, 1:{}}, log_dir=log_dir ) Args: name : a human readable short name that describes what the processes are (used as header when tee'ing stdout/stderr outputs) entrypoint : either a Callable (function) or cmd (binary) args : arguments to each replica envs : env vars to each replica log_dir : directory used to write log files nprocs : number of copies to create (one on each process) start_method : multiprocessing start method (spawn, fork, forkserver) ignored for binaries redirects : which std streams to redirect to a log file tees : which std streams to redirect + print to console class TailLog Tails the given log files. The log files do not have to exist when the start() method is called. The tail-er will gracefully wait until the log files are created by the producer and will tail the contents of the log files until the stop() method is called. .. warning:: TailLog will wait indefinitely for the log file to be created! Each log file's line will be suffixed with a header of the form: [{name}{idx}]: , where the name is user-provided and idx is the index of the log file in the log_files mapping. Usage: : log_files = {0: \"/tmp/0_stdout.log\", 1: \"/tmp/1_stdout.log\"} tailer = TailLog(\"trainer\", log_files, sys.stdout).start() # actually run the trainers to produce 0_stdout.log and 1_stdout.log run_trainers() tailer.stop() # once run_trainers() start writing the ##_stdout.log files # the tailer will print to sys.stdout: # >>> [trainer0]:log_line1 # >>> [trainer1]:log_line1 # >>> [trainer0]:log_line2 # >>> [trainer0]:log_line3 # >>> [trainer1]:log_line2 .. note:: Due to buffering log lines between files may not necessarily be printed out in order. You should configure your application's logger to suffix each log line with a proper timestamp. method __init__ __init__ ( name : str , log_files : Dict [ int , str ], dst : < class ' TextIO '>, interval_sec : float = 0.1 , progbar_events = None ) method start start () \u2192 TailLog method stop stop () \u2192 None method stopped stopped () \u2192 bool class PContext The base class that standardizes operations over a set of processes that are launched via different mechanisms. The name PContext is intentional to disambiguate with torch.multiprocessing.ProcessContext . .. warning:: stdouts and stderrs should ALWAYS be a superset of tee_stdouts and tee_stderrs (respectively) this is b/c tee is implemented as a redirect + tail -f method __init__ __init__ ( name : str , entrypoint : Union [ Callable , str ], args : Dict [ int , Tuple ], envs : Dict [ int , Dict [ str , str ]], stdouts : Dict [ int , str ], stderrs : Dict [ int , str ], tee_stdouts : Dict [ int , str ], tee_stderrs : Dict [ int , str ], error_files : Dict [ int , str ], progbar_events : Dict [ str , Event ] ) method close close ( death_sig : Optional [ Signals ] = None , timeout : int = 30 ) \u2192 None Terminates all processes managed by this context and cleans up any meta resources (e.g. redirect, error_file files). Args: death_sig : Death signal to terminate porcesses. timeout : Time to wait for processes to finish, if process is still alive after this time, it will be terminated via SIGKILL. method pids pids () \u2192 Dict [ int , int ] Returns pids of processes mapped by their respective local_ranks method start start () \u2192 None Start processes using parameters defined in the constructor. method wait wait ( timeout : float = - 1 , period : float = 1 ) \u2192 Optional [ RunProcsResult ] Waits for the specified timeout seconds, polling every period seconds for the processes to be done. Returns None if the processes are still running on timeout expiry. Negative timeout values are interpreted as \"wait-forever\". A timeout value of zero simply queries the status of the processes (e.g. equivalent to a poll). ..note: Multiprocesing library registers SIGTERM and SIGINT signal handlers that raise SignalException when the signals received. It is up to the consumer of the code to properly handle the exception. It is important not to swallow the exception otherwise the process would not terminate. Example of the typical workflow can be: .. code-block:: python pc = start_processes(...) try: pc.wait(1) .. do some other work except SignalException as e: pc.shutdown(e.sigval, timeout=30) If SIGTERM or SIGINT occurs, the code above will try to shutdown child processes by propagating received signal. If child processes will not terminate in the timeout time, the process will send the SIGKILL. class MultiprocessContext PContext holding worker processes invoked as a function. method __init__ __init__ ( name : str , entrypoint : Callable , args : Dict [ int , Tuple ], envs : Dict [ int , Dict [ str , str ]], stdouts : Dict [ int , str ], stderrs : Dict [ int , str ], tee_stdouts : Dict [ int , str ], tee_stderrs : Dict [ int , str ], error_files : Dict [ int , str ], start_method : str , progbar_events ) method close close ( death_sig : Optional [ Signals ] = None , timeout : int = 30 ) \u2192 None Terminates all processes managed by this context and cleans up any meta resources (e.g. redirect, error_file files). Args: death_sig : Death signal to terminate porcesses. timeout : Time to wait for processes to finish, if process is still alive after this time, it will be terminated via SIGKILL. method pids pids () \u2192 Dict [ int , int ] method start start () \u2192 None Start processes using parameters defined in the constructor. method wait wait ( timeout : float = - 1 , period : float = 1 ) \u2192 Optional [ RunProcsResult ] Waits for the specified timeout seconds, polling every period seconds for the processes to be done. Returns None if the processes are still running on timeout expiry. Negative timeout values are interpreted as \"wait-forever\". A timeout value of zero simply queries the status of the processes (e.g. equivalent to a poll). ..note: Multiprocesing library registers SIGTERM and SIGINT signal handlers that raise SignalException when the signals received. It is up to the consumer of the code to properly handle the exception. It is important not to swallow the exception otherwise the process would not terminate. Example of the typical workflow can be: .. code-block:: python pc = start_processes(...) try: pc.wait(1) .. do some other work except SignalException as e: pc.shutdown(e.sigval, timeout=30) If SIGTERM or SIGINT occurs, the code above will try to shutdown child processes by propagating received signal. If child processes will not terminate in the timeout time, the process will send the SIGKILL.","title":"Llutil.launcher.elastic multiprocessing"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#module-llutillauncherelastic_multiprocessing","text":"","title":"module llutil.launcher.elastic_multiprocessing"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#global-variables","text":"IS_WINDOWS","title":"Global Variables"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#function-tail_logfile","text":"tail_logfile ( header : str , file : str , dst : < class ' TextIO '>, finished : Event , interval_sec : float , lock : < built - in function allocate_lock > , progbar_events : Dict [ str , Event ] )","title":"function tail_logfile"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#function-start_processes","text":"start_processes ( name : str , entrypoint : Union [ Callable , str ], args : Dict [ int , Tuple ], envs : Dict [ int , Dict [ str , str ]], log_dir : str , start_method : str = 'spawn' , redirects : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , tee : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , progbar_events : Dict [ str , Event ] = None ) \u2192 PContext Starts n copies of entrypoint processes with the provided options. entrypoint is either a Callable (function) or a str (binary). The number of copies is determined by the number of entries for args and envs arguments, which need to have the same key set. args and env parameters are the arguments and environment variables to pass down to the entrypoint mapped by the replica index (local rank). All local ranks must be accounted for. That is, the keyset should be {0,1,...,(nprocs-1)} . .. note:: When the entrypoint is a binary ( str ), args can only be strings. If any other type is given, then it is casted to a string representation (e.g. str(arg1) ). Furthermore, a binary failure will only write an error.json error file if the main function is annotated with torch.distributed.elastic.multiprocessing.errors.record . For function launches, this is done by default and there is no need to manually annotate with the @record annotation. redirects and tees are bitmasks specifying which std stream(s) to redirect to a log file in the log_dir . Valid mask values are defined in Std . To redirect/tee only certain local ranks, pass redirects as a map with the key as the local rank to specify the redirect behavior for. Any missing local ranks will default to Std.NONE . tee acts like the unix \"tee\" command in that it redirects + prints to console. To avoid worker stdout/stderr from printing to console, use the redirects parameter. For each process, the log_dir will contain:","title":"function start_processes"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#local_rankerrorjson-if-the-process-failed-a-file-with-the-error-info","text":"","title":". {local_rank}/error.json: if the process failed, a file with the error info"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#local_rankstdoutjson-if-redirect-stdout-stdout","text":"","title":". {local_rank}/stdout.json: if redirect &amp; STDOUT == STDOUT"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#local_rankstderrjson-if-redirect-stderr-stderr","text":".. note:: It is expected that the log_dir exists, is empty, and is a directory. Example: : log_dir = \"/tmp/test\" # ok; two copies of foo: foo(\"bar0\"), foo(\"bar1\") start_processes( name=\"trainer\", entrypoint=foo, args:{0:(\"bar0\",), 1:(\"bar1\",), envs:{0:{}, 1:{}}, log_dir=log_dir ) # invalid; envs missing for local rank 1 start_processes( name=\"trainer\", entrypoint=foo, args:{0:(\"bar0\",), 1:(\"bar1\",), envs:{0:{}}, log_dir=log_dir ) # ok; two copies of /usr/bin/touch: touch file1, touch file2 start_processes( name=\"trainer\", entrypoint=\"/usr/bin/touch\", args:{0:(\"file1\",), 1:(\"file2\",), envs:{0:{}, 1:{}}, log_dir=log_dir ) # caution; arguments casted to string, runs: # echo \"1\" \"2\" \"3\" and echo \"[1, 2, 3]\" start_processes( name=\"trainer\", entrypoint=\"/usr/bin/echo\", args:{0:(1,2,3), 1:([1,2,3],), envs:{0:{}, 1:{}}, log_dir=log_dir ) Args: name : a human readable short name that describes what the processes are (used as header when tee'ing stdout/stderr outputs) entrypoint : either a Callable (function) or cmd (binary) args : arguments to each replica envs : env vars to each replica log_dir : directory used to write log files nprocs : number of copies to create (one on each process) start_method : multiprocessing start method (spawn, fork, forkserver) ignored for binaries redirects : which std streams to redirect to a log file tees : which std streams to redirect + print to console","title":". {local_rank}/stderr.json: if redirect &amp; STDERR == STDERR"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#class-taillog","text":"Tails the given log files. The log files do not have to exist when the start() method is called. The tail-er will gracefully wait until the log files are created by the producer and will tail the contents of the log files until the stop() method is called. .. warning:: TailLog will wait indefinitely for the log file to be created! Each log file's line will be suffixed with a header of the form: [{name}{idx}]: , where the name is user-provided and idx is the index of the log file in the log_files mapping. Usage: : log_files = {0: \"/tmp/0_stdout.log\", 1: \"/tmp/1_stdout.log\"} tailer = TailLog(\"trainer\", log_files, sys.stdout).start() # actually run the trainers to produce 0_stdout.log and 1_stdout.log run_trainers() tailer.stop() # once run_trainers() start writing the ##_stdout.log files # the tailer will print to sys.stdout: # >>> [trainer0]:log_line1 # >>> [trainer1]:log_line1 # >>> [trainer0]:log_line2 # >>> [trainer0]:log_line3 # >>> [trainer1]:log_line2 .. note:: Due to buffering log lines between files may not necessarily be printed out in order. You should configure your application's logger to suffix each log line with a proper timestamp.","title":"class TailLog"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-__init__","text":"__init__ ( name : str , log_files : Dict [ int , str ], dst : < class ' TextIO '>, interval_sec : float = 0.1 , progbar_events = None )","title":"method __init__"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-start","text":"start () \u2192 TailLog","title":"method start"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-stop","text":"stop () \u2192 None","title":"method stop"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-stopped","text":"stopped () \u2192 bool","title":"method stopped"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#class-pcontext","text":"The base class that standardizes operations over a set of processes that are launched via different mechanisms. The name PContext is intentional to disambiguate with torch.multiprocessing.ProcessContext . .. warning:: stdouts and stderrs should ALWAYS be a superset of tee_stdouts and tee_stderrs (respectively) this is b/c tee is implemented as a redirect + tail -f","title":"class PContext"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-__init___1","text":"__init__ ( name : str , entrypoint : Union [ Callable , str ], args : Dict [ int , Tuple ], envs : Dict [ int , Dict [ str , str ]], stdouts : Dict [ int , str ], stderrs : Dict [ int , str ], tee_stdouts : Dict [ int , str ], tee_stderrs : Dict [ int , str ], error_files : Dict [ int , str ], progbar_events : Dict [ str , Event ] )","title":"method __init__"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-close","text":"close ( death_sig : Optional [ Signals ] = None , timeout : int = 30 ) \u2192 None Terminates all processes managed by this context and cleans up any meta resources (e.g. redirect, error_file files). Args: death_sig : Death signal to terminate porcesses. timeout : Time to wait for processes to finish, if process is still alive after this time, it will be terminated via SIGKILL.","title":"method close"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-pids","text":"pids () \u2192 Dict [ int , int ] Returns pids of processes mapped by their respective local_ranks","title":"method pids"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-start_1","text":"start () \u2192 None Start processes using parameters defined in the constructor.","title":"method start"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-wait","text":"wait ( timeout : float = - 1 , period : float = 1 ) \u2192 Optional [ RunProcsResult ] Waits for the specified timeout seconds, polling every period seconds for the processes to be done. Returns None if the processes are still running on timeout expiry. Negative timeout values are interpreted as \"wait-forever\". A timeout value of zero simply queries the status of the processes (e.g. equivalent to a poll). ..note: Multiprocesing library registers SIGTERM and SIGINT signal handlers that raise SignalException when the signals received. It is up to the consumer of the code to properly handle the exception. It is important not to swallow the exception otherwise the process would not terminate. Example of the typical workflow can be: .. code-block:: python pc = start_processes(...) try: pc.wait(1) .. do some other work except SignalException as e: pc.shutdown(e.sigval, timeout=30) If SIGTERM or SIGINT occurs, the code above will try to shutdown child processes by propagating received signal. If child processes will not terminate in the timeout time, the process will send the SIGKILL.","title":"method wait"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#class-multiprocesscontext","text":"PContext holding worker processes invoked as a function.","title":"class MultiprocessContext"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-__init___2","text":"__init__ ( name : str , entrypoint : Callable , args : Dict [ int , Tuple ], envs : Dict [ int , Dict [ str , str ]], stdouts : Dict [ int , str ], stderrs : Dict [ int , str ], tee_stdouts : Dict [ int , str ], tee_stderrs : Dict [ int , str ], error_files : Dict [ int , str ], start_method : str , progbar_events )","title":"method __init__"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-close_1","text":"close ( death_sig : Optional [ Signals ] = None , timeout : int = 30 ) \u2192 None Terminates all processes managed by this context and cleans up any meta resources (e.g. redirect, error_file files). Args: death_sig : Death signal to terminate porcesses. timeout : Time to wait for processes to finish, if process is still alive after this time, it will be terminated via SIGKILL.","title":"method close"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-pids_1","text":"pids () \u2192 Dict [ int , int ]","title":"method pids"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-start_2","text":"start () \u2192 None Start processes using parameters defined in the constructor.","title":"method start"},{"location":"documents/llutil.launcher.elastic_multiprocessing/#method-wait_1","text":"wait ( timeout : float = - 1 , period : float = 1 ) \u2192 Optional [ RunProcsResult ] Waits for the specified timeout seconds, polling every period seconds for the processes to be done. Returns None if the processes are still running on timeout expiry. Negative timeout values are interpreted as \"wait-forever\". A timeout value of zero simply queries the status of the processes (e.g. equivalent to a poll). ..note: Multiprocesing library registers SIGTERM and SIGINT signal handlers that raise SignalException when the signals received. It is up to the consumer of the code to properly handle the exception. It is important not to swallow the exception otherwise the process would not terminate. Example of the typical workflow can be: .. code-block:: python pc = start_processes(...) try: pc.wait(1) .. do some other work except SignalException as e: pc.shutdown(e.sigval, timeout=30) If SIGTERM or SIGINT occurs, the code above will try to shutdown child processes by propagating received signal. If child processes will not terminate in the timeout time, the process will send the SIGKILL.","title":"method wait"},{"location":"documents/llutil.launcher.events/","text":"module llutil.launcher.events Global Variables global_shared_events class Events Communicate among main process (agent) and subprocesses (workers). method __init__ __init__ ( start_method )","title":"Llutil.launcher.events"},{"location":"documents/llutil.launcher.events/#module-llutillauncherevents","text":"","title":"module llutil.launcher.events"},{"location":"documents/llutil.launcher.events/#global-variables","text":"global_shared_events","title":"Global Variables"},{"location":"documents/llutil.launcher.events/#class-events","text":"Communicate among main process (agent) and subprocesses (workers).","title":"class Events"},{"location":"documents/llutil.launcher.events/#method-__init__","text":"__init__ ( start_method )","title":"method __init__"},{"location":"documents/llutil.launcher.launch_agent/","text":"module llutil.launcher.launch_agent function launch_agent launch_agent ( config : LaunchConfig , entrypoint : Optional [ Callable , str ], args : List [ Any ], ice_events : Events ) \u2192 Dict [ int , Any ] class LaunchConfig Creates a rendezvous config. Args: min_nodes : Minimum amount of nodes that the user function will be launched on. Elastic agent ensures that the user function start only when the min_nodes amount enters the rendezvous. max_nodes : Maximum amount of nodes that the user function will be launched on. nproc_per_node : On each node the elastic agent will launch this amount of workers that will execute user defined function. rdzv_backend : rdzv_backend to use in the rendezvous (zeus-adapter, etcd). rdzv_endpoint : The endpoint of the rdzv sync. storage. rdzv_configs : Key, value pair that specifies rendezvous specific configuration. rdzv_timeout : Legacy argument that specifies timeout for the rendezvous. It is going to be removed in future versions, see the note below. The default timeout is 900 seconds. rdzv_id : The unique run id of the job (if not passed a unique one will be deduced from run environment - flow workflow id in flow - or auto generated). role : User defined role of the worker (defaults to \"trainer\"). max_restarts : The maximum amount of restarts that elastic agent will conduct on workers before failure. monitor_interval : The interval in seconds that is used by the elastic_agent as a period of monitoring workers. start_method : The method is used by the elastic agent to start the workers (spawn, fork, forkserver). log_dir : base log directory where log files are written. If not set, one is created in a tmp dir but NOT removed on exit. redirects : configuration to redirect stdout/stderr to log files. Pass a single Std enum to redirect all workers, or a mapping keyed by local_rank to selectively redirect. tee : configuration to \"tee\" stdout/stderr to console + log file. metrics_cfg : configuration to initialize metrics. ..note: rdzv_timeout is a legacy argument that will be removed in future. Set the timeout via rdzv_configs['timeout'] function __init__ __init__ ( min_nodes : int , max_nodes : int , nproc_per_node : int , run_id : str = '' , role : str = 'default_role' , rdzv_endpoint : str = '' , rdzv_backend : str = 'etcd' , rdzv_configs : Dict [ str , Any ] = < factory > , rdzv_timeout : int = - 1 , max_restarts : int = 3 , monitor_interval : float = 30 , start_method : str = 'spawn' , log_dir : Optional [ str ] = None , redirects : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , tee : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , metrics_cfg : Dict [ str , str ] = < factory > ) \u2192 None","title":"Llutil.launcher.launch agent"},{"location":"documents/llutil.launcher.launch_agent/#module-llutillauncherlaunch_agent","text":"","title":"module llutil.launcher.launch_agent"},{"location":"documents/llutil.launcher.launch_agent/#function-launch_agent","text":"launch_agent ( config : LaunchConfig , entrypoint : Optional [ Callable , str ], args : List [ Any ], ice_events : Events ) \u2192 Dict [ int , Any ]","title":"function launch_agent"},{"location":"documents/llutil.launcher.launch_agent/#class-launchconfig","text":"Creates a rendezvous config. Args: min_nodes : Minimum amount of nodes that the user function will be launched on. Elastic agent ensures that the user function start only when the min_nodes amount enters the rendezvous. max_nodes : Maximum amount of nodes that the user function will be launched on. nproc_per_node : On each node the elastic agent will launch this amount of workers that will execute user defined function. rdzv_backend : rdzv_backend to use in the rendezvous (zeus-adapter, etcd). rdzv_endpoint : The endpoint of the rdzv sync. storage. rdzv_configs : Key, value pair that specifies rendezvous specific configuration. rdzv_timeout : Legacy argument that specifies timeout for the rendezvous. It is going to be removed in future versions, see the note below. The default timeout is 900 seconds. rdzv_id : The unique run id of the job (if not passed a unique one will be deduced from run environment - flow workflow id in flow - or auto generated). role : User defined role of the worker (defaults to \"trainer\"). max_restarts : The maximum amount of restarts that elastic agent will conduct on workers before failure. monitor_interval : The interval in seconds that is used by the elastic_agent as a period of monitoring workers. start_method : The method is used by the elastic agent to start the workers (spawn, fork, forkserver). log_dir : base log directory where log files are written. If not set, one is created in a tmp dir but NOT removed on exit. redirects : configuration to redirect stdout/stderr to log files. Pass a single Std enum to redirect all workers, or a mapping keyed by local_rank to selectively redirect. tee : configuration to \"tee\" stdout/stderr to console + log file. metrics_cfg : configuration to initialize metrics. ..note: rdzv_timeout is a legacy argument that will be removed in future. Set the timeout via rdzv_configs['timeout']","title":"class LaunchConfig"},{"location":"documents/llutil.launcher.launch_agent/#function-__init__","text":"__init__ ( min_nodes : int , max_nodes : int , nproc_per_node : int , run_id : str = '' , role : str = 'default_role' , rdzv_endpoint : str = '' , rdzv_backend : str = 'etcd' , rdzv_configs : Dict [ str , Any ] = < factory > , rdzv_timeout : int = - 1 , max_restarts : int = 3 , monitor_interval : float = 30 , start_method : str = 'spawn' , log_dir : Optional [ str ] = None , redirects : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , tee : Union [ Std , Dict [ int , Std ]] = < Std . NONE : 0 > , metrics_cfg : Dict [ str , str ] = < factory > ) \u2192 None","title":"function __init__"},{"location":"documents/llutil.launcher.launcher/","text":"module llutil.launcher.launcher function get_current_launcher get_current_launcher () \u2192 ElasticLauncher class ElasticLauncher A helper Configurable class for torchrun and torch.distributed.launch . PyTorch's elastic launch ability is embeded in this Configurable, for details please see here . HyperGraph.run() uses this class to launch multiple processes. Directly usage is also possible (see the example below). Example: def worker ( launcher ): print ( \"rank\" , launcher . rank ) print ( \"local_rank\" , launcher . local_rank ) print ( \"device\" , launcher . assigned_device ) if __name__ == \"__main__\" : launcher = ElasticLauncher ( \"cuda:*\" ) . freeze () launcher ( worker , launcher ) method __init__ __init__ ( * args , ** kwds ) \u2192 None property assigned_device property devices property dist_backend property group_rank property group_world_size property local_rank property local_world_size property master_addr property master_port property max_restarts property rank property rdzv_id property restart_count property role_name property role_rank property role_world_size property world_size","title":"Llutil.launcher.launcher"},{"location":"documents/llutil.launcher.launcher/#module-llutillauncherlauncher","text":"","title":"module llutil.launcher.launcher"},{"location":"documents/llutil.launcher.launcher/#function-get_current_launcher","text":"get_current_launcher () \u2192 ElasticLauncher","title":"function get_current_launcher"},{"location":"documents/llutil.launcher.launcher/#class-elasticlauncher","text":"A helper Configurable class for torchrun and torch.distributed.launch . PyTorch's elastic launch ability is embeded in this Configurable, for details please see here . HyperGraph.run() uses this class to launch multiple processes. Directly usage is also possible (see the example below). Example: def worker ( launcher ): print ( \"rank\" , launcher . rank ) print ( \"local_rank\" , launcher . local_rank ) print ( \"device\" , launcher . assigned_device ) if __name__ == \"__main__\" : launcher = ElasticLauncher ( \"cuda:*\" ) . freeze () launcher ( worker , launcher )","title":"class ElasticLauncher"},{"location":"documents/llutil.launcher.launcher/#method-__init__","text":"__init__ ( * args , ** kwds ) \u2192 None","title":"method __init__"},{"location":"documents/llutil.launcher.launcher/#property-assigned_device","text":"","title":"property assigned_device"},{"location":"documents/llutil.launcher.launcher/#property-devices","text":"","title":"property devices"},{"location":"documents/llutil.launcher.launcher/#property-dist_backend","text":"","title":"property dist_backend"},{"location":"documents/llutil.launcher.launcher/#property-group_rank","text":"","title":"property group_rank"},{"location":"documents/llutil.launcher.launcher/#property-group_world_size","text":"","title":"property group_world_size"},{"location":"documents/llutil.launcher.launcher/#property-local_rank","text":"","title":"property local_rank"},{"location":"documents/llutil.launcher.launcher/#property-local_world_size","text":"","title":"property local_world_size"},{"location":"documents/llutil.launcher.launcher/#property-master_addr","text":"","title":"property master_addr"},{"location":"documents/llutil.launcher.launcher/#property-master_port","text":"","title":"property master_port"},{"location":"documents/llutil.launcher.launcher/#property-max_restarts","text":"","title":"property max_restarts"},{"location":"documents/llutil.launcher.launcher/#property-rank","text":"","title":"property rank"},{"location":"documents/llutil.launcher.launcher/#property-rdzv_id","text":"","title":"property rdzv_id"},{"location":"documents/llutil.launcher.launcher/#property-restart_count","text":"","title":"property restart_count"},{"location":"documents/llutil.launcher.launcher/#property-role_name","text":"","title":"property role_name"},{"location":"documents/llutil.launcher.launcher/#property-role_rank","text":"","title":"property role_rank"},{"location":"documents/llutil.launcher.launcher/#property-role_world_size","text":"","title":"property role_world_size"},{"location":"documents/llutil.launcher.launcher/#property-world_size","text":"","title":"property world_size"},{"location":"documents/llutil.launcher.local_elastic_agent/","text":"module llutil.launcher.local_elastic_agent Global Variables DEFAULT_ROLE class LocalElasticAgent An implementation of :py:class: torchelastic.agent.server.ElasticAgent that handles host-local workers. This agent is deployed per host and is configured to spawn n workers. When using GPUs, n maps to the number of GPUs available on the host. The local agent does not communicate to other local agents deployed on other hosts, even if the workers may communicate inter-host. The worker id is interpreted to be a local process. The agent starts and stops all worker processes as a single unit. The worker function and argument passed to the worker function must be python multiprocessing compatible. To pass multiprocessing data structures to the workers you may create the data structure in the same multiprocessing context as the specified start_method and pass it as a function argument. The exit_barrier_timeout specifies the amount of time (in seconds) to wait for other agents to finish. This acts as a safety net to handle cases where workers finish at different times, to prevent agents from viewing workers that finished early as a scale-down event. It is strongly advised that the user code deal with ensuring that workers are terminated in a synchronous manner rather than relying on the exit_barrier_timeout. Example launching function : def trainer(args) -> str: return \"do train\" def main(): start_method=\"spawn\" shared_queue= multiprocessing.get_context(start_method).Queue() spec = WorkerSpec( role=\"trainer\", local_world_size=nproc_per_process, entrypoint=trainer, args=(\"foobar\",), ...<OTHER_PARAMS...>) agent = LocalElasticAgent(spec, start_method) results = agent.run() if results.is_failed(): print(\"trainer failed\") else: print(f\"rank 0 return value: {results.return_values[0]}\") # prints -> rank 0 return value: do train Example launching binary : def main(): spec = WorkerSpec( role=\"trainer\", local_world_size=nproc_per_process, entrypoint=\"/usr/local/bin/trainer\", args=(\"--trainer_args\", \"foobar\"), ...<OTHER_PARAMS...>) agent = LocalElasticAgent(spec) results = agent.run() if not results.is_failed(): print(\"binary launches do not have return values\") <a href=\"https://github.com/tjyuyao/ice-learn/blob/main/ice/llutil/launcher/local_elastic_agent.py#L109\"><img align=\"right\" style=\"float:right;\" src=\"https://img.shields.io/badge/-source-cccccc?style=flat-square\"></a> ### <kbd>method</kbd> `__init__` ```python __init__( spec: WorkerSpec, start_method='spawn', exit_barrier_timeout: float = 300, log_dir: Optional[str] = None, events: Events = None ) method run run ( role : str = 'default' ) \u2192 RunResult","title":"Llutil.launcher.local elastic agent"},{"location":"documents/llutil.launcher.local_elastic_agent/#module-llutillauncherlocal_elastic_agent","text":"","title":"module llutil.launcher.local_elastic_agent"},{"location":"documents/llutil.launcher.local_elastic_agent/#global-variables","text":"DEFAULT_ROLE","title":"Global Variables"},{"location":"documents/llutil.launcher.local_elastic_agent/#class-localelasticagent","text":"An implementation of :py:class: torchelastic.agent.server.ElasticAgent that handles host-local workers. This agent is deployed per host and is configured to spawn n workers. When using GPUs, n maps to the number of GPUs available on the host. The local agent does not communicate to other local agents deployed on other hosts, even if the workers may communicate inter-host. The worker id is interpreted to be a local process. The agent starts and stops all worker processes as a single unit. The worker function and argument passed to the worker function must be python multiprocessing compatible. To pass multiprocessing data structures to the workers you may create the data structure in the same multiprocessing context as the specified start_method and pass it as a function argument. The exit_barrier_timeout specifies the amount of time (in seconds) to wait for other agents to finish. This acts as a safety net to handle cases where workers finish at different times, to prevent agents from viewing workers that finished early as a scale-down event. It is strongly advised that the user code deal with ensuring that workers are terminated in a synchronous manner rather than relying on the exit_barrier_timeout. Example launching function : def trainer(args) -> str: return \"do train\" def main(): start_method=\"spawn\" shared_queue= multiprocessing.get_context(start_method).Queue() spec = WorkerSpec( role=\"trainer\", local_world_size=nproc_per_process, entrypoint=trainer, args=(\"foobar\",), ...<OTHER_PARAMS...>) agent = LocalElasticAgent(spec, start_method) results = agent.run() if results.is_failed(): print(\"trainer failed\") else: print(f\"rank 0 return value: {results.return_values[0]}\") # prints -> rank 0 return value: do train Example launching binary : def main(): spec = WorkerSpec( role=\"trainer\", local_world_size=nproc_per_process, entrypoint=\"/usr/local/bin/trainer\", args=(\"--trainer_args\", \"foobar\"), ...<OTHER_PARAMS...>) agent = LocalElasticAgent(spec) results = agent.run() if not results.is_failed(): print(\"binary launches do not have return values\") <a href=\"https://github.com/tjyuyao/ice-learn/blob/main/ice/llutil/launcher/local_elastic_agent.py#L109\"><img align=\"right\" style=\"float:right;\" src=\"https://img.shields.io/badge/-source-cccccc?style=flat-square\"></a> ### <kbd>method</kbd> `__init__` ```python __init__( spec: WorkerSpec, start_method='spawn', exit_barrier_timeout: float = 300, log_dir: Optional[str] = None, events: Events = None )","title":"class LocalElasticAgent"},{"location":"documents/llutil.launcher.local_elastic_agent/#method-run","text":"run ( role : str = 'default' ) \u2192 RunResult","title":"method run"},{"location":"documents/llutil.launcher/","text":"module llutil.launcher Global Variables events elastic_multiprocessing local_elastic_agent : # Copyright (c) Facebook, Inc. and its affiliates. All rights reserved. This source code is licensed under the BSD-style license found in the LICENSE file in the root directory of this source tree. launch_agent : # Copyright (c) Facebook, Inc. and its affiliates. All rights reserved. This source code is licensed under the BSD-style license found in the LICENSE file in the root directory of this source tree. launcher global_shared_events","title":"Llutil.launcher"},{"location":"documents/llutil.launcher/#module-llutillauncher","text":"","title":"module llutil.launcher"},{"location":"documents/llutil.launcher/#global-variables","text":"events elastic_multiprocessing local_elastic_agent : # Copyright (c) Facebook, Inc. and its affiliates.","title":"Global Variables"},{"location":"documents/llutil.launcher/#all-rights-reserved","text":"","title":"All rights reserved."},{"location":"documents/llutil.launcher/#_1","text":"","title":""},{"location":"documents/llutil.launcher/#this-source-code-is-licensed-under-the-bsd-style-license-found-in-the","text":"","title":"This source code is licensed under the BSD-style license found in the"},{"location":"documents/llutil.launcher/#license-file-in-the-root-directory-of-this-source-tree","text":"launch_agent : # Copyright (c) Facebook, Inc. and its affiliates.","title":"LICENSE file in the root directory of this source tree."},{"location":"documents/llutil.launcher/#all-rights-reserved_1","text":"","title":"All rights reserved."},{"location":"documents/llutil.launcher/#_2","text":"","title":""},{"location":"documents/llutil.launcher/#this-source-code-is-licensed-under-the-bsd-style-license-found-in-the_1","text":"","title":"This source code is licensed under the BSD-style license found in the"},{"location":"documents/llutil.launcher/#license-file-in-the-root-directory-of-this-source-tree_1","text":"launcher global_shared_events","title":"LICENSE file in the root directory of this source tree."},{"location":"documents/llutil.logger/","text":"module llutil.logger logging utilities. function get_logger get_logger ( name : Optional [ str ] = None ) set up a simple logger that writes into stderr. The loglevel is fetched from the LOGLEVEL env. variable or WARNING as default. The function will use the module name of the caller if no name is provided. Args: name : Name of the logger. If no name provided, the name will be derived from the call stack.","title":"Llutil.logger"},{"location":"documents/llutil.logger/#module-llutillogger","text":"logging utilities.","title":"module llutil.logger"},{"location":"documents/llutil.logger/#function-get_logger","text":"get_logger ( name : Optional [ str ] = None ) set up a simple logger that writes into stderr. The loglevel is fetched from the LOGLEVEL env. variable or WARNING as default. The function will use the module name of the caller if no name is provided. Args: name : Name of the logger. If no name provided, the name will be derived from the call stack.","title":"function get_logger"},{"location":"documents/llutil.logging/","text":"module llutil.logging logging utilities. function get_logger get_logger ( name : Optional [ str ] = None ) set up a simple logger that writes into stderr. The loglevel is fetched from the LOGLEVEL env. variable or WARNING as default. The function will use the module name of the caller if no name is provided. Args: name : Name of the logger. If no name provided, the name will be derived from the call stack.","title":"Llutil.logging"},{"location":"documents/llutil.logging/#module-llutillogging","text":"logging utilities.","title":"module llutil.logging"},{"location":"documents/llutil.logging/#function-get_logger","text":"get_logger ( name : Optional [ str ] = None ) set up a simple logger that writes into stderr. The loglevel is fetched from the LOGLEVEL env. variable or WARNING as default. The function will use the module name of the caller if no name is provided. Args: name : Name of the logger. If no name provided, the name will be derived from the call stack.","title":"function get_logger"},{"location":"documents/llutil/","text":"module llutil implements low-level utilities.","title":"Llutil"},{"location":"documents/llutil/#module-llutil","text":"implements low-level utilities.","title":"module llutil"},{"location":"documents/llutil.multiprocessing/","text":"module llutil.multiprocessing a drop-in replacement for torch.multiprocessing . ice.llutil.multiprocessing is a modified version of torch.multiprocessing . It's designed to change import torch.multiprocessing as mp to from ice import multiprocessing as mp to have all the lambda functions, closures as well as pytorch tensors sent through processes in Data Distributed Parallel paradigm. Because of the similarity of APIs we do not document most of this package contents, and we recommend referring to very good docs of the original module. Global Variables reductions function in_main_process in_main_process () Whether current process is worker process or main process. function enable_auto_freeze enable_auto_freeze ( enable : bool = True ) function auto_freeze_enabled auto_freeze_enabled ()","title":"Llutil.multiprocessing"},{"location":"documents/llutil.multiprocessing/#module-llutilmultiprocessing","text":"a drop-in replacement for torch.multiprocessing . ice.llutil.multiprocessing is a modified version of torch.multiprocessing . It's designed to change import torch.multiprocessing as mp to from ice import multiprocessing as mp to have all the lambda functions, closures as well as pytorch tensors sent through processes in Data Distributed Parallel paradigm. Because of the similarity of APIs we do not document most of this package contents, and we recommend referring to very good docs of the original module.","title":"module llutil.multiprocessing"},{"location":"documents/llutil.multiprocessing/#global-variables","text":"reductions","title":"Global Variables"},{"location":"documents/llutil.multiprocessing/#function-in_main_process","text":"in_main_process () Whether current process is worker process or main process.","title":"function in_main_process"},{"location":"documents/llutil.multiprocessing/#function-enable_auto_freeze","text":"enable_auto_freeze ( enable : bool = True )","title":"function enable_auto_freeze"},{"location":"documents/llutil.multiprocessing/#function-auto_freeze_enabled","text":"auto_freeze_enabled ()","title":"function auto_freeze_enabled"},{"location":"documents/llutil.print/","text":"module llutil.print function format_size format_size ( size ) Format a byte count as a human readable file size. format_size ( 0 ) # '0 bytes' format_size ( 1 ) # '1 byte' format_size ( 5 ) # '5 bytes' format_size ( 1024 ) # '1 KiB'","title":"Llutil.print"},{"location":"documents/llutil.print/#module-llutilprint","text":"","title":"module llutil.print"},{"location":"documents/llutil.print/#function-format_size","text":"format_size ( size ) Format a byte count as a human readable file size. format_size ( 0 ) # '0 bytes' format_size ( 1 ) # '1 byte' format_size ( 5 ) # '5 bytes' format_size ( 1024 ) # '1 KiB'","title":"function format_size"},{"location":"documents/llutil.pycuda/","text":"module llutil.pycuda Integrates PyCUDA to PyTorch and ice. class CUDAModule Just-In-Time compilation of a set of CUDA kernel functions and device functions from source. ice.CUDAModule works differently compared to pycuda's SourceModule in following ways: Support efficient multi-dimensional torch.Tensor access with optional boundary check. Automatically handle scalar data type conversion from python/pytorch to c++. Compile error message will report the original source code. Easier API. Configurable in the ice-learn eco-system. Example: import ice M , N , K = 4 , 4 , 1 a = torch . rand (( M , K ), dtype = torch . float32 ) . cuda () b = torch . rand (( K , N ), dtype = torch . float32 ) . cuda () c = torch . empty (( M , N ), dtype = torch . float32 ) . cuda () kernels = ice . CUDAModule ( r \"\"\" __global__ void matmul(Tensor<float, 2> *a, Tensor<float, 2> *b, Tensor<float, 2> *c, int M, int N, int K) { int m = blockIdx.y * blockDim.y + threadIdx.y; int n = blockIdx.x * blockDim.x + threadIdx.x; float v = 0.f; if (m >= M || n >= N) return; for (int k = 0; k < K; ++k) { v += (*a)[m][k] * (*b)[k][n]; } (*c)[m][n] = v; } \"\"\" , float_bits = 32 ) kernels . matmul ( a , b , c , M , N , K , grid = ( N // 32 + 1 , M // 32 + 1 ), block = ( 32 , 32 , 1 )) torch . cuda . synchronize () assert torch . allclose ( c , torch . mm ( a , b )) method __init__ __init__ ( source , float_bits , int_bits = 32 , include_dirs = [], boundscheck = True , ** kwds ) Setup the parameters for compiling a CUDA source. Args: source (str): CUDA C++ source string. float_bits (int): bit width of float values used as tensor scalar. int_bits (int, optional): bit width of default int scalar. Defaults to 32. include_dirs (list, optional): paths of extra include dirs. Defaults to []. boundscheck (bool, optional): enable out of bound check for tensors. Defaults to True. **kwds : other keyword args you would like to pass to pycuda's SourceModule . Note: Direct written float and int token in the source string will be substituted to ensure the default scalar data type matches the tensors. If you do not want this to happen, use more specific CUDA typename such as __half , double , int16_t , etc.","title":"Llutil.pycuda"},{"location":"documents/llutil.pycuda/#module-llutilpycuda","text":"Integrates PyCUDA to PyTorch and ice.","title":"module llutil.pycuda"},{"location":"documents/llutil.pycuda/#class-cudamodule","text":"Just-In-Time compilation of a set of CUDA kernel functions and device functions from source. ice.CUDAModule works differently compared to pycuda's SourceModule in following ways: Support efficient multi-dimensional torch.Tensor access with optional boundary check. Automatically handle scalar data type conversion from python/pytorch to c++. Compile error message will report the original source code. Easier API. Configurable in the ice-learn eco-system. Example: import ice M , N , K = 4 , 4 , 1 a = torch . rand (( M , K ), dtype = torch . float32 ) . cuda () b = torch . rand (( K , N ), dtype = torch . float32 ) . cuda () c = torch . empty (( M , N ), dtype = torch . float32 ) . cuda () kernels = ice . CUDAModule ( r \"\"\" __global__ void matmul(Tensor<float, 2> *a, Tensor<float, 2> *b, Tensor<float, 2> *c, int M, int N, int K) { int m = blockIdx.y * blockDim.y + threadIdx.y; int n = blockIdx.x * blockDim.x + threadIdx.x; float v = 0.f; if (m >= M || n >= N) return; for (int k = 0; k < K; ++k) { v += (*a)[m][k] * (*b)[k][n]; } (*c)[m][n] = v; } \"\"\" , float_bits = 32 ) kernels . matmul ( a , b , c , M , N , K , grid = ( N // 32 + 1 , M // 32 + 1 ), block = ( 32 , 32 , 1 )) torch . cuda . synchronize () assert torch . allclose ( c , torch . mm ( a , b ))","title":"class CUDAModule"},{"location":"documents/llutil.pycuda/#method-__init__","text":"__init__ ( source , float_bits , int_bits = 32 , include_dirs = [], boundscheck = True , ** kwds ) Setup the parameters for compiling a CUDA source. Args: source (str): CUDA C++ source string. float_bits (int): bit width of float values used as tensor scalar. int_bits (int, optional): bit width of default int scalar. Defaults to 32. include_dirs (list, optional): paths of extra include dirs. Defaults to []. boundscheck (bool, optional): enable out of bound check for tensors. Defaults to True. **kwds : other keyword args you would like to pass to pycuda's SourceModule . Note: Direct written float and int token in the source string will be substituted to ensure the default scalar data type matches the tensors. If you do not want this to happen, use more specific CUDA typename such as __half , double , int16_t , etc.","title":"method __init__"},{"location":"documents/llutil.shadow_tb/","text":"module llutil.shadow_tb Global Variables DEBUG_ICE SHADOW_PATTERNS function shadow shadow ( etype , evalue , tb )","title":"Llutil.shadow tb"},{"location":"documents/llutil.shadow_tb/#module-llutilshadow_tb","text":"","title":"module llutil.shadow_tb"},{"location":"documents/llutil.shadow_tb/#global-variables","text":"DEBUG_ICE SHADOW_PATTERNS","title":"Global Variables"},{"location":"documents/llutil.shadow_tb/#function-shadow","text":"shadow ( etype , evalue , tb )","title":"function shadow"},{"location":"documents/llutil.test/","text":"module llutil.test helps developers of ice to test. function requires_n_gpus requires_n_gpus ( n )","title":"Llutil.test"},{"location":"documents/llutil.test/#module-llutiltest","text":"helps developers of ice to test.","title":"module llutil.test"},{"location":"documents/llutil.test/#function-requires_n_gpus","text":"requires_n_gpus ( n )","title":"function requires_n_gpus"},{"location":"resources/dev_notes/00_setup_devenv/","text":"Setup Environment We use poetry as the virtualenv as well as project manager (e.g. dependencies, packaging, publishing, etc.). Please read about poetry (see REFERNCES section at the end of this page) and the pyproject.toml file before you run following commands to setup your local develop environment. Having another pip installed release version of ice will not cause a problem since poetry isolates the environment. Pypi Mirror for China (Optional) mkdir -p ~/.pip echo \"[config]\\nindex-url = https://pypi.douban.com/simple\" > ~/.pip/pip.conf Steps Install poetry following the instruction here . Set tab-completion for poetry following the instruction here git clone https://github.com/tjyuyao/ice-learn cd ice-learn poetry shell poetry install -E pycuda Set tab-completion for poe-the-poet following the instruction here . Install torch and torchvision manually for correct cuda version using pip in the poetry shell, e.g.: pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html References Poetry First Impression Poetry Tutorial Poetry API Reference","title":"Setup Environment"},{"location":"resources/dev_notes/00_setup_devenv/#setup-environment","text":"We use poetry as the virtualenv as well as project manager (e.g. dependencies, packaging, publishing, etc.). Please read about poetry (see REFERNCES section at the end of this page) and the pyproject.toml file before you run following commands to setup your local develop environment. Having another pip installed release version of ice will not cause a problem since poetry isolates the environment.","title":"Setup Environment"},{"location":"resources/dev_notes/00_setup_devenv/#pypi-mirror-for-china-optional","text":"mkdir -p ~/.pip echo \"[config]\\nindex-url = https://pypi.douban.com/simple\" > ~/.pip/pip.conf","title":"Pypi Mirror for China (Optional)"},{"location":"resources/dev_notes/00_setup_devenv/#steps","text":"Install poetry following the instruction here . Set tab-completion for poetry following the instruction here git clone https://github.com/tjyuyao/ice-learn cd ice-learn poetry shell poetry install -E pycuda Set tab-completion for poe-the-poet following the instruction here . Install torch and torchvision manually for correct cuda version using pip in the poetry shell, e.g.: pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html","title":"Steps"},{"location":"resources/dev_notes/00_setup_devenv/#references","text":"Poetry First Impression Poetry Tutorial Poetry API Reference","title":"References"},{"location":"resources/dev_notes/01_contribution_guide/","text":"Contribution Guide Authors fork and submit pull requests. The project owner will review and merge them. Changes does not need to be rebased, you can keep every history. But try to follow below constraints for commit messages: Prefix it with at least one of these words: [Tiny] for trivial modification. [Deps] when commits contain dependency variation. [Bugs] fixed ... when you fixed one or more bugs. [Bugs] tbfix ... when you discovered bugs but not jet fixed. Add TODO tags and descriptions in the code comments. [Feat] when a new feature is basically/fully implemented, or behavior changed. [Docs] when only documentation is modified. Note that you should modify tutorials and devnotes in docs folder directly, but modify references in source code docstring following Google docstring style, as it is automatically generated using lazydocs . [Misc] for other cases. After the prefix, describe the details with concise but meaningful words. Commits can be both small and large, but try to always accomplish one concise and meaningful thing.","title":"Contribution Guide"},{"location":"resources/dev_notes/01_contribution_guide/#contribution-guide","text":"Authors fork and submit pull requests. The project owner will review and merge them. Changes does not need to be rebased, you can keep every history. But try to follow below constraints for commit messages: Prefix it with at least one of these words: [Tiny] for trivial modification. [Deps] when commits contain dependency variation. [Bugs] fixed ... when you fixed one or more bugs. [Bugs] tbfix ... when you discovered bugs but not jet fixed. Add TODO tags and descriptions in the code comments. [Feat] when a new feature is basically/fully implemented, or behavior changed. [Docs] when only documentation is modified. Note that you should modify tutorials and devnotes in docs folder directly, but modify references in source code docstring following Google docstring style, as it is automatically generated using lazydocs . [Misc] for other cases. After the prefix, describe the details with concise but meaningful words. Commits can be both small and large, but try to always accomplish one concise and meaningful thing.","title":"Contribution Guide"},{"location":"resources/dev_notes/02_docs_and_tests/","text":"Documents & Tests This page describes solutions ice-learn adopts about documentation generation, unit tests and documentation-based test. Note that following commands should be executed in a poetry shell , or prepended by poetry run . pytest We use pytest for unittesting. For example, pytest tests/llutil/test_config.py -vs where -s will print outputs for failed tests. Run specific tests with test_mod.py::TestClass:test_method or test_mod.py::test_function . pytest tests/llutil/test_multiprocessing.py::test_reduce -v Option -m slow will run tests decorated with the @pytest.mark.slow decorator. pytest tests/llutil/test_multiprocessing.py -v -m slow Option -m \"not slow\" will run tests not decorated with the @pytest.mark.slow decorator. pytest tests/llutil/ -v -m \"not slow\" See more configurations in pytest.ini . ice.llutil.test has some extensions for conditional tests for conveniency. xdoctest We use xdoctest for testing demostration code in docstring. For example, python -m xdoctest ice/llutil/config.py or pytest ice/llutil/ -v --xdoc lazydocs We generate markdown documentations from docstring using a modified lazydocs script. For example, python ./docs/build_docs.py mkdocs We generate the documents site from manually written as well as autogenerated markdown using mkdocs , the plugin mkdocs-awesome-pages and the theme mkdocs-material . In the ./docs directory, files in documents are automatically generated by lazydocs , while other subfolders contain manually written docs. Configuration file is mkdocs.yml . Changing the navigator appearance of the document site requires modifying .pages file in each level of subdirectories. Run following command locally to preview the site at the root directory of ice-learn project: mkdocs serve Run following command to push documents to gh-pages branch (for Github Pages). mkdocs gh-deploy See this page for more infomation on deploying documents.","title":"Documents & Tests"},{"location":"resources/dev_notes/02_docs_and_tests/#documents-tests","text":"This page describes solutions ice-learn adopts about documentation generation, unit tests and documentation-based test. Note that following commands should be executed in a poetry shell , or prepended by poetry run .","title":"Documents &amp; Tests"},{"location":"resources/dev_notes/02_docs_and_tests/#pytest","text":"We use pytest for unittesting. For example, pytest tests/llutil/test_config.py -vs where -s will print outputs for failed tests. Run specific tests with test_mod.py::TestClass:test_method or test_mod.py::test_function . pytest tests/llutil/test_multiprocessing.py::test_reduce -v Option -m slow will run tests decorated with the @pytest.mark.slow decorator. pytest tests/llutil/test_multiprocessing.py -v -m slow Option -m \"not slow\" will run tests not decorated with the @pytest.mark.slow decorator. pytest tests/llutil/ -v -m \"not slow\" See more configurations in pytest.ini . ice.llutil.test has some extensions for conditional tests for conveniency.","title":"pytest"},{"location":"resources/dev_notes/02_docs_and_tests/#xdoctest","text":"We use xdoctest for testing demostration code in docstring. For example, python -m xdoctest ice/llutil/config.py or pytest ice/llutil/ -v --xdoc","title":"xdoctest"},{"location":"resources/dev_notes/02_docs_and_tests/#lazydocs","text":"We generate markdown documentations from docstring using a modified lazydocs script. For example, python ./docs/build_docs.py","title":"lazydocs"},{"location":"resources/dev_notes/02_docs_and_tests/#mkdocs","text":"We generate the documents site from manually written as well as autogenerated markdown using mkdocs , the plugin mkdocs-awesome-pages and the theme mkdocs-material . In the ./docs directory, files in documents are automatically generated by lazydocs , while other subfolders contain manually written docs. Configuration file is mkdocs.yml . Changing the navigator appearance of the document site requires modifying .pages file in each level of subdirectories. Run following command locally to preview the site at the root directory of ice-learn project: mkdocs serve Run following command to push documents to gh-pages branch (for Github Pages). mkdocs gh-deploy See this page for more infomation on deploying documents.","title":"mkdocs"},{"location":"resources/dev_notes/03_architechture_design/","text":"The Folder Structure llutil for Low-Level Utilities that supports the most fundamental mechanisms. multiprocessing enables cross-processes communication for tensors, lambdas and closures. config converts every class into a configurable . modifier defines a tool for pipeline operation, useful in dataset transform and learning rate update, etc. core implements the kernel hyper-graph architecture for scheduling multitasks and experiments. api organizes all resources and provide user-friendly interfaces. repro reproduces public works using low-level or high-level APIs in ice . Models, tricks, and other useful code will be incorporated back into api if in need.","title":"The Folder Structure"},{"location":"resources/dev_notes/03_architechture_design/#the-folder-structure","text":"llutil for Low-Level Utilities that supports the most fundamental mechanisms. multiprocessing enables cross-processes communication for tensors, lambdas and closures. config converts every class into a configurable . modifier defines a tool for pipeline operation, useful in dataset transform and learning rate update, etc. core implements the kernel hyper-graph architecture for scheduling multitasks and experiments. api organizes all resources and provide user-friendly interfaces. repro reproduces public works using low-level or high-level APIs in ice . Models, tricks, and other useful code will be incorporated back into api if in need.","title":"The Folder Structure"},{"location":"user_guide/01_debug_tips/","text":"How to debug ice programs Debug by print_forward_output Debug by breakpoint Debug by Integrated Development Environment","title":"How to debug `ice` programs"},{"location":"user_guide/01_debug_tips/#how-to-debug-ice-programs","text":"","title":"How to debug ice programs"},{"location":"user_guide/01_debug_tips/#debug-by-print_forward_output","text":"","title":"Debug by print_forward_output"},{"location":"user_guide/01_debug_tips/#debug-by-breakpoint","text":"","title":"Debug by breakpoint"},{"location":"user_guide/01_debug_tips/#debug-by-integrated-development-environment","text":"","title":"Debug by Integrated Development Environment"}]}